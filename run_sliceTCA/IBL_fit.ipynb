{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHiF2GEMNydk",
        "outputId": "99b1f0c2-7333-4042-cbd4-a043ffddd758"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqVOdtHDQ8on",
        "outputId": "d8e269b8-0c2a-4bf8-f427-c5078bc5dfc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/iterative-tensor-decomposition-colab\n"
          ]
        }
      ],
      "source": [
        "cd drive/MyDrive/iterative-tensor-decomposition-colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05Y9zjdCOdCA"
      },
      "outputs": [],
      "source": [
        "from run.run_tca import decompose\n",
        "import numpy as np\n",
        "import scipy.ndimage as spnd\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "data = np.load('./data/IBL_neurons_10_warped.npy')/.01\n",
        "\n",
        "idx  = np.where(np.array([np.mean(d) for d in data]) >.2)[0]\n",
        "data = data[idx]\n",
        "\n",
        "data = spnd.gaussian_filter1d(data, sigma=2)\n",
        "data = np.array([d-np.min(d) for d in data])\n",
        "data = np.array([d/np.max(d) for d in data])\n",
        "data = torch.from_numpy(data).float().permute(1, 0, 2).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I35Dk2uIGKsY",
        "outputId": "53b5e506-8af3-4896-a4b6-ac9b475d36e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([831, 221, 350])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Om4r3dlON0v",
        "outputId": "ec4fdf4d-6fd7-48a8-d16e-65f403176658"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.20069121789232217\n"
          ]
        }
      ],
      "source": [
        "print((1*1*15*860000)/(831*221*350))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X06E2010O3ON"
      },
      "outputs": [],
      "source": [
        "#The hyperparameters\n",
        "slice_TCA = True\n",
        "positive = True\n",
        "orthogonal_constraint  = False\n",
        "cross_validation = False\n",
        "orthogonal_penalty = False\n",
        "metric = False\n",
        "do_varimax = False\n",
        "cut_cv_mask = 4\n",
        "\n",
        "mask_cross_validation = 0.2\n",
        "\n",
        "learning_rate = 0.02\n",
        "mask = .8\n",
        "\n",
        "decay_rate_lr = 1\n",
        "decay_rate_mask = 0.5\n",
        "decay_iterations = 5\n",
        "decay_type_lr='exponential'\n",
        "decay_type_mask='exponential'\n",
        "\n",
        "iterations = decay_iterations*99\n",
        "batch_size = 20\n",
        "test_freq = -1\n",
        "initialization = 'uniform-positive'\n",
        "\n",
        "verbose_train = True\n",
        "verbose_test = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Xf_Tl79ZU18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91c7bf81-a2a8-4579-b635-7b4168667587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Iteration: 38 \tmse_loss: 0.0580325909\n",
            "Iteration: 39 \tmse_loss: 0.0578261428\n",
            "Iteration: 40 \tmse_loss: 0.0623776466\n",
            "Test -- Iteration: 40 \tmse_loss: 0.0623139478\n",
            "Iteration: 41 \tmse_loss: 0.0622183569\n",
            "Iteration: 42 \tmse_loss: 0.0619361885\n",
            "Iteration: 43 \tmse_loss: 0.0615781173\n",
            "Iteration: 44 \tmse_loss: 0.0611634068\n",
            "Iteration: 45 \tmse_loss: 0.0607211068\n",
            "Iteration: 46 \tmse_loss: 0.0602798946\n",
            "Iteration: 47 \tmse_loss: 0.0598539636\n",
            "Iteration: 48 \tmse_loss: 0.0594529137\n",
            "Iteration: 49 \tmse_loss: 0.0590884052\n",
            "Iteration: 50 \tmse_loss: 0.0587555580\n",
            "Iteration: 51 \tmse_loss: 0.0584507100\n",
            "Iteration: 52 \tmse_loss: 0.0581758209\n",
            "Iteration: 53 \tmse_loss: 0.0579195842\n",
            "Iteration: 54 \tmse_loss: 0.0576813668\n",
            "Iteration: 55 \tmse_loss: 0.0574625246\n",
            "Iteration: 56 \tmse_loss: 0.0572609119\n",
            "Iteration: 57 \tmse_loss: 0.0570730567\n",
            "Iteration: 58 \tmse_loss: 0.0568962432\n",
            "Iteration: 59 \tmse_loss: 0.0567297861\n",
            "Iteration: 60 \tmse_loss: 0.0612825155\n",
            "Test -- Iteration: 60 \tmse_loss: 0.0612482317\n",
            "Iteration: 61 \tmse_loss: 0.0611633658\n",
            "Iteration: 62 \tmse_loss: 0.0609304607\n",
            "Iteration: 63 \tmse_loss: 0.0606204532\n",
            "Iteration: 64 \tmse_loss: 0.0602589324\n",
            "Iteration: 65 \tmse_loss: 0.0598731264\n",
            "Iteration: 66 \tmse_loss: 0.0594859086\n",
            "Iteration: 67 \tmse_loss: 0.0591056831\n",
            "Iteration: 68 \tmse_loss: 0.0587454028\n",
            "Iteration: 69 \tmse_loss: 0.0584114045\n",
            "Iteration: 70 \tmse_loss: 0.0581009164\n",
            "Iteration: 71 \tmse_loss: 0.0578178801\n",
            "Iteration: 72 \tmse_loss: 0.0575579591\n",
            "Iteration: 73 \tmse_loss: 0.0573229976\n",
            "Iteration: 74 \tmse_loss: 0.0571104065\n",
            "Iteration: 75 \tmse_loss: 0.0569108203\n",
            "Iteration: 76 \tmse_loss: 0.0567288138\n",
            "Iteration: 77 \tmse_loss: 0.0565591902\n",
            "Iteration: 78 \tmse_loss: 0.0563998558\n",
            "Iteration: 79 \tmse_loss: 0.0562529899\n",
            "Iteration: 80 \tmse_loss: 0.0605819300\n",
            "Test -- Iteration: 80 \tmse_loss: 0.0605567507\n",
            "Iteration: 81 \tmse_loss: 0.0604714938\n",
            "Iteration: 82 \tmse_loss: 0.0602694750\n",
            "Iteration: 83 \tmse_loss: 0.0600032248\n",
            "Iteration: 84 \tmse_loss: 0.0596865751\n",
            "Iteration: 85 \tmse_loss: 0.0593531430\n",
            "Iteration: 86 \tmse_loss: 0.0590131953\n",
            "Iteration: 87 \tmse_loss: 0.0586759932\n",
            "Iteration: 88 \tmse_loss: 0.0583531149\n",
            "Iteration: 89 \tmse_loss: 0.0580410846\n",
            "Iteration: 90 \tmse_loss: 0.0577484928\n",
            "Iteration: 91 \tmse_loss: 0.0574837625\n",
            "Iteration: 92 \tmse_loss: 0.0572415181\n",
            "Iteration: 93 \tmse_loss: 0.0570186079\n",
            "Iteration: 94 \tmse_loss: 0.0568184517\n",
            "Iteration: 95 \tmse_loss: 0.0566359311\n",
            "Iteration: 96 \tmse_loss: 0.0564640500\n",
            "Iteration: 97 \tmse_loss: 0.0563069321\n",
            "Iteration: 98 \tmse_loss: 0.0561633222\n",
            "Iteration: 99 \tmse_loss: 0.0560310446\n",
            "Iteration: 100 \tmse_loss: 0.0600545295\n",
            "Test -- Iteration: 100 \tmse_loss: 0.0600571334\n",
            "Iteration: 101 \tmse_loss: 0.0599623211\n",
            "Iteration: 102 \tmse_loss: 0.0597859174\n",
            "Iteration: 103 \tmse_loss: 0.0595542751\n",
            "Iteration: 104 \tmse_loss: 0.0592816696\n",
            "Iteration: 105 \tmse_loss: 0.0589907542\n",
            "Iteration: 106 \tmse_loss: 0.0586892851\n",
            "Iteration: 107 \tmse_loss: 0.0583888441\n",
            "Iteration: 108 \tmse_loss: 0.0580926165\n",
            "Iteration: 109 \tmse_loss: 0.0578033552\n",
            "Iteration: 110 \tmse_loss: 0.0575291589\n",
            "Iteration: 111 \tmse_loss: 0.0572729819\n",
            "Iteration: 112 \tmse_loss: 0.0570408329\n",
            "Iteration: 113 \tmse_loss: 0.0568297543\n",
            "Iteration: 114 \tmse_loss: 0.0566317402\n",
            "Iteration: 115 \tmse_loss: 0.0564500429\n",
            "Iteration: 116 \tmse_loss: 0.0562872328\n",
            "Iteration: 117 \tmse_loss: 0.0561373197\n",
            "Iteration: 118 \tmse_loss: 0.0560012236\n",
            "Iteration: 119 \tmse_loss: 0.0558820888\n",
            "Iteration: 120 \tmse_loss: 0.0597051755\n",
            "Test -- Iteration: 120 \tmse_loss: 0.0597111359\n",
            "Iteration: 121 \tmse_loss: 0.0596220084\n",
            "Iteration: 122 \tmse_loss: 0.0594703183\n",
            "Iteration: 123 \tmse_loss: 0.0592647120\n",
            "Iteration: 124 \tmse_loss: 0.0590226054\n",
            "Iteration: 125 \tmse_loss: 0.0587635674\n",
            "Iteration: 126 \tmse_loss: 0.0584901124\n",
            "Iteration: 127 \tmse_loss: 0.0582155287\n",
            "Iteration: 128 \tmse_loss: 0.0579380095\n",
            "Iteration: 129 \tmse_loss: 0.0576596484\n",
            "Iteration: 130 \tmse_loss: 0.0573957302\n",
            "Iteration: 131 \tmse_loss: 0.0571491793\n",
            "Iteration: 132 \tmse_loss: 0.0569230691\n",
            "Iteration: 133 \tmse_loss: 0.0567156300\n",
            "Iteration: 134 \tmse_loss: 0.0565192662\n",
            "Iteration: 135 \tmse_loss: 0.0563381687\n",
            "Iteration: 136 \tmse_loss: 0.0561800338\n",
            "Iteration: 137 \tmse_loss: 0.0560330041\n",
            "Iteration: 138 \tmse_loss: 0.0559007488\n",
            "Iteration: 139 \tmse_loss: 0.0557863116\n",
            "Iteration: 140 \tmse_loss: 0.0594417192\n",
            "Test -- Iteration: 140 \tmse_loss: 0.0594623834\n",
            "Iteration: 141 \tmse_loss: 0.0593653470\n",
            "Iteration: 142 \tmse_loss: 0.0592284352\n",
            "Iteration: 143 \tmse_loss: 0.0590421967\n",
            "Iteration: 144 \tmse_loss: 0.0588206649\n",
            "Iteration: 145 \tmse_loss: 0.0585827567\n",
            "Iteration: 146 \tmse_loss: 0.0583354868\n",
            "Iteration: 147 \tmse_loss: 0.0580818392\n",
            "Iteration: 148 \tmse_loss: 0.0578186363\n",
            "Iteration: 149 \tmse_loss: 0.0575577840\n",
            "Iteration: 150 \tmse_loss: 0.0573079549\n",
            "Iteration: 151 \tmse_loss: 0.0570742749\n",
            "Iteration: 152 \tmse_loss: 0.0568536259\n",
            "Iteration: 153 \tmse_loss: 0.0566493049\n",
            "Iteration: 154 \tmse_loss: 0.0564553477\n",
            "Iteration: 155 \tmse_loss: 0.0562775508\n",
            "Iteration: 156 \tmse_loss: 0.0561209582\n",
            "Iteration: 157 \tmse_loss: 0.0559762307\n",
            "Iteration: 158 \tmse_loss: 0.0558472089\n",
            "Iteration: 159 \tmse_loss: 0.0557310730\n",
            "Iteration: 160 \tmse_loss: 0.0592566989\n",
            "Test -- Iteration: 160 \tmse_loss: 0.0592867322\n",
            "Iteration: 161 \tmse_loss: 0.0591876805\n",
            "Iteration: 162 \tmse_loss: 0.0590636954\n",
            "Iteration: 163 \tmse_loss: 0.0588854216\n",
            "Iteration: 164 \tmse_loss: 0.0586831793\n",
            "Iteration: 165 \tmse_loss: 0.0584669970\n",
            "Iteration: 166 \tmse_loss: 0.0582416654\n",
            "Iteration: 167 \tmse_loss: 0.0580012389\n",
            "Iteration: 168 \tmse_loss: 0.0577548891\n",
            "Iteration: 169 \tmse_loss: 0.0575059466\n",
            "Iteration: 170 \tmse_loss: 0.0572667196\n",
            "Iteration: 171 \tmse_loss: 0.0570402928\n",
            "Iteration: 172 \tmse_loss: 0.0568233132\n",
            "Iteration: 173 \tmse_loss: 0.0566186160\n",
            "Iteration: 174 \tmse_loss: 0.0564290956\n",
            "Iteration: 175 \tmse_loss: 0.0562582612\n",
            "Iteration: 176 \tmse_loss: 0.0560978390\n",
            "Iteration: 177 \tmse_loss: 0.0559536144\n",
            "Iteration: 178 \tmse_loss: 0.0558222719\n",
            "Iteration: 179 \tmse_loss: 0.0557066463\n",
            "Iteration: 180 \tmse_loss: 0.0591462888\n",
            "Test -- Iteration: 180 \tmse_loss: 0.0591531657\n",
            "Iteration: 181 \tmse_loss: 0.0590794012\n",
            "Iteration: 182 \tmse_loss: 0.0589672513\n",
            "Iteration: 183 \tmse_loss: 0.0588086732\n",
            "Iteration: 184 \tmse_loss: 0.0586219840\n",
            "Iteration: 185 \tmse_loss: 0.0584237985\n",
            "Iteration: 186 \tmse_loss: 0.0582146272\n",
            "Iteration: 187 \tmse_loss: 0.0579854511\n",
            "Iteration: 188 \tmse_loss: 0.0577528216\n",
            "Iteration: 189 \tmse_loss: 0.0575188436\n",
            "Iteration: 190 \tmse_loss: 0.0572909415\n",
            "Iteration: 191 \tmse_loss: 0.0570722632\n",
            "Iteration: 192 \tmse_loss: 0.0568651967\n",
            "Iteration: 193 \tmse_loss: 0.0566647314\n",
            "Iteration: 194 \tmse_loss: 0.0564760976\n",
            "Iteration: 195 \tmse_loss: 0.0562999435\n",
            "Iteration: 196 \tmse_loss: 0.0561415404\n",
            "Iteration: 197 \tmse_loss: 0.0560000762\n",
            "Iteration: 198 \tmse_loss: 0.0558727868\n",
            "Final loss \tmse_loss: 0.0558727868\n",
            "Iteration: 0 \tmse_loss: 0.0589582883\n",
            "Test -- Iteration: 0 \tmse_loss: 0.0600485355\n",
            "Iteration: 1 \tmse_loss: 0.0597008169\n",
            "Iteration: 2 \tmse_loss: 0.0590771325\n",
            "Iteration: 3 \tmse_loss: 0.0581691042\n",
            "Iteration: 4 \tmse_loss: 0.0581471063\n",
            "Iteration: 5 \tmse_loss: 0.0577139519\n",
            "Iteration: 6 \tmse_loss: 0.0571497604\n",
            "Iteration: 7 \tmse_loss: 0.0568834506\n",
            "Iteration: 8 \tmse_loss: 0.0567311905\n",
            "Iteration: 9 \tmse_loss: 0.0566012412\n",
            "Iteration: 10 \tmse_loss: 0.0564221814\n",
            "Iteration: 11 \tmse_loss: 0.0561876707\n",
            "Iteration: 12 \tmse_loss: 0.0559895746\n",
            "Iteration: 13 \tmse_loss: 0.0558505356\n",
            "Iteration: 14 \tmse_loss: 0.0557382926\n",
            "Iteration: 15 \tmse_loss: 0.0556235053\n",
            "Iteration: 16 \tmse_loss: 0.0555077568\n",
            "Iteration: 17 \tmse_loss: 0.0553923622\n",
            "Iteration: 18 \tmse_loss: 0.0552946776\n",
            "Iteration: 19 \tmse_loss: 0.0552140214\n",
            "Iteration: 20 \tmse_loss: 0.0592869669\n",
            "Test -- Iteration: 20 \tmse_loss: 0.0592878722\n",
            "Iteration: 21 \tmse_loss: 0.0591984056\n",
            "Iteration: 22 \tmse_loss: 0.0590393394\n",
            "Iteration: 23 \tmse_loss: 0.0588446371\n",
            "Iteration: 24 \tmse_loss: 0.0586266257\n",
            "Iteration: 25 \tmse_loss: 0.0584006868\n",
            "Iteration: 26 \tmse_loss: 0.0581728257\n",
            "Iteration: 27 \tmse_loss: 0.0579458587\n",
            "Iteration: 28 \tmse_loss: 0.0577225983\n",
            "Iteration: 29 \tmse_loss: 0.0574973673\n",
            "Iteration: 30 \tmse_loss: 0.0572705045\n",
            "Iteration: 31 \tmse_loss: 0.0570462644\n",
            "Iteration: 32 \tmse_loss: 0.0568269864\n",
            "Iteration: 33 \tmse_loss: 0.0566180348\n",
            "Iteration: 34 \tmse_loss: 0.0564256459\n",
            "Iteration: 35 \tmse_loss: 0.0562513545\n",
            "Iteration: 36 \tmse_loss: 0.0560967699\n",
            "Iteration: 37 \tmse_loss: 0.0559563711\n",
            "Iteration: 38 \tmse_loss: 0.0558288135\n",
            "Iteration: 39 \tmse_loss: 0.0557122529\n",
            "Iteration: 40 \tmse_loss: 0.0591190904\n",
            "Test -- Iteration: 40 \tmse_loss: 0.0591345541\n",
            "Iteration: 41 \tmse_loss: 0.0590401664\n",
            "Iteration: 42 \tmse_loss: 0.0588977151\n",
            "Iteration: 43 \tmse_loss: 0.0587234497\n",
            "Iteration: 44 \tmse_loss: 0.0585256256\n",
            "Iteration: 45 \tmse_loss: 0.0583170429\n",
            "Iteration: 46 \tmse_loss: 0.0581023470\n",
            "Iteration: 47 \tmse_loss: 0.0578917265\n",
            "Iteration: 48 \tmse_loss: 0.0576839745\n",
            "Iteration: 49 \tmse_loss: 0.0574723072\n",
            "Iteration: 50 \tmse_loss: 0.0572528765\n",
            "Iteration: 51 \tmse_loss: 0.0570331812\n",
            "Iteration: 52 \tmse_loss: 0.0568220913\n",
            "Iteration: 53 \tmse_loss: 0.0566212498\n",
            "Iteration: 54 \tmse_loss: 0.0564333797\n",
            "Iteration: 55 \tmse_loss: 0.0562646650\n",
            "Iteration: 56 \tmse_loss: 0.0561170913\n",
            "Iteration: 57 \tmse_loss: 0.0559791699\n",
            "Iteration: 58 \tmse_loss: 0.0558523610\n",
            "Iteration: 59 \tmse_loss: 0.0557353683\n",
            "Iteration: 60 \tmse_loss: 0.0590183102\n",
            "Test -- Iteration: 60 \tmse_loss: 0.0590419397\n",
            "Iteration: 61 \tmse_loss: 0.0589475743\n",
            "Iteration: 62 \tmse_loss: 0.0588233322\n",
            "Iteration: 63 \tmse_loss: 0.0586660579\n",
            "Iteration: 64 \tmse_loss: 0.0584853888\n",
            "Iteration: 65 \tmse_loss: 0.0582917146\n",
            "Iteration: 66 \tmse_loss: 0.0580945238\n",
            "Iteration: 67 \tmse_loss: 0.0578972213\n",
            "Iteration: 68 \tmse_loss: 0.0576927848\n",
            "Iteration: 69 \tmse_loss: 0.0574755780\n",
            "Iteration: 70 \tmse_loss: 0.0572580583\n",
            "Iteration: 71 \tmse_loss: 0.0570469946\n",
            "Iteration: 72 \tmse_loss: 0.0568412021\n",
            "Iteration: 73 \tmse_loss: 0.0566403382\n",
            "Iteration: 74 \tmse_loss: 0.0564611778\n",
            "Iteration: 75 \tmse_loss: 0.0562987663\n",
            "Iteration: 76 \tmse_loss: 0.0561443083\n",
            "Iteration: 77 \tmse_loss: 0.0560015850\n",
            "Iteration: 78 \tmse_loss: 0.0558714941\n",
            "Iteration: 79 \tmse_loss: 0.0557539985\n",
            "Iteration: 80 \tmse_loss: 0.0589284226\n",
            "Test -- Iteration: 80 \tmse_loss: 0.0589653701\n",
            "Iteration: 81 \tmse_loss: 0.0588580184\n",
            "Iteration: 82 \tmse_loss: 0.0587435104\n",
            "Iteration: 83 \tmse_loss: 0.0586014874\n",
            "Iteration: 84 \tmse_loss: 0.0584397018\n",
            "Iteration: 85 \tmse_loss: 0.0582601838\n",
            "Iteration: 86 \tmse_loss: 0.0580711812\n",
            "Iteration: 87 \tmse_loss: 0.0578823537\n",
            "Iteration: 88 \tmse_loss: 0.0576843768\n",
            "Iteration: 89 \tmse_loss: 0.0574735180\n",
            "Iteration: 90 \tmse_loss: 0.0572613925\n",
            "Iteration: 91 \tmse_loss: 0.0570554473\n",
            "Iteration: 92 \tmse_loss: 0.0568573698\n",
            "Iteration: 93 \tmse_loss: 0.0566668212\n",
            "Iteration: 94 \tmse_loss: 0.0564896688\n",
            "Iteration: 95 \tmse_loss: 0.0563286208\n",
            "Iteration: 96 \tmse_loss: 0.0561747029\n",
            "Iteration: 97 \tmse_loss: 0.0560306683\n",
            "Iteration: 98 \tmse_loss: 0.0558978654\n",
            "Iteration: 99 \tmse_loss: 0.0557771735\n",
            "Iteration: 100 \tmse_loss: 0.0588342510\n",
            "Test -- Iteration: 100 \tmse_loss: 0.0588919707\n",
            "Iteration: 101 \tmse_loss: 0.0587735884\n",
            "Iteration: 102 \tmse_loss: 0.0586743057\n",
            "Iteration: 103 \tmse_loss: 0.0585417710\n",
            "Iteration: 104 \tmse_loss: 0.0583894774\n",
            "Iteration: 105 \tmse_loss: 0.0582174063\n",
            "Iteration: 106 \tmse_loss: 0.0580412932\n",
            "Iteration: 107 \tmse_loss: 0.0578594133\n",
            "Iteration: 108 \tmse_loss: 0.0576626845\n",
            "Iteration: 109 \tmse_loss: 0.0574593470\n",
            "Iteration: 110 \tmse_loss: 0.0572590269\n",
            "Iteration: 111 \tmse_loss: 0.0570601970\n",
            "Iteration: 112 \tmse_loss: 0.0568684898\n",
            "Iteration: 113 \tmse_loss: 0.0566866286\n",
            "Iteration: 114 \tmse_loss: 0.0565120876\n",
            "Iteration: 115 \tmse_loss: 0.0563495755\n",
            "Iteration: 116 \tmse_loss: 0.0561921522\n",
            "Iteration: 117 \tmse_loss: 0.0560449399\n",
            "Iteration: 118 \tmse_loss: 0.0559123680\n",
            "Iteration: 119 \tmse_loss: 0.0557911061\n",
            "Iteration: 120 \tmse_loss: 0.0587598868\n",
            "Test -- Iteration: 120 \tmse_loss: 0.0588204749\n",
            "Iteration: 121 \tmse_loss: 0.0587063394\n",
            "Iteration: 122 \tmse_loss: 0.0586212240\n",
            "Iteration: 123 \tmse_loss: 0.0584996454\n",
            "Iteration: 124 \tmse_loss: 0.0583583228\n",
            "Iteration: 125 \tmse_loss: 0.0581976920\n",
            "Iteration: 126 \tmse_loss: 0.0580297522\n",
            "Iteration: 127 \tmse_loss: 0.0578495227\n",
            "Iteration: 128 \tmse_loss: 0.0576613434\n",
            "Iteration: 129 \tmse_loss: 0.0574657731\n",
            "Iteration: 130 \tmse_loss: 0.0572751984\n",
            "Iteration: 131 \tmse_loss: 0.0570837110\n",
            "Iteration: 132 \tmse_loss: 0.0568971932\n",
            "Iteration: 133 \tmse_loss: 0.0567208193\n",
            "Iteration: 134 \tmse_loss: 0.0565518513\n",
            "Iteration: 135 \tmse_loss: 0.0563868620\n",
            "Iteration: 136 \tmse_loss: 0.0562302060\n",
            "Iteration: 137 \tmse_loss: 0.0560856946\n",
            "Iteration: 138 \tmse_loss: 0.0559485480\n",
            "Iteration: 139 \tmse_loss: 0.0558277443\n",
            "Iteration: 140 \tmse_loss: 0.0586990155\n",
            "Test -- Iteration: 140 \tmse_loss: 0.0587610528\n",
            "Iteration: 141 \tmse_loss: 0.0586472824\n",
            "Iteration: 142 \tmse_loss: 0.0585639328\n",
            "Iteration: 143 \tmse_loss: 0.0584502816\n",
            "Iteration: 144 \tmse_loss: 0.0583191998\n",
            "Iteration: 145 \tmse_loss: 0.0581722669\n",
            "Iteration: 146 \tmse_loss: 0.0580165237\n",
            "Iteration: 147 \tmse_loss: 0.0578422286\n",
            "Iteration: 148 \tmse_loss: 0.0576577261\n",
            "Iteration: 149 \tmse_loss: 0.0574721210\n",
            "Iteration: 150 \tmse_loss: 0.0572909676\n",
            "Iteration: 151 \tmse_loss: 0.0571089722\n",
            "Iteration: 152 \tmse_loss: 0.0569274016\n",
            "Iteration: 153 \tmse_loss: 0.0567544959\n",
            "Iteration: 154 \tmse_loss: 0.0565882921\n",
            "Iteration: 155 \tmse_loss: 0.0564256161\n",
            "Iteration: 156 \tmse_loss: 0.0562726781\n",
            "Iteration: 157 \tmse_loss: 0.0561286546\n",
            "Iteration: 158 \tmse_loss: 0.0559995174\n",
            "Iteration: 159 \tmse_loss: 0.0558796413\n",
            "Iteration: 160 \tmse_loss: 0.0586337522\n",
            "Test -- Iteration: 160 \tmse_loss: 0.0587018691\n",
            "Iteration: 161 \tmse_loss: 0.0585890785\n",
            "Iteration: 162 \tmse_loss: 0.0585104898\n",
            "Iteration: 163 \tmse_loss: 0.0584022924\n",
            "Iteration: 164 \tmse_loss: 0.0582735799\n",
            "Iteration: 165 \tmse_loss: 0.0581366122\n",
            "Iteration: 166 \tmse_loss: 0.0579850376\n",
            "Iteration: 167 \tmse_loss: 0.0578166023\n",
            "Iteration: 168 \tmse_loss: 0.0576436184\n",
            "Iteration: 169 \tmse_loss: 0.0574632324\n",
            "Iteration: 170 \tmse_loss: 0.0572836250\n",
            "Iteration: 171 \tmse_loss: 0.0571089685\n",
            "Iteration: 172 \tmse_loss: 0.0569333732\n",
            "Iteration: 173 \tmse_loss: 0.0567597672\n",
            "Iteration: 174 \tmse_loss: 0.0565964878\n",
            "Iteration: 175 \tmse_loss: 0.0564401187\n",
            "Iteration: 176 \tmse_loss: 0.0562879033\n",
            "Iteration: 177 \tmse_loss: 0.0561482459\n",
            "Iteration: 178 \tmse_loss: 0.0560173579\n",
            "Iteration: 179 \tmse_loss: 0.0558984317\n",
            "Iteration: 180 \tmse_loss: 0.0586310737\n",
            "Test -- Iteration: 180 \tmse_loss: 0.0586436801\n",
            "Iteration: 181 \tmse_loss: 0.0585813858\n",
            "Iteration: 182 \tmse_loss: 0.0585084483\n",
            "Iteration: 183 \tmse_loss: 0.0584065579\n",
            "Iteration: 184 \tmse_loss: 0.0582808927\n",
            "Iteration: 185 \tmse_loss: 0.0581524111\n",
            "Iteration: 186 \tmse_loss: 0.0580084771\n",
            "Iteration: 187 \tmse_loss: 0.0578434095\n",
            "Iteration: 188 \tmse_loss: 0.0576777831\n",
            "Iteration: 189 \tmse_loss: 0.0575120896\n",
            "Iteration: 190 \tmse_loss: 0.0573372804\n",
            "Iteration: 191 \tmse_loss: 0.0571669973\n",
            "Iteration: 192 \tmse_loss: 0.0569986999\n",
            "Iteration: 193 \tmse_loss: 0.0568275489\n",
            "Iteration: 194 \tmse_loss: 0.0566644780\n",
            "Iteration: 195 \tmse_loss: 0.0565062948\n",
            "Iteration: 196 \tmse_loss: 0.0563565455\n",
            "Iteration: 197 \tmse_loss: 0.0562224537\n",
            "Iteration: 198 \tmse_loss: 0.0560929477\n",
            "Final loss \tmse_loss: 0.0560929477\n",
            "Iteration: 0 \tmse_loss: 0.0584336668\n",
            "Test -- Iteration: 0 \tmse_loss: 0.0606568679\n",
            "Iteration: 1 \tmse_loss: 0.0603061058\n",
            "Iteration: 2 \tmse_loss: 0.0594946072\n",
            "Iteration: 3 \tmse_loss: 0.0584220625\n",
            "Iteration: 4 \tmse_loss: 0.0584986359\n",
            "Iteration: 5 \tmse_loss: 0.0581953675\n",
            "Iteration: 6 \tmse_loss: 0.0574845038\n",
            "Iteration: 7 \tmse_loss: 0.0571773201\n",
            "Iteration: 8 \tmse_loss: 0.0570935607\n",
            "Iteration: 9 \tmse_loss: 0.0570308603\n",
            "Iteration: 10 \tmse_loss: 0.0568990558\n",
            "Iteration: 11 \tmse_loss: 0.0566400737\n",
            "Iteration: 12 \tmse_loss: 0.0563708507\n",
            "Iteration: 13 \tmse_loss: 0.0562118813\n",
            "Iteration: 14 \tmse_loss: 0.0561049879\n",
            "Iteration: 15 \tmse_loss: 0.0559946448\n",
            "Iteration: 16 \tmse_loss: 0.0558663346\n",
            "Iteration: 17 \tmse_loss: 0.0557330213\n",
            "Iteration: 18 \tmse_loss: 0.0556212552\n",
            "Iteration: 19 \tmse_loss: 0.0555276908\n",
            "Iteration: 20 \tmse_loss: 0.0587274805\n",
            "Test -- Iteration: 20 \tmse_loss: 0.0587934479\n",
            "Iteration: 21 \tmse_loss: 0.0586760752\n",
            "Iteration: 22 \tmse_loss: 0.0585798360\n",
            "Iteration: 23 \tmse_loss: 0.0584614165\n",
            "Iteration: 24 \tmse_loss: 0.0583258793\n",
            "Iteration: 25 \tmse_loss: 0.0581751801\n",
            "Iteration: 26 \tmse_loss: 0.0580162443\n",
            "Iteration: 27 \tmse_loss: 0.0578570142\n",
            "Iteration: 28 \tmse_loss: 0.0576999970\n",
            "Iteration: 29 \tmse_loss: 0.0575352348\n",
            "Iteration: 30 \tmse_loss: 0.0573581494\n",
            "Iteration: 31 \tmse_loss: 0.0571787991\n",
            "Iteration: 32 \tmse_loss: 0.0570051409\n",
            "Iteration: 33 \tmse_loss: 0.0568393320\n",
            "Iteration: 34 \tmse_loss: 0.0566746220\n",
            "Iteration: 35 \tmse_loss: 0.0565170236\n",
            "Iteration: 36 \tmse_loss: 0.0563744046\n",
            "Iteration: 37 \tmse_loss: 0.0562384799\n",
            "Iteration: 38 \tmse_loss: 0.0561101325\n",
            "Iteration: 39 \tmse_loss: 0.0559837632\n",
            "Iteration: 40 \tmse_loss: 0.0585756600\n",
            "Test -- Iteration: 40 \tmse_loss: 0.0586529709\n",
            "Iteration: 41 \tmse_loss: 0.0585284568\n",
            "Iteration: 42 \tmse_loss: 0.0584373139\n",
            "Iteration: 43 \tmse_loss: 0.0583263412\n",
            "Iteration: 44 \tmse_loss: 0.0582012050\n",
            "Iteration: 45 \tmse_loss: 0.0580672212\n",
            "Iteration: 46 \tmse_loss: 0.0579211861\n",
            "Iteration: 47 \tmse_loss: 0.0577651151\n",
            "Iteration: 48 \tmse_loss: 0.0576086715\n",
            "Iteration: 49 \tmse_loss: 0.0574489199\n",
            "Iteration: 50 \tmse_loss: 0.0572823361\n",
            "Iteration: 51 \tmse_loss: 0.0571137816\n",
            "Iteration: 52 \tmse_loss: 0.0569467545\n",
            "Iteration: 53 \tmse_loss: 0.0567845069\n",
            "Iteration: 54 \tmse_loss: 0.0566298924\n",
            "Iteration: 55 \tmse_loss: 0.0564773604\n",
            "Iteration: 56 \tmse_loss: 0.0563366339\n",
            "Iteration: 57 \tmse_loss: 0.0562070794\n",
            "Iteration: 58 \tmse_loss: 0.0560812280\n",
            "Iteration: 59 \tmse_loss: 0.0559639521\n",
            "Iteration: 60 \tmse_loss: 0.0585084781\n",
            "Test -- Iteration: 60 \tmse_loss: 0.0585921034\n",
            "Iteration: 61 \tmse_loss: 0.0584657751\n",
            "Iteration: 62 \tmse_loss: 0.0583868399\n",
            "Iteration: 63 \tmse_loss: 0.0582854338\n",
            "Iteration: 64 \tmse_loss: 0.0581657067\n",
            "Iteration: 65 \tmse_loss: 0.0580378510\n",
            "Iteration: 66 \tmse_loss: 0.0579010285\n",
            "Iteration: 67 \tmse_loss: 0.0577533394\n",
            "Iteration: 68 \tmse_loss: 0.0576014780\n",
            "Iteration: 69 \tmse_loss: 0.0574431792\n",
            "Iteration: 70 \tmse_loss: 0.0572768077\n",
            "Iteration: 71 \tmse_loss: 0.0571078472\n",
            "Iteration: 72 \tmse_loss: 0.0569423549\n",
            "Iteration: 73 \tmse_loss: 0.0567796193\n",
            "Iteration: 74 \tmse_loss: 0.0566261820\n",
            "Iteration: 75 \tmse_loss: 0.0564809740\n",
            "Iteration: 76 \tmse_loss: 0.0563410670\n",
            "Iteration: 77 \tmse_loss: 0.0562073216\n",
            "Iteration: 78 \tmse_loss: 0.0560845844\n",
            "Iteration: 79 \tmse_loss: 0.0559683964\n",
            "Iteration: 80 \tmse_loss: 0.0584603921\n",
            "Test -- Iteration: 80 \tmse_loss: 0.0585575625\n",
            "Iteration: 81 \tmse_loss: 0.0584121756\n",
            "Iteration: 82 \tmse_loss: 0.0583368763\n",
            "Iteration: 83 \tmse_loss: 0.0582412519\n",
            "Iteration: 84 \tmse_loss: 0.0581299625\n",
            "Iteration: 85 \tmse_loss: 0.0580048598\n",
            "Iteration: 86 \tmse_loss: 0.0578699335\n",
            "Iteration: 87 \tmse_loss: 0.0577309057\n",
            "Iteration: 88 \tmse_loss: 0.0575862229\n",
            "Iteration: 89 \tmse_loss: 0.0574268289\n",
            "Iteration: 90 \tmse_loss: 0.0572640710\n",
            "Iteration: 91 \tmse_loss: 0.0570990294\n",
            "Iteration: 92 \tmse_loss: 0.0569355711\n",
            "Iteration: 93 \tmse_loss: 0.0567808598\n",
            "Iteration: 94 \tmse_loss: 0.0566258505\n",
            "Iteration: 95 \tmse_loss: 0.0564781986\n",
            "Iteration: 96 \tmse_loss: 0.0563415773\n",
            "Iteration: 97 \tmse_loss: 0.0562099367\n",
            "Iteration: 98 \tmse_loss: 0.0560833849\n",
            "Iteration: 99 \tmse_loss: 0.0559710339\n",
            "Iteration: 100 \tmse_loss: 0.0584173910\n",
            "Test -- Iteration: 100 \tmse_loss: 0.0585296005\n",
            "Iteration: 101 \tmse_loss: 0.0583688729\n",
            "Iteration: 102 \tmse_loss: 0.0582915545\n",
            "Iteration: 103 \tmse_loss: 0.0581980199\n",
            "Iteration: 104 \tmse_loss: 0.0580924861\n",
            "Iteration: 105 \tmse_loss: 0.0579738282\n",
            "Iteration: 106 \tmse_loss: 0.0578451306\n",
            "Iteration: 107 \tmse_loss: 0.0577091686\n",
            "Iteration: 108 \tmse_loss: 0.0575652830\n",
            "Iteration: 109 \tmse_loss: 0.0574087612\n",
            "Iteration: 110 \tmse_loss: 0.0572468378\n",
            "Iteration: 111 \tmse_loss: 0.0570903085\n",
            "Iteration: 112 \tmse_loss: 0.0569291934\n",
            "Iteration: 113 \tmse_loss: 0.0567733496\n",
            "Iteration: 114 \tmse_loss: 0.0566227473\n",
            "Iteration: 115 \tmse_loss: 0.0564777330\n",
            "Iteration: 116 \tmse_loss: 0.0563397035\n",
            "Iteration: 117 \tmse_loss: 0.0562111102\n",
            "Iteration: 118 \tmse_loss: 0.0560877435\n",
            "Iteration: 119 \tmse_loss: 0.0559685044\n",
            "Iteration: 120 \tmse_loss: 0.0583826937\n",
            "Test -- Iteration: 120 \tmse_loss: 0.0584949404\n",
            "Iteration: 121 \tmse_loss: 0.0583396554\n",
            "Iteration: 122 \tmse_loss: 0.0582695790\n",
            "Iteration: 123 \tmse_loss: 0.0581792369\n",
            "Iteration: 124 \tmse_loss: 0.0580776259\n",
            "Iteration: 125 \tmse_loss: 0.0579631813\n",
            "Iteration: 126 \tmse_loss: 0.0578434728\n",
            "Iteration: 127 \tmse_loss: 0.0577100329\n",
            "Iteration: 128 \tmse_loss: 0.0575647131\n",
            "Iteration: 129 \tmse_loss: 0.0574149899\n",
            "Iteration: 130 \tmse_loss: 0.0572590530\n",
            "Iteration: 131 \tmse_loss: 0.0571022220\n",
            "Iteration: 132 \tmse_loss: 0.0569472834\n",
            "Iteration: 133 \tmse_loss: 0.0567954443\n",
            "Iteration: 134 \tmse_loss: 0.0566448309\n",
            "Iteration: 135 \tmse_loss: 0.0565038323\n",
            "Iteration: 136 \tmse_loss: 0.0563676581\n",
            "Iteration: 137 \tmse_loss: 0.0562333129\n",
            "Iteration: 138 \tmse_loss: 0.0561125241\n",
            "Iteration: 139 \tmse_loss: 0.0559982546\n",
            "Iteration: 140 \tmse_loss: 0.0583479218\n",
            "Test -- Iteration: 140 \tmse_loss: 0.0584550612\n",
            "Iteration: 141 \tmse_loss: 0.0583029799\n",
            "Iteration: 142 \tmse_loss: 0.0582391843\n",
            "Iteration: 143 \tmse_loss: 0.0581550710\n",
            "Iteration: 144 \tmse_loss: 0.0580569804\n",
            "Iteration: 145 \tmse_loss: 0.0579493344\n",
            "Iteration: 146 \tmse_loss: 0.0578316115\n",
            "Iteration: 147 \tmse_loss: 0.0577016287\n",
            "Iteration: 148 \tmse_loss: 0.0575591624\n",
            "Iteration: 149 \tmse_loss: 0.0574108362\n",
            "Iteration: 150 \tmse_loss: 0.0572634935\n",
            "Iteration: 151 \tmse_loss: 0.0571099892\n",
            "Iteration: 152 \tmse_loss: 0.0569549836\n",
            "Iteration: 153 \tmse_loss: 0.0568116121\n",
            "Iteration: 154 \tmse_loss: 0.0566696152\n",
            "Iteration: 155 \tmse_loss: 0.0565257445\n",
            "Iteration: 156 \tmse_loss: 0.0563904308\n",
            "Iteration: 157 \tmse_loss: 0.0562632233\n",
            "Iteration: 158 \tmse_loss: 0.0561426766\n",
            "Iteration: 159 \tmse_loss: 0.0560293794\n",
            "Iteration: 160 \tmse_loss: 0.0583112650\n",
            "Test -- Iteration: 160 \tmse_loss: 0.0584152192\n",
            "Iteration: 161 \tmse_loss: 0.0582657792\n",
            "Iteration: 162 \tmse_loss: 0.0582078062\n",
            "Iteration: 163 \tmse_loss: 0.0581296235\n",
            "Iteration: 164 \tmse_loss: 0.0580344498\n",
            "Iteration: 165 \tmse_loss: 0.0579286478\n",
            "Iteration: 166 \tmse_loss: 0.0578139499\n",
            "Iteration: 167 \tmse_loss: 0.0576842502\n",
            "Iteration: 168 \tmse_loss: 0.0575458817\n",
            "Iteration: 169 \tmse_loss: 0.0574014336\n",
            "Iteration: 170 \tmse_loss: 0.0572561584\n",
            "Iteration: 171 \tmse_loss: 0.0571048260\n",
            "Iteration: 172 \tmse_loss: 0.0569563434\n",
            "Iteration: 173 \tmse_loss: 0.0568127334\n",
            "Iteration: 174 \tmse_loss: 0.0566715263\n",
            "Iteration: 175 \tmse_loss: 0.0565313250\n",
            "Iteration: 176 \tmse_loss: 0.0563974082\n",
            "Iteration: 177 \tmse_loss: 0.0562708825\n",
            "Iteration: 178 \tmse_loss: 0.0561526902\n",
            "Iteration: 179 \tmse_loss: 0.0560379364\n",
            "Iteration: 180 \tmse_loss: 0.0583390109\n",
            "Test -- Iteration: 180 \tmse_loss: 0.0583768561\n",
            "Iteration: 181 \tmse_loss: 0.0582940876\n",
            "Iteration: 182 \tmse_loss: 0.0582370348\n",
            "Iteration: 183 \tmse_loss: 0.0581615046\n",
            "Iteration: 184 \tmse_loss: 0.0580647253\n",
            "Iteration: 185 \tmse_loss: 0.0579620786\n",
            "Iteration: 186 \tmse_loss: 0.0578562804\n",
            "Iteration: 187 \tmse_loss: 0.0577270761\n",
            "Iteration: 188 \tmse_loss: 0.0575874746\n",
            "Iteration: 189 \tmse_loss: 0.0574516840\n",
            "Iteration: 190 \tmse_loss: 0.0573076755\n",
            "Iteration: 191 \tmse_loss: 0.0571577549\n",
            "Iteration: 192 \tmse_loss: 0.0570139401\n",
            "Iteration: 193 \tmse_loss: 0.0568729900\n",
            "Iteration: 194 \tmse_loss: 0.0567323044\n",
            "Iteration: 195 \tmse_loss: 0.0565937869\n",
            "Iteration: 196 \tmse_loss: 0.0564588606\n",
            "Iteration: 197 \tmse_loss: 0.0563341565\n",
            "Iteration: 198 \tmse_loss: 0.0562165268\n",
            "Final loss \tmse_loss: 0.0562165268\n",
            "Iteration: 0 \tmse_loss: 0.0581647083\n",
            "Test -- Iteration: 0 \tmse_loss: 0.0611804053\n",
            "Iteration: 1 \tmse_loss: 0.0608251132\n",
            "Iteration: 2 \tmse_loss: 0.0598142333\n",
            "Iteration: 3 \tmse_loss: 0.0585626736\n",
            "Iteration: 4 \tmse_loss: 0.0587420948\n",
            "Iteration: 5 \tmse_loss: 0.0584914349\n",
            "Iteration: 6 \tmse_loss: 0.0576372892\n",
            "Iteration: 7 \tmse_loss: 0.0573342219\n",
            "Iteration: 8 \tmse_loss: 0.0573028550\n",
            "Iteration: 9 \tmse_loss: 0.0572993346\n",
            "Iteration: 10 \tmse_loss: 0.0571861304\n",
            "Iteration: 11 \tmse_loss: 0.0569043532\n",
            "Iteration: 12 \tmse_loss: 0.0566040725\n",
            "Iteration: 13 \tmse_loss: 0.0564313680\n",
            "Iteration: 14 \tmse_loss: 0.0563269630\n",
            "Iteration: 15 \tmse_loss: 0.0562244877\n",
            "Iteration: 16 \tmse_loss: 0.0560956001\n",
            "Iteration: 17 \tmse_loss: 0.0559538677\n",
            "Iteration: 18 \tmse_loss: 0.0558325946\n",
            "Iteration: 19 \tmse_loss: 0.0557296500\n",
            "Iteration: 20 \tmse_loss: 0.0584328137\n",
            "Test -- Iteration: 20 \tmse_loss: 0.0585455224\n",
            "Iteration: 21 \tmse_loss: 0.0583955646\n",
            "Iteration: 22 \tmse_loss: 0.0583298020\n",
            "Iteration: 23 \tmse_loss: 0.0582368560\n",
            "Iteration: 24 \tmse_loss: 0.0581289642\n",
            "Iteration: 25 \tmse_loss: 0.0580082759\n",
            "Iteration: 26 \tmse_loss: 0.0578838922\n",
            "Iteration: 27 \tmse_loss: 0.0577578098\n",
            "Iteration: 28 \tmse_loss: 0.0576237589\n",
            "Iteration: 29 \tmse_loss: 0.0574844442\n",
            "Iteration: 30 \tmse_loss: 0.0573430769\n",
            "Iteration: 31 \tmse_loss: 0.0571971387\n",
            "Iteration: 32 \tmse_loss: 0.0570462793\n",
            "Iteration: 33 \tmse_loss: 0.0568973273\n",
            "Iteration: 34 \tmse_loss: 0.0567540117\n",
            "Iteration: 35 \tmse_loss: 0.0566185974\n",
            "Iteration: 36 \tmse_loss: 0.0564908087\n",
            "Iteration: 37 \tmse_loss: 0.0563660525\n",
            "Iteration: 38 \tmse_loss: 0.0562438779\n",
            "Iteration: 39 \tmse_loss: 0.0561265759\n",
            "Iteration: 40 \tmse_loss: 0.0582998991\n",
            "Test -- Iteration: 40 \tmse_loss: 0.0584152602\n",
            "Iteration: 41 \tmse_loss: 0.0582566634\n",
            "Iteration: 42 \tmse_loss: 0.0581818298\n",
            "Iteration: 43 \tmse_loss: 0.0580979623\n",
            "Iteration: 44 \tmse_loss: 0.0580019206\n",
            "Iteration: 45 \tmse_loss: 0.0578942038\n",
            "Iteration: 46 \tmse_loss: 0.0577737093\n",
            "Iteration: 47 \tmse_loss: 0.0576473549\n",
            "Iteration: 48 \tmse_loss: 0.0575210527\n",
            "Iteration: 49 \tmse_loss: 0.0573872514\n",
            "Iteration: 50 \tmse_loss: 0.0572471172\n",
            "Iteration: 51 \tmse_loss: 0.0571071915\n",
            "Iteration: 52 \tmse_loss: 0.0569658615\n",
            "Iteration: 53 \tmse_loss: 0.0568250939\n",
            "Iteration: 54 \tmse_loss: 0.0566902794\n",
            "Iteration: 55 \tmse_loss: 0.0565598048\n",
            "Iteration: 56 \tmse_loss: 0.0564273186\n",
            "Iteration: 57 \tmse_loss: 0.0563062243\n",
            "Iteration: 58 \tmse_loss: 0.0561902858\n",
            "Iteration: 59 \tmse_loss: 0.0560802557\n",
            "Iteration: 60 \tmse_loss: 0.0582358949\n",
            "Test -- Iteration: 60 \tmse_loss: 0.0583626404\n",
            "Iteration: 61 \tmse_loss: 0.0582025275\n",
            "Iteration: 62 \tmse_loss: 0.0581388958\n",
            "Iteration: 63 \tmse_loss: 0.0580620319\n",
            "Iteration: 64 \tmse_loss: 0.0579686128\n",
            "Iteration: 65 \tmse_loss: 0.0578629337\n",
            "Iteration: 66 \tmse_loss: 0.0577493794\n",
            "Iteration: 67 \tmse_loss: 0.0576296337\n",
            "Iteration: 68 \tmse_loss: 0.0575062409\n",
            "Iteration: 69 \tmse_loss: 0.0573753752\n",
            "Iteration: 70 \tmse_loss: 0.0572347008\n",
            "Iteration: 71 \tmse_loss: 0.0570930988\n",
            "Iteration: 72 \tmse_loss: 0.0569538958\n",
            "Iteration: 73 \tmse_loss: 0.0568118617\n",
            "Iteration: 74 \tmse_loss: 0.0566725023\n",
            "Iteration: 75 \tmse_loss: 0.0565420724\n",
            "Iteration: 76 \tmse_loss: 0.0564163700\n",
            "Iteration: 77 \tmse_loss: 0.0562957004\n",
            "Iteration: 78 \tmse_loss: 0.0561801679\n",
            "Iteration: 79 \tmse_loss: 0.0560709275\n",
            "Iteration: 80 \tmse_loss: 0.0581996068\n",
            "Test -- Iteration: 80 \tmse_loss: 0.0583460219\n",
            "Iteration: 81 \tmse_loss: 0.0581645630\n",
            "Iteration: 82 \tmse_loss: 0.0581023358\n",
            "Iteration: 83 \tmse_loss: 0.0580247417\n",
            "Iteration: 84 \tmse_loss: 0.0579331107\n",
            "Iteration: 85 \tmse_loss: 0.0578348786\n",
            "Iteration: 86 \tmse_loss: 0.0577258691\n",
            "Iteration: 87 \tmse_loss: 0.0576124638\n",
            "Iteration: 88 \tmse_loss: 0.0574880987\n",
            "Iteration: 89 \tmse_loss: 0.0573539063\n",
            "Iteration: 90 \tmse_loss: 0.0572204702\n",
            "Iteration: 91 \tmse_loss: 0.0570828468\n",
            "Iteration: 92 \tmse_loss: 0.0569384992\n",
            "Iteration: 93 \tmse_loss: 0.0568016917\n",
            "Iteration: 94 \tmse_loss: 0.0566660576\n",
            "Iteration: 95 \tmse_loss: 0.0565348417\n",
            "Iteration: 96 \tmse_loss: 0.0564100631\n",
            "Iteration: 97 \tmse_loss: 0.0562935472\n",
            "Iteration: 98 \tmse_loss: 0.0561765768\n",
            "Iteration: 99 \tmse_loss: 0.0560668707\n",
            "Iteration: 100 \tmse_loss: 0.0581773035\n",
            "Test -- Iteration: 100 \tmse_loss: 0.0583299845\n",
            "Iteration: 101 \tmse_loss: 0.0581364892\n",
            "Iteration: 102 \tmse_loss: 0.0580761358\n",
            "Iteration: 103 \tmse_loss: 0.0579980165\n",
            "Iteration: 104 \tmse_loss: 0.0579104312\n",
            "Iteration: 105 \tmse_loss: 0.0578147843\n",
            "Iteration: 106 \tmse_loss: 0.0577075072\n",
            "Iteration: 107 \tmse_loss: 0.0575950108\n",
            "Iteration: 108 \tmse_loss: 0.0574766733\n",
            "Iteration: 109 \tmse_loss: 0.0573446602\n",
            "Iteration: 110 \tmse_loss: 0.0572059564\n",
            "Iteration: 111 \tmse_loss: 0.0570686571\n",
            "Iteration: 112 \tmse_loss: 0.0569269992\n",
            "Iteration: 113 \tmse_loss: 0.0567878447\n",
            "Iteration: 114 \tmse_loss: 0.0566551052\n",
            "Iteration: 115 \tmse_loss: 0.0565236248\n",
            "Iteration: 116 \tmse_loss: 0.0564005971\n",
            "Iteration: 117 \tmse_loss: 0.0562888421\n",
            "Iteration: 118 \tmse_loss: 0.0561721623\n",
            "Iteration: 119 \tmse_loss: 0.0560570247\n",
            "Iteration: 120 \tmse_loss: 0.0581598170\n",
            "Test -- Iteration: 120 \tmse_loss: 0.0583067536\n",
            "Iteration: 121 \tmse_loss: 0.0581186190\n",
            "Iteration: 122 \tmse_loss: 0.0580589734\n",
            "Iteration: 123 \tmse_loss: 0.0579884127\n",
            "Iteration: 124 \tmse_loss: 0.0579018407\n",
            "Iteration: 125 \tmse_loss: 0.0578106642\n",
            "Iteration: 126 \tmse_loss: 0.0577123910\n",
            "Iteration: 127 \tmse_loss: 0.0576009862\n",
            "Iteration: 128 \tmse_loss: 0.0574786849\n",
            "Iteration: 129 \tmse_loss: 0.0573494248\n",
            "Iteration: 130 \tmse_loss: 0.0572140440\n",
            "Iteration: 131 \tmse_loss: 0.0570789911\n",
            "Iteration: 132 \tmse_loss: 0.0569433197\n",
            "Iteration: 133 \tmse_loss: 0.0568053052\n",
            "Iteration: 134 \tmse_loss: 0.0566753931\n",
            "Iteration: 135 \tmse_loss: 0.0565500297\n",
            "Iteration: 136 \tmse_loss: 0.0564271398\n",
            "Iteration: 137 \tmse_loss: 0.0563079678\n",
            "Iteration: 138 \tmse_loss: 0.0561933070\n",
            "Iteration: 139 \tmse_loss: 0.0560829714\n",
            "Iteration: 140 \tmse_loss: 0.0581421480\n",
            "Test -- Iteration: 140 \tmse_loss: 0.0582828410\n",
            "Iteration: 141 \tmse_loss: 0.0581011400\n",
            "Iteration: 142 \tmse_loss: 0.0580430776\n",
            "Iteration: 143 \tmse_loss: 0.0579761565\n",
            "Iteration: 144 \tmse_loss: 0.0578981303\n",
            "Iteration: 145 \tmse_loss: 0.0578048825\n",
            "Iteration: 146 \tmse_loss: 0.0577074625\n",
            "Iteration: 147 \tmse_loss: 0.0576039143\n",
            "Iteration: 148 \tmse_loss: 0.0574817993\n",
            "Iteration: 149 \tmse_loss: 0.0573523156\n",
            "Iteration: 150 \tmse_loss: 0.0572226867\n",
            "Iteration: 151 \tmse_loss: 0.0570886694\n",
            "Iteration: 152 \tmse_loss: 0.0569559671\n",
            "Iteration: 153 \tmse_loss: 0.0568245873\n",
            "Iteration: 154 \tmse_loss: 0.0566937402\n",
            "Iteration: 155 \tmse_loss: 0.0565677136\n",
            "Iteration: 156 \tmse_loss: 0.0564475842\n",
            "Iteration: 157 \tmse_loss: 0.0563297793\n",
            "Iteration: 158 \tmse_loss: 0.0562149994\n",
            "Iteration: 159 \tmse_loss: 0.0561096109\n",
            "Iteration: 160 \tmse_loss: 0.0581197999\n",
            "Test -- Iteration: 160 \tmse_loss: 0.0582548976\n",
            "Iteration: 161 \tmse_loss: 0.0580787957\n",
            "Iteration: 162 \tmse_loss: 0.0580282770\n",
            "Iteration: 163 \tmse_loss: 0.0579597354\n",
            "Iteration: 164 \tmse_loss: 0.0578826219\n",
            "Iteration: 165 \tmse_loss: 0.0577940866\n",
            "Iteration: 166 \tmse_loss: 0.0576971546\n",
            "Iteration: 167 \tmse_loss: 0.0575915463\n",
            "Iteration: 168 \tmse_loss: 0.0574754849\n",
            "Iteration: 169 \tmse_loss: 0.0573487431\n",
            "Iteration: 170 \tmse_loss: 0.0572214685\n",
            "Iteration: 171 \tmse_loss: 0.0570914485\n",
            "Iteration: 172 \tmse_loss: 0.0569559820\n",
            "Iteration: 173 \tmse_loss: 0.0568288974\n",
            "Iteration: 174 \tmse_loss: 0.0567024872\n",
            "Iteration: 175 \tmse_loss: 0.0565738492\n",
            "Iteration: 176 \tmse_loss: 0.0564522669\n",
            "Iteration: 177 \tmse_loss: 0.0563383028\n",
            "Iteration: 178 \tmse_loss: 0.0562237576\n",
            "Iteration: 179 \tmse_loss: 0.0561183877\n",
            "Iteration: 180 \tmse_loss: 0.0581743680\n",
            "Test -- Iteration: 180 \tmse_loss: 0.0582275167\n",
            "Iteration: 181 \tmse_loss: 0.0581284650\n",
            "Iteration: 182 \tmse_loss: 0.0580749214\n",
            "Iteration: 183 \tmse_loss: 0.0580107048\n",
            "Iteration: 184 \tmse_loss: 0.0579281896\n",
            "Iteration: 185 \tmse_loss: 0.0578433238\n",
            "Iteration: 186 \tmse_loss: 0.0577545203\n",
            "Iteration: 187 \tmse_loss: 0.0576436073\n",
            "Iteration: 188 \tmse_loss: 0.0575262345\n",
            "Iteration: 189 \tmse_loss: 0.0574114025\n",
            "Iteration: 190 \tmse_loss: 0.0572789721\n",
            "Iteration: 191 \tmse_loss: 0.0571451150\n",
            "Iteration: 192 \tmse_loss: 0.0570163690\n",
            "Iteration: 193 \tmse_loss: 0.0568858683\n",
            "Iteration: 194 \tmse_loss: 0.0567585677\n",
            "Iteration: 195 \tmse_loss: 0.0566352122\n",
            "Iteration: 196 \tmse_loss: 0.0565149672\n",
            "Iteration: 197 \tmse_loss: 0.0564025715\n",
            "Iteration: 198 \tmse_loss: 0.0562953055\n",
            "Final loss \tmse_loss: 0.0562953055\n",
            "Iteration: 0 \tmse_loss: 2.0237941742\n",
            "Test -- Iteration: 0 \tmse_loss: 1.8720678091\n",
            "Iteration: 1 \tmse_loss: 1.8719099760\n",
            "Iteration: 2 \tmse_loss: 1.7293158770\n",
            "Iteration: 3 \tmse_loss: 1.5968075991\n",
            "Iteration: 4 \tmse_loss: 1.4746662378\n",
            "Iteration: 5 \tmse_loss: 1.3617402315\n",
            "Iteration: 6 \tmse_loss: 1.2572002411\n",
            "Iteration: 7 \tmse_loss: 1.1608675718\n",
            "Iteration: 8 \tmse_loss: 1.0728914738\n",
            "Iteration: 9 \tmse_loss: 0.9924800396\n",
            "Iteration: 10 \tmse_loss: 0.9187785983\n",
            "Iteration: 11 \tmse_loss: 0.8515977263\n",
            "Iteration: 12 \tmse_loss: 0.7904917598\n",
            "Iteration: 13 \tmse_loss: 0.7349609137\n",
            "Iteration: 14 \tmse_loss: 0.6843613982\n",
            "Iteration: 15 \tmse_loss: 0.6384620667\n",
            "Iteration: 16 \tmse_loss: 0.5969245434\n",
            "Iteration: 17 \tmse_loss: 0.5592743754\n",
            "Iteration: 18 \tmse_loss: 0.5250292420\n",
            "Iteration: 19 \tmse_loss: 0.4937256277\n",
            "Iteration: 20 \tmse_loss: 0.4655078351\n",
            "Test -- Iteration: 20 \tmse_loss: 0.4393226802\n",
            "Iteration: 21 \tmse_loss: 0.4392965436\n",
            "Iteration: 22 \tmse_loss: 0.4152595103\n",
            "Iteration: 23 \tmse_loss: 0.3932267129\n",
            "Iteration: 24 \tmse_loss: 0.3730550110\n",
            "Iteration: 25 \tmse_loss: 0.3545608819\n",
            "Iteration: 26 \tmse_loss: 0.3375531137\n",
            "Iteration: 27 \tmse_loss: 0.3219498694\n",
            "Iteration: 28 \tmse_loss: 0.3076305389\n",
            "Iteration: 29 \tmse_loss: 0.2944531143\n",
            "Iteration: 30 \tmse_loss: 0.2823095918\n",
            "Iteration: 31 \tmse_loss: 0.2710995674\n",
            "Iteration: 32 \tmse_loss: 0.2607227266\n",
            "Iteration: 33 \tmse_loss: 0.2511025667\n",
            "Iteration: 34 \tmse_loss: 0.2421898842\n",
            "Iteration: 35 \tmse_loss: 0.2339164317\n",
            "Iteration: 36 \tmse_loss: 0.2262094766\n",
            "Iteration: 37 \tmse_loss: 0.2190364897\n",
            "Iteration: 38 \tmse_loss: 0.2123481035\n",
            "Iteration: 39 \tmse_loss: 0.2061054856\n",
            "Iteration: 40 \tmse_loss: 0.2013532519\n",
            "Test -- Iteration: 40 \tmse_loss: 0.1959564835\n",
            "Iteration: 41 \tmse_loss: 0.1959177554\n",
            "Iteration: 42 \tmse_loss: 0.1908086389\n",
            "Iteration: 43 \tmse_loss: 0.1860180050\n",
            "Iteration: 44 \tmse_loss: 0.1815150380\n",
            "Iteration: 45 \tmse_loss: 0.1772880554\n",
            "Iteration: 46 \tmse_loss: 0.1733100861\n",
            "Iteration: 47 \tmse_loss: 0.1695545763\n",
            "Iteration: 48 \tmse_loss: 0.1660106331\n",
            "Iteration: 49 \tmse_loss: 0.1626690030\n",
            "Iteration: 50 \tmse_loss: 0.1595107615\n",
            "Iteration: 51 \tmse_loss: 0.1565246582\n",
            "Iteration: 52 \tmse_loss: 0.1537024975\n",
            "Iteration: 53 \tmse_loss: 0.1510313451\n",
            "Iteration: 54 \tmse_loss: 0.1484994441\n",
            "Iteration: 55 \tmse_loss: 0.1460942775\n",
            "Iteration: 56 \tmse_loss: 0.1438098401\n",
            "Iteration: 57 \tmse_loss: 0.1416385472\n",
            "Iteration: 58 \tmse_loss: 0.1395712644\n",
            "Iteration: 59 \tmse_loss: 0.1376045346\n",
            "Iteration: 60 \tmse_loss: 0.1362760812\n",
            "Test -- Iteration: 60 \tmse_loss: 0.1345017403\n",
            "Iteration: 61 \tmse_loss: 0.1345119029\n",
            "Iteration: 62 \tmse_loss: 0.1328244209\n",
            "Iteration: 63 \tmse_loss: 0.1312101036\n",
            "Iteration: 64 \tmse_loss: 0.1296648979\n",
            "Iteration: 65 \tmse_loss: 0.1281862855\n",
            "Iteration: 66 \tmse_loss: 0.1267704517\n",
            "Iteration: 67 \tmse_loss: 0.1254114807\n",
            "Iteration: 68 \tmse_loss: 0.1241079569\n",
            "Iteration: 69 \tmse_loss: 0.1228558049\n",
            "Iteration: 70 \tmse_loss: 0.1216515973\n",
            "Iteration: 71 \tmse_loss: 0.1204934642\n",
            "Iteration: 72 \tmse_loss: 0.1193787381\n",
            "Iteration: 73 \tmse_loss: 0.1183054745\n",
            "Iteration: 74 \tmse_loss: 0.1172722802\n",
            "Iteration: 75 \tmse_loss: 0.1162782088\n",
            "Iteration: 76 \tmse_loss: 0.1153225228\n",
            "Iteration: 77 \tmse_loss: 0.1144024953\n",
            "Iteration: 78 \tmse_loss: 0.1135138944\n",
            "Iteration: 79 \tmse_loss: 0.1126545519\n",
            "Iteration: 80 \tmse_loss: 0.1121466383\n",
            "Test -- Iteration: 80 \tmse_loss: 0.1113752648\n",
            "Iteration: 81 \tmse_loss: 0.1113646924\n",
            "Iteration: 82 \tmse_loss: 0.1106058806\n",
            "Iteration: 83 \tmse_loss: 0.1098701730\n",
            "Iteration: 84 \tmse_loss: 0.1091565713\n",
            "Iteration: 85 \tmse_loss: 0.1084643900\n",
            "Iteration: 86 \tmse_loss: 0.1077934727\n",
            "Iteration: 87 \tmse_loss: 0.1071432158\n",
            "Iteration: 88 \tmse_loss: 0.1065116599\n",
            "Iteration: 89 \tmse_loss: 0.1058979407\n",
            "Iteration: 90 \tmse_loss: 0.1053004712\n",
            "Iteration: 91 \tmse_loss: 0.1047193110\n",
            "Iteration: 92 \tmse_loss: 0.1041552499\n",
            "Iteration: 93 \tmse_loss: 0.1036066040\n",
            "Iteration: 94 \tmse_loss: 0.1030730680\n",
            "Iteration: 95 \tmse_loss: 0.1025534123\n",
            "Iteration: 96 \tmse_loss: 0.1020463333\n",
            "Iteration: 97 \tmse_loss: 0.1015519276\n",
            "Iteration: 98 \tmse_loss: 0.1010700688\n",
            "Iteration: 99 \tmse_loss: 0.1006003991\n",
            "Iteration: 100 \tmse_loss: 0.1004131287\n",
            "Test -- Iteration: 100 \tmse_loss: 0.0999896824\n",
            "Iteration: 101 \tmse_loss: 0.0999793336\n",
            "Iteration: 102 \tmse_loss: 0.0995526984\n",
            "Iteration: 103 \tmse_loss: 0.0991339311\n",
            "Iteration: 104 \tmse_loss: 0.0987227485\n",
            "Iteration: 105 \tmse_loss: 0.0983199999\n",
            "Iteration: 106 \tmse_loss: 0.0979242846\n",
            "Iteration: 107 \tmse_loss: 0.0975355506\n",
            "Iteration: 108 \tmse_loss: 0.0971542299\n",
            "Iteration: 109 \tmse_loss: 0.0967794135\n",
            "Iteration: 110 \tmse_loss: 0.0964113474\n",
            "Iteration: 111 \tmse_loss: 0.0960500389\n",
            "Iteration: 112 \tmse_loss: 0.0956956819\n",
            "Iteration: 113 \tmse_loss: 0.0953472331\n",
            "Iteration: 114 \tmse_loss: 0.0950045139\n",
            "Iteration: 115 \tmse_loss: 0.0946677178\n",
            "Iteration: 116 \tmse_loss: 0.0943368450\n",
            "Iteration: 117 \tmse_loss: 0.0940114111\n",
            "Iteration: 118 \tmse_loss: 0.0936914012\n",
            "Iteration: 119 \tmse_loss: 0.0933767334\n",
            "Iteration: 120 \tmse_loss: 0.0932644755\n",
            "Test -- Iteration: 120 \tmse_loss: 0.0930403098\n",
            "Iteration: 121 \tmse_loss: 0.0929738656\n",
            "Iteration: 122 \tmse_loss: 0.0926857740\n",
            "Iteration: 123 \tmse_loss: 0.0924009010\n",
            "Iteration: 124 \tmse_loss: 0.0921189338\n",
            "Iteration: 125 \tmse_loss: 0.0918402821\n",
            "Iteration: 126 \tmse_loss: 0.0915648565\n",
            "Iteration: 127 \tmse_loss: 0.0912928656\n",
            "Iteration: 128 \tmse_loss: 0.0910237879\n",
            "Iteration: 129 \tmse_loss: 0.0907578319\n",
            "Iteration: 130 \tmse_loss: 0.0904953033\n",
            "Iteration: 131 \tmse_loss: 0.0902358368\n",
            "Iteration: 132 \tmse_loss: 0.0899793431\n",
            "Iteration: 133 \tmse_loss: 0.0897258520\n",
            "Iteration: 134 \tmse_loss: 0.0894754231\n",
            "Iteration: 135 \tmse_loss: 0.0892281979\n",
            "Iteration: 136 \tmse_loss: 0.0889839232\n",
            "Iteration: 137 \tmse_loss: 0.0887424573\n",
            "Iteration: 138 \tmse_loss: 0.0885040835\n",
            "Iteration: 139 \tmse_loss: 0.0882687047\n",
            "Iteration: 140 \tmse_loss: 0.0883709937\n",
            "Test -- Iteration: 140 \tmse_loss: 0.0881328434\n",
            "Iteration: 141 \tmse_loss: 0.0881556794\n",
            "Iteration: 142 \tmse_loss: 0.0879413709\n",
            "Iteration: 143 \tmse_loss: 0.0877281055\n",
            "Iteration: 144 \tmse_loss: 0.0875160024\n",
            "Iteration: 145 \tmse_loss: 0.0873052254\n",
            "Iteration: 146 \tmse_loss: 0.0870959014\n",
            "Iteration: 147 \tmse_loss: 0.0868879631\n",
            "Iteration: 148 \tmse_loss: 0.0866813362\n",
            "Iteration: 149 \tmse_loss: 0.0864761919\n",
            "Iteration: 150 \tmse_loss: 0.0862727016\n",
            "Iteration: 151 \tmse_loss: 0.0860709697\n",
            "Iteration: 152 \tmse_loss: 0.0858710036\n",
            "Iteration: 153 \tmse_loss: 0.0856726393\n",
            "Iteration: 154 \tmse_loss: 0.0854762122\n",
            "Iteration: 155 \tmse_loss: 0.0852814987\n",
            "Iteration: 156 \tmse_loss: 0.0850885957\n",
            "Iteration: 157 \tmse_loss: 0.0848975331\n",
            "Iteration: 158 \tmse_loss: 0.0847081318\n",
            "Iteration: 159 \tmse_loss: 0.0845205411\n",
            "Iteration: 160 \tmse_loss: 0.0845358372\n",
            "Test -- Iteration: 160 \tmse_loss: 0.0843824744\n",
            "Iteration: 161 \tmse_loss: 0.0843664706\n",
            "Iteration: 162 \tmse_loss: 0.0841971934\n",
            "Iteration: 163 \tmse_loss: 0.0840280354\n",
            "Iteration: 164 \tmse_loss: 0.0838591382\n",
            "Iteration: 165 \tmse_loss: 0.0836906433\n",
            "Iteration: 166 \tmse_loss: 0.0835225657\n",
            "Iteration: 167 \tmse_loss: 0.0833551660\n",
            "Iteration: 168 \tmse_loss: 0.0831885785\n",
            "Iteration: 169 \tmse_loss: 0.0830227509\n",
            "Iteration: 170 \tmse_loss: 0.0828578249\n",
            "Iteration: 171 \tmse_loss: 0.0826936588\n",
            "Iteration: 172 \tmse_loss: 0.0825304836\n",
            "Iteration: 173 \tmse_loss: 0.0823682770\n",
            "Iteration: 174 \tmse_loss: 0.0822071806\n",
            "Iteration: 175 \tmse_loss: 0.0820471942\n",
            "Iteration: 176 \tmse_loss: 0.0818883181\n",
            "Iteration: 177 \tmse_loss: 0.0817305446\n",
            "Iteration: 178 \tmse_loss: 0.0815739259\n",
            "Iteration: 179 \tmse_loss: 0.0814185217\n",
            "Iteration: 180 \tmse_loss: 0.0815146193\n",
            "Test -- Iteration: 180 \tmse_loss: 0.0813772604\n",
            "Iteration: 181 \tmse_loss: 0.0813760757\n",
            "Iteration: 182 \tmse_loss: 0.0812370703\n",
            "Iteration: 183 \tmse_loss: 0.0810976252\n",
            "Iteration: 184 \tmse_loss: 0.0809578300\n",
            "Iteration: 185 \tmse_loss: 0.0808178857\n",
            "Iteration: 186 \tmse_loss: 0.0806779042\n",
            "Iteration: 187 \tmse_loss: 0.0805379227\n",
            "Iteration: 188 \tmse_loss: 0.0803984776\n",
            "Iteration: 189 \tmse_loss: 0.0802592263\n",
            "Iteration: 190 \tmse_loss: 0.0801203772\n",
            "Iteration: 191 \tmse_loss: 0.0799819529\n",
            "Iteration: 192 \tmse_loss: 0.0798441023\n",
            "Iteration: 193 \tmse_loss: 0.0797067508\n",
            "Iteration: 194 \tmse_loss: 0.0795701891\n",
            "Iteration: 195 \tmse_loss: 0.0794342831\n",
            "Iteration: 196 \tmse_loss: 0.0792990401\n",
            "Iteration: 197 \tmse_loss: 0.0791645050\n",
            "Iteration: 198 \tmse_loss: 0.0790308118\n",
            "Final loss \tmse_loss: 0.0790308118\n",
            "Iteration: 0 \tmse_loss: 0.0794793069\n",
            "Test -- Iteration: 0 \tmse_loss: 0.0764731616\n",
            "Iteration: 1 \tmse_loss: 0.0764130801\n",
            "Iteration: 2 \tmse_loss: 0.0725645274\n",
            "Iteration: 3 \tmse_loss: 0.0696605667\n",
            "Iteration: 4 \tmse_loss: 0.0676388517\n",
            "Iteration: 5 \tmse_loss: 0.0664701611\n",
            "Iteration: 6 \tmse_loss: 0.0654902533\n",
            "Iteration: 7 \tmse_loss: 0.0645886809\n",
            "Iteration: 8 \tmse_loss: 0.0638682917\n",
            "Iteration: 9 \tmse_loss: 0.0633575171\n",
            "Iteration: 10 \tmse_loss: 0.0629654601\n",
            "Iteration: 11 \tmse_loss: 0.0626332834\n",
            "Iteration: 12 \tmse_loss: 0.0623522252\n",
            "Iteration: 13 \tmse_loss: 0.0621124692\n",
            "Iteration: 14 \tmse_loss: 0.0618749075\n",
            "Iteration: 15 \tmse_loss: 0.0616298094\n",
            "Iteration: 16 \tmse_loss: 0.0613862015\n",
            "Iteration: 17 \tmse_loss: 0.0611459091\n",
            "Iteration: 18 \tmse_loss: 0.0609090514\n",
            "Iteration: 19 \tmse_loss: 0.0606869049\n",
            "Iteration: 20 \tmse_loss: 0.0646350086\n",
            "Test -- Iteration: 20 \tmse_loss: 0.0644375533\n",
            "Iteration: 21 \tmse_loss: 0.0643512011\n",
            "Iteration: 22 \tmse_loss: 0.0639534146\n",
            "Iteration: 23 \tmse_loss: 0.0635118708\n",
            "Iteration: 24 \tmse_loss: 0.0630519986\n",
            "Iteration: 25 \tmse_loss: 0.0625908598\n",
            "Iteration: 26 \tmse_loss: 0.0621324442\n",
            "Iteration: 27 \tmse_loss: 0.0616918430\n",
            "Iteration: 28 \tmse_loss: 0.0612714104\n",
            "Iteration: 29 \tmse_loss: 0.0608715937\n",
            "Iteration: 30 \tmse_loss: 0.0604997538\n",
            "Iteration: 31 \tmse_loss: 0.0601575747\n",
            "Iteration: 32 \tmse_loss: 0.0598402917\n",
            "Iteration: 33 \tmse_loss: 0.0595436022\n",
            "Iteration: 34 \tmse_loss: 0.0592589527\n",
            "Iteration: 35 \tmse_loss: 0.0589885190\n",
            "Iteration: 36 \tmse_loss: 0.0587344691\n",
            "Iteration: 37 \tmse_loss: 0.0584929883\n",
            "Iteration: 38 \tmse_loss: 0.0582631342\n",
            "Iteration: 39 \tmse_loss: 0.0580511354\n",
            "Iteration: 40 \tmse_loss: 0.0624990314\n",
            "Test -- Iteration: 40 \tmse_loss: 0.0624148659\n",
            "Iteration: 41 \tmse_loss: 0.0623418540\n",
            "Iteration: 42 \tmse_loss: 0.0620507337\n",
            "Iteration: 43 \tmse_loss: 0.0616841130\n",
            "Iteration: 44 \tmse_loss: 0.0612679422\n",
            "Iteration: 45 \tmse_loss: 0.0608340055\n",
            "Iteration: 46 \tmse_loss: 0.0604028590\n",
            "Iteration: 47 \tmse_loss: 0.0599876232\n",
            "Iteration: 48 \tmse_loss: 0.0595930107\n",
            "Iteration: 49 \tmse_loss: 0.0592301488\n",
            "Iteration: 50 \tmse_loss: 0.0588982850\n",
            "Iteration: 51 \tmse_loss: 0.0585951358\n",
            "Iteration: 52 \tmse_loss: 0.0583165362\n",
            "Iteration: 53 \tmse_loss: 0.0580636486\n",
            "Iteration: 54 \tmse_loss: 0.0578243621\n",
            "Iteration: 55 \tmse_loss: 0.0576020032\n",
            "Iteration: 56 \tmse_loss: 0.0573982336\n",
            "Iteration: 57 \tmse_loss: 0.0572050624\n",
            "Iteration: 58 \tmse_loss: 0.0570270680\n",
            "Iteration: 59 \tmse_loss: 0.0568627715\n",
            "Iteration: 60 \tmse_loss: 0.0613987632\n",
            "Test -- Iteration: 60 \tmse_loss: 0.0613862686\n",
            "Iteration: 61 \tmse_loss: 0.0612786487\n",
            "Iteration: 62 \tmse_loss: 0.0610457025\n",
            "Iteration: 63 \tmse_loss: 0.0607413575\n",
            "Iteration: 64 \tmse_loss: 0.0603851564\n",
            "Iteration: 65 \tmse_loss: 0.0600073524\n",
            "Iteration: 66 \tmse_loss: 0.0596281625\n",
            "Iteration: 67 \tmse_loss: 0.0592634752\n",
            "Iteration: 68 \tmse_loss: 0.0589193702\n",
            "Iteration: 69 \tmse_loss: 0.0585986264\n",
            "Iteration: 70 \tmse_loss: 0.0582994074\n",
            "Iteration: 71 \tmse_loss: 0.0580199063\n",
            "Iteration: 72 \tmse_loss: 0.0577625297\n",
            "Iteration: 73 \tmse_loss: 0.0575239696\n",
            "Iteration: 74 \tmse_loss: 0.0572985671\n",
            "Iteration: 75 \tmse_loss: 0.0570924804\n",
            "Iteration: 76 \tmse_loss: 0.0569016635\n",
            "Iteration: 77 \tmse_loss: 0.0567212328\n",
            "Iteration: 78 \tmse_loss: 0.0565484613\n",
            "Iteration: 79 \tmse_loss: 0.0563925840\n",
            "Iteration: 80 \tmse_loss: 0.0607930124\n",
            "Test -- Iteration: 80 \tmse_loss: 0.0607502535\n",
            "Iteration: 81 \tmse_loss: 0.0606941096\n",
            "Iteration: 82 \tmse_loss: 0.0604920313\n",
            "Iteration: 83 \tmse_loss: 0.0602200553\n",
            "Iteration: 84 \tmse_loss: 0.0599013343\n",
            "Iteration: 85 \tmse_loss: 0.0595640913\n",
            "Iteration: 86 \tmse_loss: 0.0592211746\n",
            "Iteration: 87 \tmse_loss: 0.0588877648\n",
            "Iteration: 88 \tmse_loss: 0.0585733764\n",
            "Iteration: 89 \tmse_loss: 0.0582758449\n",
            "Iteration: 90 \tmse_loss: 0.0579980537\n",
            "Iteration: 91 \tmse_loss: 0.0577365458\n",
            "Iteration: 92 \tmse_loss: 0.0574924424\n",
            "Iteration: 93 \tmse_loss: 0.0572686680\n",
            "Iteration: 94 \tmse_loss: 0.0570571385\n",
            "Iteration: 95 \tmse_loss: 0.0568580516\n",
            "Iteration: 96 \tmse_loss: 0.0566738509\n",
            "Iteration: 97 \tmse_loss: 0.0564983860\n",
            "Iteration: 98 \tmse_loss: 0.0563391112\n",
            "Iteration: 99 \tmse_loss: 0.0561844781\n",
            "Iteration: 100 \tmse_loss: 0.0602902211\n",
            "Test -- Iteration: 100 \tmse_loss: 0.0602784380\n",
            "Iteration: 101 \tmse_loss: 0.0602083988\n",
            "Iteration: 102 \tmse_loss: 0.0600378998\n",
            "Iteration: 103 \tmse_loss: 0.0598036051\n",
            "Iteration: 104 \tmse_loss: 0.0595239550\n",
            "Iteration: 105 \tmse_loss: 0.0592206381\n",
            "Iteration: 106 \tmse_loss: 0.0589083061\n",
            "Iteration: 107 \tmse_loss: 0.0586047955\n",
            "Iteration: 108 \tmse_loss: 0.0583092347\n",
            "Iteration: 109 \tmse_loss: 0.0580280796\n",
            "Iteration: 110 \tmse_loss: 0.0577593893\n",
            "Iteration: 111 \tmse_loss: 0.0575100519\n",
            "Iteration: 112 \tmse_loss: 0.0572786219\n",
            "Iteration: 113 \tmse_loss: 0.0570646897\n",
            "Iteration: 114 \tmse_loss: 0.0568616651\n",
            "Iteration: 115 \tmse_loss: 0.0566712357\n",
            "Iteration: 116 \tmse_loss: 0.0564924963\n",
            "Iteration: 117 \tmse_loss: 0.0563276261\n",
            "Iteration: 118 \tmse_loss: 0.0561740883\n",
            "Iteration: 119 \tmse_loss: 0.0560281873\n",
            "Iteration: 120 \tmse_loss: 0.0599184856\n",
            "Test -- Iteration: 120 \tmse_loss: 0.0599544048\n",
            "Iteration: 121 \tmse_loss: 0.0598386526\n",
            "Iteration: 122 \tmse_loss: 0.0596884340\n",
            "Iteration: 123 \tmse_loss: 0.0594773442\n",
            "Iteration: 124 \tmse_loss: 0.0592243187\n",
            "Iteration: 125 \tmse_loss: 0.0589541160\n",
            "Iteration: 126 \tmse_loss: 0.0586764626\n",
            "Iteration: 127 \tmse_loss: 0.0584017634\n",
            "Iteration: 128 \tmse_loss: 0.0581274107\n",
            "Iteration: 129 \tmse_loss: 0.0578593463\n",
            "Iteration: 130 \tmse_loss: 0.0576069951\n",
            "Iteration: 131 \tmse_loss: 0.0573697463\n",
            "Iteration: 132 \tmse_loss: 0.0571530983\n",
            "Iteration: 133 \tmse_loss: 0.0569456816\n",
            "Iteration: 134 \tmse_loss: 0.0567467324\n",
            "Iteration: 135 \tmse_loss: 0.0565607473\n",
            "Iteration: 136 \tmse_loss: 0.0563914701\n",
            "Iteration: 137 \tmse_loss: 0.0562378690\n",
            "Iteration: 138 \tmse_loss: 0.0560873635\n",
            "Iteration: 139 \tmse_loss: 0.0559474453\n",
            "Iteration: 140 \tmse_loss: 0.0597307272\n",
            "Test -- Iteration: 140 \tmse_loss: 0.0597236380\n",
            "Iteration: 141 \tmse_loss: 0.0596663915\n",
            "Iteration: 142 \tmse_loss: 0.0595306270\n",
            "Iteration: 143 \tmse_loss: 0.0593379252\n",
            "Iteration: 144 \tmse_loss: 0.0591098294\n",
            "Iteration: 145 \tmse_loss: 0.0588638335\n",
            "Iteration: 146 \tmse_loss: 0.0586116798\n",
            "Iteration: 147 \tmse_loss: 0.0583535731\n",
            "Iteration: 148 \tmse_loss: 0.0580946580\n",
            "Iteration: 149 \tmse_loss: 0.0578418300\n",
            "Iteration: 150 \tmse_loss: 0.0575972609\n",
            "Iteration: 151 \tmse_loss: 0.0573701039\n",
            "Iteration: 152 \tmse_loss: 0.0571554862\n",
            "Iteration: 153 \tmse_loss: 0.0569516793\n",
            "Iteration: 154 \tmse_loss: 0.0567582585\n",
            "Iteration: 155 \tmse_loss: 0.0565790571\n",
            "Iteration: 156 \tmse_loss: 0.0564139821\n",
            "Iteration: 157 \tmse_loss: 0.0562552623\n",
            "Iteration: 158 \tmse_loss: 0.0561092533\n",
            "Iteration: 159 \tmse_loss: 0.0559762865\n",
            "Iteration: 160 \tmse_loss: 0.0595504232\n",
            "Test -- Iteration: 160 \tmse_loss: 0.0595503189\n",
            "Iteration: 161 \tmse_loss: 0.0594804958\n",
            "Iteration: 162 \tmse_loss: 0.0593531281\n",
            "Iteration: 163 \tmse_loss: 0.0591772161\n",
            "Iteration: 164 \tmse_loss: 0.0589662045\n",
            "Iteration: 165 \tmse_loss: 0.0587345548\n",
            "Iteration: 166 \tmse_loss: 0.0584991239\n",
            "Iteration: 167 \tmse_loss: 0.0582561530\n",
            "Iteration: 168 \tmse_loss: 0.0580097772\n",
            "Iteration: 169 \tmse_loss: 0.0577675439\n",
            "Iteration: 170 \tmse_loss: 0.0575384349\n",
            "Iteration: 171 \tmse_loss: 0.0573211759\n",
            "Iteration: 172 \tmse_loss: 0.0571119785\n",
            "Iteration: 173 \tmse_loss: 0.0569113195\n",
            "Iteration: 174 \tmse_loss: 0.0567271449\n",
            "Iteration: 175 \tmse_loss: 0.0565503687\n",
            "Iteration: 176 \tmse_loss: 0.0563813373\n",
            "Iteration: 177 \tmse_loss: 0.0562271476\n",
            "Iteration: 178 \tmse_loss: 0.0560860224\n",
            "Iteration: 179 \tmse_loss: 0.0559574887\n",
            "Iteration: 180 \tmse_loss: 0.0593783706\n",
            "Test -- Iteration: 180 \tmse_loss: 0.0593903475\n",
            "Iteration: 181 \tmse_loss: 0.0593158267\n",
            "Iteration: 182 \tmse_loss: 0.0592037402\n",
            "Iteration: 183 \tmse_loss: 0.0590412207\n",
            "Iteration: 184 \tmse_loss: 0.0588463135\n",
            "Iteration: 185 \tmse_loss: 0.0586373545\n",
            "Iteration: 186 \tmse_loss: 0.0584154725\n",
            "Iteration: 187 \tmse_loss: 0.0581850521\n",
            "Iteration: 188 \tmse_loss: 0.0579468161\n",
            "Iteration: 189 \tmse_loss: 0.0577150099\n",
            "Iteration: 190 \tmse_loss: 0.0574971773\n",
            "Iteration: 191 \tmse_loss: 0.0572829470\n",
            "Iteration: 192 \tmse_loss: 0.0570790470\n",
            "Iteration: 193 \tmse_loss: 0.0568878390\n",
            "Iteration: 194 \tmse_loss: 0.0567024089\n",
            "Iteration: 195 \tmse_loss: 0.0565258078\n",
            "Iteration: 196 \tmse_loss: 0.0563614406\n",
            "Iteration: 197 \tmse_loss: 0.0562099032\n",
            "Iteration: 198 \tmse_loss: 0.0560723692\n",
            "Final loss \tmse_loss: 0.0560723692\n",
            "Iteration: 0 \tmse_loss: 0.0591894500\n",
            "Test -- Iteration: 0 \tmse_loss: 0.0603421219\n",
            "Iteration: 1 \tmse_loss: 0.0600034520\n",
            "Iteration: 2 \tmse_loss: 0.0590700097\n",
            "Iteration: 3 \tmse_loss: 0.0584416166\n",
            "Iteration: 4 \tmse_loss: 0.0582823753\n",
            "Iteration: 5 \tmse_loss: 0.0578317456\n",
            "Iteration: 6 \tmse_loss: 0.0573961586\n",
            "Iteration: 7 \tmse_loss: 0.0571339652\n",
            "Iteration: 8 \tmse_loss: 0.0569642149\n",
            "Iteration: 9 \tmse_loss: 0.0567872897\n",
            "Iteration: 10 \tmse_loss: 0.0565673560\n",
            "Iteration: 11 \tmse_loss: 0.0563374162\n",
            "Iteration: 12 \tmse_loss: 0.0561432838\n",
            "Iteration: 13 \tmse_loss: 0.0559941456\n",
            "Iteration: 14 \tmse_loss: 0.0558724478\n",
            "Iteration: 15 \tmse_loss: 0.0557453148\n",
            "Iteration: 16 \tmse_loss: 0.0556129552\n",
            "Iteration: 17 \tmse_loss: 0.0554890335\n",
            "Iteration: 18 \tmse_loss: 0.0553745031\n",
            "Iteration: 19 \tmse_loss: 0.0552704185\n",
            "Iteration: 20 \tmse_loss: 0.0595413893\n",
            "Test -- Iteration: 20 \tmse_loss: 0.0595001951\n",
            "Iteration: 21 \tmse_loss: 0.0594466552\n",
            "Iteration: 22 \tmse_loss: 0.0592672490\n",
            "Iteration: 23 \tmse_loss: 0.0590513013\n",
            "Iteration: 24 \tmse_loss: 0.0588157885\n",
            "Iteration: 25 \tmse_loss: 0.0585749857\n",
            "Iteration: 26 \tmse_loss: 0.0583383106\n",
            "Iteration: 27 \tmse_loss: 0.0581091419\n",
            "Iteration: 28 \tmse_loss: 0.0578837246\n",
            "Iteration: 29 \tmse_loss: 0.0576611944\n",
            "Iteration: 30 \tmse_loss: 0.0574387051\n",
            "Iteration: 31 \tmse_loss: 0.0572203547\n",
            "Iteration: 32 \tmse_loss: 0.0570065342\n",
            "Iteration: 33 \tmse_loss: 0.0568017997\n",
            "Iteration: 34 \tmse_loss: 0.0566129982\n",
            "Iteration: 35 \tmse_loss: 0.0564377978\n",
            "Iteration: 36 \tmse_loss: 0.0562778711\n",
            "Iteration: 37 \tmse_loss: 0.0561236329\n",
            "Iteration: 38 \tmse_loss: 0.0559790097\n",
            "Iteration: 39 \tmse_loss: 0.0558492802\n",
            "Iteration: 40 \tmse_loss: 0.0593171306\n",
            "Test -- Iteration: 40 \tmse_loss: 0.0593005307\n",
            "Iteration: 41 \tmse_loss: 0.0592429265\n",
            "Iteration: 42 \tmse_loss: 0.0591022409\n",
            "Iteration: 43 \tmse_loss: 0.0589271672\n",
            "Iteration: 44 \tmse_loss: 0.0587259606\n",
            "Iteration: 45 \tmse_loss: 0.0585085191\n",
            "Iteration: 46 \tmse_loss: 0.0582893267\n",
            "Iteration: 47 \tmse_loss: 0.0580687784\n",
            "Iteration: 48 \tmse_loss: 0.0578506775\n",
            "Iteration: 49 \tmse_loss: 0.0576287769\n",
            "Iteration: 50 \tmse_loss: 0.0574071705\n",
            "Iteration: 51 \tmse_loss: 0.0571925268\n",
            "Iteration: 52 \tmse_loss: 0.0569886342\n",
            "Iteration: 53 \tmse_loss: 0.0567946173\n",
            "Iteration: 54 \tmse_loss: 0.0566158295\n",
            "Iteration: 55 \tmse_loss: 0.0564524606\n",
            "Iteration: 56 \tmse_loss: 0.0562954582\n",
            "Iteration: 57 \tmse_loss: 0.0561427511\n",
            "Iteration: 58 \tmse_loss: 0.0560045131\n",
            "Iteration: 59 \tmse_loss: 0.0558739603\n",
            "Iteration: 60 \tmse_loss: 0.0591392033\n",
            "Test -- Iteration: 60 \tmse_loss: 0.0591547526\n",
            "Iteration: 61 \tmse_loss: 0.0590733849\n",
            "Iteration: 62 \tmse_loss: 0.0589582846\n",
            "Iteration: 63 \tmse_loss: 0.0588044897\n",
            "Iteration: 64 \tmse_loss: 0.0586236157\n",
            "Iteration: 65 \tmse_loss: 0.0584268384\n",
            "Iteration: 66 \tmse_loss: 0.0582227483\n",
            "Iteration: 67 \tmse_loss: 0.0580199100\n",
            "Iteration: 68 \tmse_loss: 0.0578094870\n",
            "Iteration: 69 \tmse_loss: 0.0575905181\n",
            "Iteration: 70 \tmse_loss: 0.0573743284\n",
            "Iteration: 71 \tmse_loss: 0.0571698323\n",
            "Iteration: 72 \tmse_loss: 0.0569746606\n",
            "Iteration: 73 \tmse_loss: 0.0567889921\n",
            "Iteration: 74 \tmse_loss: 0.0566146858\n",
            "Iteration: 75 \tmse_loss: 0.0564478561\n",
            "Iteration: 76 \tmse_loss: 0.0562941320\n",
            "Iteration: 77 \tmse_loss: 0.0561472438\n",
            "Iteration: 78 \tmse_loss: 0.0560045540\n",
            "Iteration: 79 \tmse_loss: 0.0558755286\n",
            "Iteration: 80 \tmse_loss: 0.0590564609\n",
            "Test -- Iteration: 80 \tmse_loss: 0.0590437390\n",
            "Iteration: 81 \tmse_loss: 0.0589951165\n",
            "Iteration: 82 \tmse_loss: 0.0588900819\n",
            "Iteration: 83 \tmse_loss: 0.0587511994\n",
            "Iteration: 84 \tmse_loss: 0.0585887879\n",
            "Iteration: 85 \tmse_loss: 0.0584036633\n",
            "Iteration: 86 \tmse_loss: 0.0582128167\n",
            "Iteration: 87 \tmse_loss: 0.0580147877\n",
            "Iteration: 88 \tmse_loss: 0.0578089803\n",
            "Iteration: 89 \tmse_loss: 0.0576012433\n",
            "Iteration: 90 \tmse_loss: 0.0573969148\n",
            "Iteration: 91 \tmse_loss: 0.0571988523\n",
            "Iteration: 92 \tmse_loss: 0.0570074506\n",
            "Iteration: 93 \tmse_loss: 0.0568272620\n",
            "Iteration: 94 \tmse_loss: 0.0566583388\n",
            "Iteration: 95 \tmse_loss: 0.0564955622\n",
            "Iteration: 96 \tmse_loss: 0.0563402548\n",
            "Iteration: 97 \tmse_loss: 0.0561899357\n",
            "Iteration: 98 \tmse_loss: 0.0560519360\n",
            "Iteration: 99 \tmse_loss: 0.0559294596\n",
            "Iteration: 100 \tmse_loss: 0.0589389913\n",
            "Test -- Iteration: 100 \tmse_loss: 0.0589640029\n",
            "Iteration: 101 \tmse_loss: 0.0588883646\n",
            "Iteration: 102 \tmse_loss: 0.0587987490\n",
            "Iteration: 103 \tmse_loss: 0.0586742572\n",
            "Iteration: 104 \tmse_loss: 0.0585164726\n",
            "Iteration: 105 \tmse_loss: 0.0583435260\n",
            "Iteration: 106 \tmse_loss: 0.0581657663\n",
            "Iteration: 107 \tmse_loss: 0.0579751171\n",
            "Iteration: 108 \tmse_loss: 0.0577761643\n",
            "Iteration: 109 \tmse_loss: 0.0575723760\n",
            "Iteration: 110 \tmse_loss: 0.0573751293\n",
            "Iteration: 111 \tmse_loss: 0.0571858250\n",
            "Iteration: 112 \tmse_loss: 0.0569989122\n",
            "Iteration: 113 \tmse_loss: 0.0568230450\n",
            "Iteration: 114 \tmse_loss: 0.0566529110\n",
            "Iteration: 115 \tmse_loss: 0.0564872958\n",
            "Iteration: 116 \tmse_loss: 0.0563293025\n",
            "Iteration: 117 \tmse_loss: 0.0561847836\n",
            "Iteration: 118 \tmse_loss: 0.0560481139\n",
            "Iteration: 119 \tmse_loss: 0.0559233874\n",
            "Iteration: 120 \tmse_loss: 0.0588054955\n",
            "Test -- Iteration: 120 \tmse_loss: 0.0588875934\n",
            "Iteration: 121 \tmse_loss: 0.0587551966\n",
            "Iteration: 122 \tmse_loss: 0.0586758070\n",
            "Iteration: 123 \tmse_loss: 0.0585587323\n",
            "Iteration: 124 \tmse_loss: 0.0584063716\n",
            "Iteration: 125 \tmse_loss: 0.0582469665\n",
            "Iteration: 126 \tmse_loss: 0.0580826811\n",
            "Iteration: 127 \tmse_loss: 0.0578997396\n",
            "Iteration: 128 \tmse_loss: 0.0577069856\n",
            "Iteration: 129 \tmse_loss: 0.0575148985\n",
            "Iteration: 130 \tmse_loss: 0.0573257133\n",
            "Iteration: 131 \tmse_loss: 0.0571427494\n",
            "Iteration: 132 \tmse_loss: 0.0569619946\n",
            "Iteration: 133 \tmse_loss: 0.0567866005\n",
            "Iteration: 134 \tmse_loss: 0.0566181578\n",
            "Iteration: 135 \tmse_loss: 0.0564569123\n",
            "Iteration: 136 \tmse_loss: 0.0562994070\n",
            "Iteration: 137 \tmse_loss: 0.0561546162\n",
            "Iteration: 138 \tmse_loss: 0.0560205281\n",
            "Iteration: 139 \tmse_loss: 0.0558942705\n",
            "Iteration: 140 \tmse_loss: 0.0588166751\n",
            "Test -- Iteration: 140 \tmse_loss: 0.0588405505\n",
            "Iteration: 141 \tmse_loss: 0.0587751828\n",
            "Iteration: 142 \tmse_loss: 0.0586955845\n",
            "Iteration: 143 \tmse_loss: 0.0585818291\n",
            "Iteration: 144 \tmse_loss: 0.0584364608\n",
            "Iteration: 145 \tmse_loss: 0.0582871996\n",
            "Iteration: 146 \tmse_loss: 0.0581249632\n",
            "Iteration: 147 \tmse_loss: 0.0579482019\n",
            "Iteration: 148 \tmse_loss: 0.0577638894\n",
            "Iteration: 149 \tmse_loss: 0.0575827248\n",
            "Iteration: 150 \tmse_loss: 0.0574002415\n",
            "Iteration: 151 \tmse_loss: 0.0572202578\n",
            "Iteration: 152 \tmse_loss: 0.0570446141\n",
            "Iteration: 153 \tmse_loss: 0.0568723418\n",
            "Iteration: 154 \tmse_loss: 0.0567069873\n",
            "Iteration: 155 \tmse_loss: 0.0565456524\n",
            "Iteration: 156 \tmse_loss: 0.0563889667\n",
            "Iteration: 157 \tmse_loss: 0.0562455133\n",
            "Iteration: 158 \tmse_loss: 0.0561137237\n",
            "Iteration: 159 \tmse_loss: 0.0559911877\n",
            "Iteration: 160 \tmse_loss: 0.0587422028\n",
            "Test -- Iteration: 160 \tmse_loss: 0.0587855540\n",
            "Iteration: 161 \tmse_loss: 0.0586977080\n",
            "Iteration: 162 \tmse_loss: 0.0586178899\n",
            "Iteration: 163 \tmse_loss: 0.0585086010\n",
            "Iteration: 164 \tmse_loss: 0.0583707392\n",
            "Iteration: 165 \tmse_loss: 0.0582294948\n",
            "Iteration: 166 \tmse_loss: 0.0580719896\n",
            "Iteration: 167 \tmse_loss: 0.0579032674\n",
            "Iteration: 168 \tmse_loss: 0.0577281825\n",
            "Iteration: 169 \tmse_loss: 0.0575548857\n",
            "Iteration: 170 \tmse_loss: 0.0573793501\n",
            "Iteration: 171 \tmse_loss: 0.0572091937\n",
            "Iteration: 172 \tmse_loss: 0.0570373274\n",
            "Iteration: 173 \tmse_loss: 0.0568664372\n",
            "Iteration: 174 \tmse_loss: 0.0566999875\n",
            "Iteration: 175 \tmse_loss: 0.0565403365\n",
            "Iteration: 176 \tmse_loss: 0.0563875772\n",
            "Iteration: 177 \tmse_loss: 0.0562450923\n",
            "Iteration: 178 \tmse_loss: 0.0561151206\n",
            "Iteration: 179 \tmse_loss: 0.0559909530\n",
            "Iteration: 180 \tmse_loss: 0.0586886033\n",
            "Test -- Iteration: 180 \tmse_loss: 0.0587242097\n",
            "Iteration: 181 \tmse_loss: 0.0586484000\n",
            "Iteration: 182 \tmse_loss: 0.0585776456\n",
            "Iteration: 183 \tmse_loss: 0.0584741682\n",
            "Iteration: 184 \tmse_loss: 0.0583445355\n",
            "Iteration: 185 \tmse_loss: 0.0582093298\n",
            "Iteration: 186 \tmse_loss: 0.0580565184\n",
            "Iteration: 187 \tmse_loss: 0.0578948110\n",
            "Iteration: 188 \tmse_loss: 0.0577281006\n",
            "Iteration: 189 \tmse_loss: 0.0575567558\n",
            "Iteration: 190 \tmse_loss: 0.0573884621\n",
            "Iteration: 191 \tmse_loss: 0.0572225004\n",
            "Iteration: 192 \tmse_loss: 0.0570524372\n",
            "Iteration: 193 \tmse_loss: 0.0568832308\n",
            "Iteration: 194 \tmse_loss: 0.0567234606\n",
            "Iteration: 195 \tmse_loss: 0.0565632321\n",
            "Iteration: 196 \tmse_loss: 0.0564098582\n",
            "Iteration: 197 \tmse_loss: 0.0562707670\n",
            "Iteration: 198 \tmse_loss: 0.0561427996\n",
            "Final loss \tmse_loss: 0.0561427996\n",
            "Iteration: 0 \tmse_loss: 0.0585236140\n",
            "Test -- Iteration: 0 \tmse_loss: 0.0607448295\n",
            "Iteration: 1 \tmse_loss: 0.0604049601\n",
            "Iteration: 2 \tmse_loss: 0.0595732890\n",
            "Iteration: 3 \tmse_loss: 0.0584384874\n",
            "Iteration: 4 \tmse_loss: 0.0586515181\n",
            "Iteration: 5 \tmse_loss: 0.0582621023\n",
            "Iteration: 6 \tmse_loss: 0.0575163290\n",
            "Iteration: 7 \tmse_loss: 0.0572693311\n",
            "Iteration: 8 \tmse_loss: 0.0571953990\n",
            "Iteration: 9 \tmse_loss: 0.0571257137\n",
            "Iteration: 10 \tmse_loss: 0.0569962710\n",
            "Iteration: 11 \tmse_loss: 0.0567281060\n",
            "Iteration: 12 \tmse_loss: 0.0564375073\n",
            "Iteration: 13 \tmse_loss: 0.0562538356\n",
            "Iteration: 14 \tmse_loss: 0.0561468825\n",
            "Iteration: 15 \tmse_loss: 0.0560529530\n",
            "Iteration: 16 \tmse_loss: 0.0559364259\n",
            "Iteration: 17 \tmse_loss: 0.0557985120\n",
            "Iteration: 18 \tmse_loss: 0.0556635112\n",
            "Iteration: 19 \tmse_loss: 0.0555538535\n",
            "Iteration: 20 \tmse_loss: 0.0587994717\n",
            "Test -- Iteration: 20 \tmse_loss: 0.0588643886\n",
            "Iteration: 21 \tmse_loss: 0.0587594546\n",
            "Iteration: 22 \tmse_loss: 0.0586690865\n",
            "Iteration: 23 \tmse_loss: 0.0585357212\n",
            "Iteration: 24 \tmse_loss: 0.0583839305\n",
            "Iteration: 25 \tmse_loss: 0.0582375862\n",
            "Iteration: 26 \tmse_loss: 0.0580890924\n",
            "Iteration: 27 \tmse_loss: 0.0579295866\n",
            "Iteration: 28 \tmse_loss: 0.0577638187\n",
            "Iteration: 29 \tmse_loss: 0.0575981177\n",
            "Iteration: 30 \tmse_loss: 0.0574277714\n",
            "Iteration: 31 \tmse_loss: 0.0572535731\n",
            "Iteration: 32 \tmse_loss: 0.0570788682\n",
            "Iteration: 33 \tmse_loss: 0.0569049567\n",
            "Iteration: 34 \tmse_loss: 0.0567369461\n",
            "Iteration: 35 \tmse_loss: 0.0565807223\n",
            "Iteration: 36 \tmse_loss: 0.0564353131\n",
            "Iteration: 37 \tmse_loss: 0.0562988073\n",
            "Iteration: 38 \tmse_loss: 0.0561694913\n",
            "Iteration: 39 \tmse_loss: 0.0560434684\n",
            "Iteration: 40 \tmse_loss: 0.0586792603\n",
            "Test -- Iteration: 40 \tmse_loss: 0.0587308034\n",
            "Iteration: 41 \tmse_loss: 0.0586209111\n",
            "Iteration: 42 \tmse_loss: 0.0585243069\n",
            "Iteration: 43 \tmse_loss: 0.0584112853\n",
            "Iteration: 44 \tmse_loss: 0.0582818463\n",
            "Iteration: 45 \tmse_loss: 0.0581419654\n",
            "Iteration: 46 \tmse_loss: 0.0579944663\n",
            "Iteration: 47 \tmse_loss: 0.0578443743\n",
            "Iteration: 48 \tmse_loss: 0.0576897115\n",
            "Iteration: 49 \tmse_loss: 0.0575301684\n",
            "Iteration: 50 \tmse_loss: 0.0573640913\n",
            "Iteration: 51 \tmse_loss: 0.0571943410\n",
            "Iteration: 52 \tmse_loss: 0.0570260920\n",
            "Iteration: 53 \tmse_loss: 0.0568607152\n",
            "Iteration: 54 \tmse_loss: 0.0567007251\n",
            "Iteration: 55 \tmse_loss: 0.0565488152\n",
            "Iteration: 56 \tmse_loss: 0.0564072803\n",
            "Iteration: 57 \tmse_loss: 0.0562727079\n",
            "Iteration: 58 \tmse_loss: 0.0561470054\n",
            "Iteration: 59 \tmse_loss: 0.0560284443\n",
            "Iteration: 60 \tmse_loss: 0.0585844778\n",
            "Test -- Iteration: 60 \tmse_loss: 0.0586665757\n",
            "Iteration: 61 \tmse_loss: 0.0585367717\n",
            "Iteration: 62 \tmse_loss: 0.0584512316\n",
            "Iteration: 63 \tmse_loss: 0.0583456904\n",
            "Iteration: 64 \tmse_loss: 0.0582241565\n",
            "Iteration: 65 \tmse_loss: 0.0580927506\n",
            "Iteration: 66 \tmse_loss: 0.0579541288\n",
            "Iteration: 67 \tmse_loss: 0.0578073002\n",
            "Iteration: 68 \tmse_loss: 0.0576564893\n",
            "Iteration: 69 \tmse_loss: 0.0574976616\n",
            "Iteration: 70 \tmse_loss: 0.0573354363\n",
            "Iteration: 71 \tmse_loss: 0.0571690612\n",
            "Iteration: 72 \tmse_loss: 0.0570021532\n",
            "Iteration: 73 \tmse_loss: 0.0568412058\n",
            "Iteration: 74 \tmse_loss: 0.0566878133\n",
            "Iteration: 75 \tmse_loss: 0.0565367155\n",
            "Iteration: 76 \tmse_loss: 0.0563964844\n",
            "Iteration: 77 \tmse_loss: 0.0562665984\n",
            "Iteration: 78 \tmse_loss: 0.0561396554\n",
            "Iteration: 79 \tmse_loss: 0.0560205542\n",
            "Iteration: 80 \tmse_loss: 0.0585668869\n",
            "Test -- Iteration: 80 \tmse_loss: 0.0586148873\n",
            "Iteration: 81 \tmse_loss: 0.0585192963\n",
            "Iteration: 82 \tmse_loss: 0.0584393628\n",
            "Iteration: 83 \tmse_loss: 0.0583407022\n",
            "Iteration: 84 \tmse_loss: 0.0582244731\n",
            "Iteration: 85 \tmse_loss: 0.0580981001\n",
            "Iteration: 86 \tmse_loss: 0.0579652786\n",
            "Iteration: 87 \tmse_loss: 0.0578238294\n",
            "Iteration: 88 \tmse_loss: 0.0576780811\n",
            "Iteration: 89 \tmse_loss: 0.0575217567\n",
            "Iteration: 90 \tmse_loss: 0.0573568195\n",
            "Iteration: 91 \tmse_loss: 0.0571952462\n",
            "Iteration: 92 \tmse_loss: 0.0570346452\n",
            "Iteration: 93 \tmse_loss: 0.0568734817\n",
            "Iteration: 94 \tmse_loss: 0.0567239337\n",
            "Iteration: 95 \tmse_loss: 0.0565792210\n",
            "Iteration: 96 \tmse_loss: 0.0564380027\n",
            "Iteration: 97 \tmse_loss: 0.0563100949\n",
            "Iteration: 98 \tmse_loss: 0.0561869256\n",
            "Iteration: 99 \tmse_loss: 0.0560631827\n",
            "Iteration: 100 \tmse_loss: 0.0584967621\n",
            "Test -- Iteration: 100 \tmse_loss: 0.0585766435\n",
            "Iteration: 101 \tmse_loss: 0.0584535860\n",
            "Iteration: 102 \tmse_loss: 0.0583807305\n",
            "Iteration: 103 \tmse_loss: 0.0582919940\n",
            "Iteration: 104 \tmse_loss: 0.0581822544\n",
            "Iteration: 105 \tmse_loss: 0.0580592118\n",
            "Iteration: 106 \tmse_loss: 0.0579290912\n",
            "Iteration: 107 \tmse_loss: 0.0577944070\n",
            "Iteration: 108 \tmse_loss: 0.0576496199\n",
            "Iteration: 109 \tmse_loss: 0.0574929044\n",
            "Iteration: 110 \tmse_loss: 0.0573321357\n",
            "Iteration: 111 \tmse_loss: 0.0571750663\n",
            "Iteration: 112 \tmse_loss: 0.0570178777\n",
            "Iteration: 113 \tmse_loss: 0.0568584874\n",
            "Iteration: 114 \tmse_loss: 0.0567099079\n",
            "Iteration: 115 \tmse_loss: 0.0565674603\n",
            "Iteration: 116 \tmse_loss: 0.0564259589\n",
            "Iteration: 117 \tmse_loss: 0.0562958866\n",
            "Iteration: 118 \tmse_loss: 0.0561724082\n",
            "Iteration: 119 \tmse_loss: 0.0560509972\n",
            "Iteration: 120 \tmse_loss: 0.0584052056\n",
            "Test -- Iteration: 120 \tmse_loss: 0.0585366860\n",
            "Iteration: 121 \tmse_loss: 0.0583574623\n",
            "Iteration: 122 \tmse_loss: 0.0582883060\n",
            "Iteration: 123 \tmse_loss: 0.0582021028\n",
            "Iteration: 124 \tmse_loss: 0.0580995046\n",
            "Iteration: 125 \tmse_loss: 0.0579833724\n",
            "Iteration: 126 \tmse_loss: 0.0578635894\n",
            "Iteration: 127 \tmse_loss: 0.0577327460\n",
            "Iteration: 128 \tmse_loss: 0.0575873293\n",
            "Iteration: 129 \tmse_loss: 0.0574353859\n",
            "Iteration: 130 \tmse_loss: 0.0572792552\n",
            "Iteration: 131 \tmse_loss: 0.0571239851\n",
            "Iteration: 132 \tmse_loss: 0.0569668114\n",
            "Iteration: 133 \tmse_loss: 0.0568137579\n",
            "Iteration: 134 \tmse_loss: 0.0566668771\n",
            "Iteration: 135 \tmse_loss: 0.0565271117\n",
            "Iteration: 136 \tmse_loss: 0.0563906021\n",
            "Iteration: 137 \tmse_loss: 0.0562594198\n",
            "Iteration: 138 \tmse_loss: 0.0561366454\n",
            "Iteration: 139 \tmse_loss: 0.0560206026\n",
            "Iteration: 140 \tmse_loss: 0.0584389083\n",
            "Test -- Iteration: 140 \tmse_loss: 0.0585058182\n",
            "Iteration: 141 \tmse_loss: 0.0583952814\n",
            "Iteration: 142 \tmse_loss: 0.0583321638\n",
            "Iteration: 143 \tmse_loss: 0.0582507178\n",
            "Iteration: 144 \tmse_loss: 0.0581495315\n",
            "Iteration: 145 \tmse_loss: 0.0580339916\n",
            "Iteration: 146 \tmse_loss: 0.0579146259\n",
            "Iteration: 147 \tmse_loss: 0.0577881858\n",
            "Iteration: 148 \tmse_loss: 0.0576490425\n",
            "Iteration: 149 \tmse_loss: 0.0575006269\n",
            "Iteration: 150 \tmse_loss: 0.0573487543\n",
            "Iteration: 151 \tmse_loss: 0.0571971498\n",
            "Iteration: 152 \tmse_loss: 0.0570453405\n",
            "Iteration: 153 \tmse_loss: 0.0568962134\n",
            "Iteration: 154 \tmse_loss: 0.0567529462\n",
            "Iteration: 155 \tmse_loss: 0.0566118918\n",
            "Iteration: 156 \tmse_loss: 0.0564733222\n",
            "Iteration: 157 \tmse_loss: 0.0563412346\n",
            "Iteration: 158 \tmse_loss: 0.0562189333\n",
            "Iteration: 159 \tmse_loss: 0.0561056323\n",
            "Iteration: 160 \tmse_loss: 0.0583973341\n",
            "Test -- Iteration: 160 \tmse_loss: 0.0584769920\n",
            "Iteration: 161 \tmse_loss: 0.0583509579\n",
            "Iteration: 162 \tmse_loss: 0.0582862385\n",
            "Iteration: 163 \tmse_loss: 0.0582079627\n",
            "Iteration: 164 \tmse_loss: 0.0581084415\n",
            "Iteration: 165 \tmse_loss: 0.0580018312\n",
            "Iteration: 166 \tmse_loss: 0.0578888841\n",
            "Iteration: 167 \tmse_loss: 0.0577620156\n",
            "Iteration: 168 \tmse_loss: 0.0576223098\n",
            "Iteration: 169 \tmse_loss: 0.0574765131\n",
            "Iteration: 170 \tmse_loss: 0.0573302545\n",
            "Iteration: 171 \tmse_loss: 0.0571830459\n",
            "Iteration: 172 \tmse_loss: 0.0570330061\n",
            "Iteration: 173 \tmse_loss: 0.0568889678\n",
            "Iteration: 174 \tmse_loss: 0.0567467250\n",
            "Iteration: 175 \tmse_loss: 0.0566036515\n",
            "Iteration: 176 \tmse_loss: 0.0564708002\n",
            "Iteration: 177 \tmse_loss: 0.0563465953\n",
            "Iteration: 178 \tmse_loss: 0.0562221408\n",
            "Iteration: 179 \tmse_loss: 0.0561062694\n",
            "Iteration: 180 \tmse_loss: 0.0583807305\n",
            "Test -- Iteration: 180 \tmse_loss: 0.0584335178\n",
            "Iteration: 181 \tmse_loss: 0.0583357960\n",
            "Iteration: 182 \tmse_loss: 0.0582791381\n",
            "Iteration: 183 \tmse_loss: 0.0582022853\n",
            "Iteration: 184 \tmse_loss: 0.0581066385\n",
            "Iteration: 185 \tmse_loss: 0.0579998121\n",
            "Iteration: 186 \tmse_loss: 0.0578879453\n",
            "Iteration: 187 \tmse_loss: 0.0577625893\n",
            "Iteration: 188 \tmse_loss: 0.0576262102\n",
            "Iteration: 189 \tmse_loss: 0.0574823730\n",
            "Iteration: 190 \tmse_loss: 0.0573395602\n",
            "Iteration: 191 \tmse_loss: 0.0571943447\n",
            "Iteration: 192 \tmse_loss: 0.0570520237\n",
            "Iteration: 193 \tmse_loss: 0.0569087565\n",
            "Iteration: 194 \tmse_loss: 0.0567649193\n",
            "Iteration: 195 \tmse_loss: 0.0566247739\n",
            "Iteration: 196 \tmse_loss: 0.0564948544\n",
            "Iteration: 197 \tmse_loss: 0.0563698672\n",
            "Iteration: 198 \tmse_loss: 0.0562484227\n",
            "Final loss \tmse_loss: 0.0562484227\n",
            "Iteration: 0 \tmse_loss: 0.0582286641\n",
            "Test -- Iteration: 0 \tmse_loss: 0.0612521581\n",
            "Iteration: 1 \tmse_loss: 0.0608954914\n",
            "Iteration: 2 \tmse_loss: 0.0599410012\n",
            "Iteration: 3 \tmse_loss: 0.0585606247\n",
            "Iteration: 4 \tmse_loss: 0.0589615814\n",
            "Iteration: 5 \tmse_loss: 0.0585817620\n",
            "Iteration: 6 \tmse_loss: 0.0576803014\n",
            "Iteration: 7 \tmse_loss: 0.0574092306\n",
            "Iteration: 8 \tmse_loss: 0.0573913157\n",
            "Iteration: 9 \tmse_loss: 0.0573822111\n",
            "Iteration: 10 \tmse_loss: 0.0572699755\n",
            "Iteration: 11 \tmse_loss: 0.0569791831\n",
            "Iteration: 12 \tmse_loss: 0.0566541851\n",
            "Iteration: 13 \tmse_loss: 0.0564694516\n",
            "Iteration: 14 \tmse_loss: 0.0563719124\n",
            "Iteration: 15 \tmse_loss: 0.0562779866\n",
            "Iteration: 16 \tmse_loss: 0.0561592877\n",
            "Iteration: 17 \tmse_loss: 0.0560157336\n",
            "Iteration: 18 \tmse_loss: 0.0558728054\n",
            "Iteration: 19 \tmse_loss: 0.0557541102\n",
            "Iteration: 20 \tmse_loss: 0.0584841296\n",
            "Test -- Iteration: 20 \tmse_loss: 0.0586080849\n",
            "Iteration: 21 \tmse_loss: 0.0584619492\n",
            "Iteration: 22 \tmse_loss: 0.0583988801\n",
            "Iteration: 23 \tmse_loss: 0.0582998618\n",
            "Iteration: 24 \tmse_loss: 0.0581816733\n",
            "Iteration: 25 \tmse_loss: 0.0580618232\n",
            "Iteration: 26 \tmse_loss: 0.0579375029\n",
            "Iteration: 27 \tmse_loss: 0.0578093231\n",
            "Iteration: 28 \tmse_loss: 0.0576741174\n",
            "Iteration: 29 \tmse_loss: 0.0575363822\n",
            "Iteration: 30 \tmse_loss: 0.0573912449\n",
            "Iteration: 31 \tmse_loss: 0.0572396629\n",
            "Iteration: 32 \tmse_loss: 0.0570898429\n",
            "Iteration: 33 \tmse_loss: 0.0569474362\n",
            "Iteration: 34 \tmse_loss: 0.0568034947\n",
            "Iteration: 35 \tmse_loss: 0.0566640571\n",
            "Iteration: 36 \tmse_loss: 0.0565313883\n",
            "Iteration: 37 \tmse_loss: 0.0564051233\n",
            "Iteration: 38 \tmse_loss: 0.0562854595\n",
            "Iteration: 39 \tmse_loss: 0.0561687760\n",
            "Iteration: 40 \tmse_loss: 0.0583672822\n",
            "Test -- Iteration: 40 \tmse_loss: 0.0584742315\n",
            "Iteration: 41 \tmse_loss: 0.0583223961\n",
            "Iteration: 42 \tmse_loss: 0.0582485646\n",
            "Iteration: 43 \tmse_loss: 0.0581597015\n",
            "Iteration: 44 \tmse_loss: 0.0580630116\n",
            "Iteration: 45 \tmse_loss: 0.0579562411\n",
            "Iteration: 46 \tmse_loss: 0.0578392409\n",
            "Iteration: 47 \tmse_loss: 0.0577146672\n",
            "Iteration: 48 \tmse_loss: 0.0575847626\n",
            "Iteration: 49 \tmse_loss: 0.0574472770\n",
            "Iteration: 50 \tmse_loss: 0.0573079772\n",
            "Iteration: 51 \tmse_loss: 0.0571657754\n",
            "Iteration: 52 \tmse_loss: 0.0570218675\n",
            "Iteration: 53 \tmse_loss: 0.0568811335\n",
            "Iteration: 54 \tmse_loss: 0.0567442328\n",
            "Iteration: 55 \tmse_loss: 0.0566124357\n",
            "Iteration: 56 \tmse_loss: 0.0564859398\n",
            "Iteration: 57 \tmse_loss: 0.0563594289\n",
            "Iteration: 58 \tmse_loss: 0.0562384203\n",
            "Iteration: 59 \tmse_loss: 0.0561256669\n",
            "Iteration: 60 \tmse_loss: 0.0582880825\n",
            "Test -- Iteration: 60 \tmse_loss: 0.0584197603\n",
            "Iteration: 61 \tmse_loss: 0.0582494847\n",
            "Iteration: 62 \tmse_loss: 0.0581851713\n",
            "Iteration: 63 \tmse_loss: 0.0581066236\n",
            "Iteration: 64 \tmse_loss: 0.0580135584\n",
            "Iteration: 65 \tmse_loss: 0.0579106659\n",
            "Iteration: 66 \tmse_loss: 0.0578002967\n",
            "Iteration: 67 \tmse_loss: 0.0576782264\n",
            "Iteration: 68 \tmse_loss: 0.0575526394\n",
            "Iteration: 69 \tmse_loss: 0.0574207306\n",
            "Iteration: 70 \tmse_loss: 0.0572836436\n",
            "Iteration: 71 \tmse_loss: 0.0571422353\n",
            "Iteration: 72 \tmse_loss: 0.0569992997\n",
            "Iteration: 73 \tmse_loss: 0.0568600148\n",
            "Iteration: 74 \tmse_loss: 0.0567234606\n",
            "Iteration: 75 \tmse_loss: 0.0565904304\n",
            "Iteration: 76 \tmse_loss: 0.0564629883\n",
            "Iteration: 77 \tmse_loss: 0.0563416779\n",
            "Iteration: 78 \tmse_loss: 0.0562260635\n",
            "Iteration: 79 \tmse_loss: 0.0561133660\n",
            "Iteration: 80 \tmse_loss: 0.0582897104\n",
            "Test -- Iteration: 80 \tmse_loss: 0.0583899207\n",
            "Iteration: 81 \tmse_loss: 0.0582508296\n",
            "Iteration: 82 \tmse_loss: 0.0581873842\n",
            "Iteration: 83 \tmse_loss: 0.0581101701\n",
            "Iteration: 84 \tmse_loss: 0.0580179244\n",
            "Iteration: 85 \tmse_loss: 0.0579198748\n",
            "Iteration: 86 \tmse_loss: 0.0578117855\n",
            "Iteration: 87 \tmse_loss: 0.0576961525\n",
            "Iteration: 88 \tmse_loss: 0.0575746298\n",
            "Iteration: 89 \tmse_loss: 0.0574408807\n",
            "Iteration: 90 \tmse_loss: 0.0573026948\n",
            "Iteration: 91 \tmse_loss: 0.0571659207\n",
            "Iteration: 92 \tmse_loss: 0.0570267104\n",
            "Iteration: 93 \tmse_loss: 0.0568854772\n",
            "Iteration: 94 \tmse_loss: 0.0567521453\n",
            "Iteration: 95 \tmse_loss: 0.0566215776\n",
            "Iteration: 96 \tmse_loss: 0.0564965308\n",
            "Iteration: 97 \tmse_loss: 0.0563774593\n",
            "Iteration: 98 \tmse_loss: 0.0562622808\n",
            "Iteration: 99 \tmse_loss: 0.0561500378\n",
            "Iteration: 100 \tmse_loss: 0.0582472868\n",
            "Test -- Iteration: 100 \tmse_loss: 0.0583712384\n",
            "Iteration: 101 \tmse_loss: 0.0582098775\n",
            "Iteration: 102 \tmse_loss: 0.0581511483\n",
            "Iteration: 103 \tmse_loss: 0.0580772609\n",
            "Iteration: 104 \tmse_loss: 0.0579903051\n",
            "Iteration: 105 \tmse_loss: 0.0578941330\n",
            "Iteration: 106 \tmse_loss: 0.0577893592\n",
            "Iteration: 107 \tmse_loss: 0.0576802902\n",
            "Iteration: 108 \tmse_loss: 0.0575567782\n",
            "Iteration: 109 \tmse_loss: 0.0574250333\n",
            "Iteration: 110 \tmse_loss: 0.0572910309\n",
            "Iteration: 111 \tmse_loss: 0.0571537875\n",
            "Iteration: 112 \tmse_loss: 0.0570118055\n",
            "Iteration: 113 \tmse_loss: 0.0568749048\n",
            "Iteration: 114 \tmse_loss: 0.0567427166\n",
            "Iteration: 115 \tmse_loss: 0.0566148423\n",
            "Iteration: 116 \tmse_loss: 0.0564889498\n",
            "Iteration: 117 \tmse_loss: 0.0563677065\n",
            "Iteration: 118 \tmse_loss: 0.0562540926\n",
            "Iteration: 119 \tmse_loss: 0.0561484061\n",
            "Iteration: 120 \tmse_loss: 0.0581704490\n",
            "Test -- Iteration: 120 \tmse_loss: 0.0583509207\n",
            "Iteration: 121 \tmse_loss: 0.0581310391\n",
            "Iteration: 122 \tmse_loss: 0.0580764376\n",
            "Iteration: 123 \tmse_loss: 0.0580071770\n",
            "Iteration: 124 \tmse_loss: 0.0579204410\n",
            "Iteration: 125 \tmse_loss: 0.0578289367\n",
            "Iteration: 126 \tmse_loss: 0.0577270202\n",
            "Iteration: 127 \tmse_loss: 0.0576195531\n",
            "Iteration: 128 \tmse_loss: 0.0574949123\n",
            "Iteration: 129 \tmse_loss: 0.0573630556\n",
            "Iteration: 130 \tmse_loss: 0.0572362989\n",
            "Iteration: 131 \tmse_loss: 0.0571028106\n",
            "Iteration: 132 \tmse_loss: 0.0569625050\n",
            "Iteration: 133 \tmse_loss: 0.0568239838\n",
            "Iteration: 134 \tmse_loss: 0.0566960499\n",
            "Iteration: 135 \tmse_loss: 0.0565721802\n",
            "Iteration: 136 \tmse_loss: 0.0564450398\n",
            "Iteration: 137 \tmse_loss: 0.0563248172\n",
            "Iteration: 138 \tmse_loss: 0.0562115572\n",
            "Iteration: 139 \tmse_loss: 0.0561038591\n",
            "Iteration: 140 \tmse_loss: 0.0582210124\n",
            "Test -- Iteration: 140 \tmse_loss: 0.0583331846\n",
            "Iteration: 141 \tmse_loss: 0.0581820421\n",
            "Iteration: 142 \tmse_loss: 0.0581306405\n",
            "Iteration: 143 \tmse_loss: 0.0580618903\n",
            "Iteration: 144 \tmse_loss: 0.0579743795\n",
            "Iteration: 145 \tmse_loss: 0.0578830875\n",
            "Iteration: 146 \tmse_loss: 0.0577875599\n",
            "Iteration: 147 \tmse_loss: 0.0576805621\n",
            "Iteration: 148 \tmse_loss: 0.0575579219\n",
            "Iteration: 149 \tmse_loss: 0.0574268177\n",
            "Iteration: 150 \tmse_loss: 0.0573000126\n",
            "Iteration: 151 \tmse_loss: 0.0571680889\n",
            "Iteration: 152 \tmse_loss: 0.0570282862\n",
            "Iteration: 153 \tmse_loss: 0.0568978898\n",
            "Iteration: 154 \tmse_loss: 0.0567705445\n",
            "Iteration: 155 \tmse_loss: 0.0566434041\n",
            "Iteration: 156 \tmse_loss: 0.0565177538\n",
            "Iteration: 157 \tmse_loss: 0.0564013161\n",
            "Iteration: 158 \tmse_loss: 0.0562895760\n",
            "Iteration: 159 \tmse_loss: 0.0561815389\n",
            "Iteration: 160 \tmse_loss: 0.0581939965\n",
            "Test -- Iteration: 160 \tmse_loss: 0.0583141893\n",
            "Iteration: 161 \tmse_loss: 0.0581553318\n",
            "Iteration: 162 \tmse_loss: 0.0581038110\n",
            "Iteration: 163 \tmse_loss: 0.0580362678\n",
            "Iteration: 164 \tmse_loss: 0.0579540879\n",
            "Iteration: 165 \tmse_loss: 0.0578654930\n",
            "Iteration: 166 \tmse_loss: 0.0577733405\n",
            "Iteration: 167 \tmse_loss: 0.0576674491\n",
            "Iteration: 168 \tmse_loss: 0.0575446151\n",
            "Iteration: 169 \tmse_loss: 0.0574214831\n",
            "Iteration: 170 \tmse_loss: 0.0572983585\n",
            "Iteration: 171 \tmse_loss: 0.0571634322\n",
            "Iteration: 172 \tmse_loss: 0.0570291169\n",
            "Iteration: 173 \tmse_loss: 0.0569015704\n",
            "Iteration: 174 \tmse_loss: 0.0567722581\n",
            "Iteration: 175 \tmse_loss: 0.0566458814\n",
            "Iteration: 176 \tmse_loss: 0.0565225780\n",
            "Iteration: 177 \tmse_loss: 0.0564076975\n",
            "Iteration: 178 \tmse_loss: 0.0562988706\n",
            "Iteration: 179 \tmse_loss: 0.0561913550\n",
            "Iteration: 180 \tmse_loss: 0.0582037382\n",
            "Test -- Iteration: 180 \tmse_loss: 0.0582811050\n",
            "Iteration: 181 \tmse_loss: 0.0581635721\n",
            "Iteration: 182 \tmse_loss: 0.0581159666\n",
            "Iteration: 183 \tmse_loss: 0.0580515526\n",
            "Iteration: 184 \tmse_loss: 0.0579664670\n",
            "Iteration: 185 \tmse_loss: 0.0578807481\n",
            "Iteration: 186 \tmse_loss: 0.0577910468\n",
            "Iteration: 187 \tmse_loss: 0.0576819777\n",
            "Iteration: 188 \tmse_loss: 0.0575627051\n",
            "Iteration: 189 \tmse_loss: 0.0574434027\n",
            "Iteration: 190 \tmse_loss: 0.0573171377\n",
            "Iteration: 191 \tmse_loss: 0.0571851246\n",
            "Iteration: 192 \tmse_loss: 0.0570551902\n",
            "Iteration: 193 \tmse_loss: 0.0569260158\n",
            "Iteration: 194 \tmse_loss: 0.0568018444\n",
            "Iteration: 195 \tmse_loss: 0.0566763952\n",
            "Iteration: 196 \tmse_loss: 0.0565507337\n",
            "Iteration: 197 \tmse_loss: 0.0564369075\n",
            "Iteration: 198 \tmse_loss: 0.0563309789\n",
            "Final loss \tmse_loss: 0.0563309789\n",
            "Iteration: 0 \tmse_loss: 2.0562722683\n",
            "Test -- Iteration: 0 \tmse_loss: 1.9036729336\n",
            "Iteration: 1 \tmse_loss: 1.9034409523\n",
            "Iteration: 2 \tmse_loss: 1.7600300312\n",
            "Iteration: 3 \tmse_loss: 1.6268571615\n",
            "Iteration: 4 \tmse_loss: 1.5036467314\n",
            "Iteration: 5 \tmse_loss: 1.3899893761\n",
            "Iteration: 6 \tmse_loss: 1.2847756147\n",
            "Iteration: 7 \tmse_loss: 1.1878700256\n",
            "Iteration: 8 \tmse_loss: 1.0990059376\n",
            "Iteration: 9 \tmse_loss: 1.0178258419\n",
            "Iteration: 10 \tmse_loss: 0.9433686733\n",
            "Iteration: 11 \tmse_loss: 0.8751749992\n",
            "Iteration: 12 \tmse_loss: 0.8130106330\n",
            "Iteration: 13 \tmse_loss: 0.7562946677\n",
            "Iteration: 14 \tmse_loss: 0.7046121359\n",
            "Iteration: 15 \tmse_loss: 0.6575325727\n",
            "Iteration: 16 \tmse_loss: 0.6147093773\n",
            "Iteration: 17 \tmse_loss: 0.5757115483\n",
            "Iteration: 18 \tmse_loss: 0.5401234627\n",
            "Iteration: 19 \tmse_loss: 0.5075973868\n",
            "Iteration: 20 \tmse_loss: 0.4783084393\n",
            "Test -- Iteration: 20 \tmse_loss: 0.4513007402\n",
            "Iteration: 21 \tmse_loss: 0.4512280822\n",
            "Iteration: 22 \tmse_loss: 0.4264090955\n",
            "Iteration: 23 \tmse_loss: 0.4036726356\n",
            "Iteration: 24 \tmse_loss: 0.3828488290\n",
            "Iteration: 25 \tmse_loss: 0.3637422919\n",
            "Iteration: 26 \tmse_loss: 0.3462069035\n",
            "Iteration: 27 \tmse_loss: 0.3300892711\n",
            "Iteration: 28 \tmse_loss: 0.3152913153\n",
            "Iteration: 29 \tmse_loss: 0.3016414344\n",
            "Iteration: 30 \tmse_loss: 0.2890636325\n",
            "Iteration: 31 \tmse_loss: 0.2774700224\n",
            "Iteration: 32 \tmse_loss: 0.2667498887\n",
            "Iteration: 33 \tmse_loss: 0.2568333745\n",
            "Iteration: 34 \tmse_loss: 0.2476285696\n",
            "Iteration: 35 \tmse_loss: 0.2391068935\n",
            "Iteration: 36 \tmse_loss: 0.2311978638\n",
            "Iteration: 37 \tmse_loss: 0.2238284051\n",
            "Iteration: 38 \tmse_loss: 0.2169629335\n",
            "Iteration: 39 \tmse_loss: 0.2105651945\n",
            "Iteration: 40 \tmse_loss: 0.2057517618\n",
            "Test -- Iteration: 40 \tmse_loss: 0.2002176791\n",
            "Iteration: 41 \tmse_loss: 0.2002000511\n",
            "Iteration: 42 \tmse_loss: 0.1949952096\n",
            "Iteration: 43 \tmse_loss: 0.1901027858\n",
            "Iteration: 44 \tmse_loss: 0.1854998022\n",
            "Iteration: 45 \tmse_loss: 0.1811721474\n",
            "Iteration: 46 \tmse_loss: 0.1770928055\n",
            "Iteration: 47 \tmse_loss: 0.1732460111\n",
            "Iteration: 48 \tmse_loss: 0.1696138531\n",
            "Iteration: 49 \tmse_loss: 0.1661860049\n",
            "Iteration: 50 \tmse_loss: 0.1629482359\n",
            "Iteration: 51 \tmse_loss: 0.1598893255\n",
            "Iteration: 52 \tmse_loss: 0.1569929421\n",
            "Iteration: 53 \tmse_loss: 0.1542502344\n",
            "Iteration: 54 \tmse_loss: 0.1516513377\n",
            "Iteration: 55 \tmse_loss: 0.1491823196\n",
            "Iteration: 56 \tmse_loss: 0.1468366086\n",
            "Iteration: 57 \tmse_loss: 0.1446051598\n",
            "Iteration: 58 \tmse_loss: 0.1424844414\n",
            "Iteration: 59 \tmse_loss: 0.1404630989\n",
            "Iteration: 60 \tmse_loss: 0.1390605569\n",
            "Test -- Iteration: 60 \tmse_loss: 0.1372645944\n",
            "Iteration: 61 \tmse_loss: 0.1372466534\n",
            "Iteration: 62 \tmse_loss: 0.1355114728\n",
            "Iteration: 63 \tmse_loss: 0.1338497847\n",
            "Iteration: 64 \tmse_loss: 0.1322578490\n",
            "Iteration: 65 \tmse_loss: 0.1307315379\n",
            "Iteration: 66 \tmse_loss: 0.1292663068\n",
            "Iteration: 67 \tmse_loss: 0.1278597414\n",
            "Iteration: 68 \tmse_loss: 0.1265100986\n",
            "Iteration: 69 \tmse_loss: 0.1252125800\n",
            "Iteration: 70 \tmse_loss: 0.1239672527\n",
            "Iteration: 71 \tmse_loss: 0.1227699369\n",
            "Iteration: 72 \tmse_loss: 0.1216180995\n",
            "Iteration: 73 \tmse_loss: 0.1205095202\n",
            "Iteration: 74 \tmse_loss: 0.1194415614\n",
            "Iteration: 75 \tmse_loss: 0.1184131205\n",
            "Iteration: 76 \tmse_loss: 0.1174218133\n",
            "Iteration: 77 \tmse_loss: 0.1164653376\n",
            "Iteration: 78 \tmse_loss: 0.1155412048\n",
            "Iteration: 79 \tmse_loss: 0.1146497354\n",
            "Iteration: 80 \tmse_loss: 0.1141648740\n",
            "Test -- Iteration: 80 \tmse_loss: 0.1133562550\n",
            "Iteration: 81 \tmse_loss: 0.1133517995\n",
            "Iteration: 82 \tmse_loss: 0.1125624403\n",
            "Iteration: 83 \tmse_loss: 0.1117955074\n",
            "Iteration: 84 \tmse_loss: 0.1110514030\n",
            "Iteration: 85 \tmse_loss: 0.1103284806\n",
            "Iteration: 86 \tmse_loss: 0.1096269488\n",
            "Iteration: 87 \tmse_loss: 0.1089475676\n",
            "Iteration: 88 \tmse_loss: 0.1082900688\n",
            "Iteration: 89 \tmse_loss: 0.1076520085\n",
            "Iteration: 90 \tmse_loss: 0.1070319936\n",
            "Iteration: 91 \tmse_loss: 0.1064300761\n",
            "Iteration: 92 \tmse_loss: 0.1058441177\n",
            "Iteration: 93 \tmse_loss: 0.1052733436\n",
            "Iteration: 94 \tmse_loss: 0.1047176942\n",
            "Iteration: 95 \tmse_loss: 0.1041756794\n",
            "Iteration: 96 \tmse_loss: 0.1036475897\n",
            "Iteration: 97 \tmse_loss: 0.1031327695\n",
            "Iteration: 98 \tmse_loss: 0.1026297361\n",
            "Iteration: 99 \tmse_loss: 0.1021379232\n",
            "Iteration: 100 \tmse_loss: 0.1019508466\n",
            "Test -- Iteration: 100 \tmse_loss: 0.1014964059\n",
            "Iteration: 101 \tmse_loss: 0.1014965475\n",
            "Iteration: 102 \tmse_loss: 0.1010502204\n",
            "Iteration: 103 \tmse_loss: 0.1006119773\n",
            "Iteration: 104 \tmse_loss: 0.1001819968\n",
            "Iteration: 105 \tmse_loss: 0.0997601226\n",
            "Iteration: 106 \tmse_loss: 0.0993463174\n",
            "Iteration: 107 \tmse_loss: 0.0989405736\n",
            "Iteration: 108 \tmse_loss: 0.0985423103\n",
            "Iteration: 109 \tmse_loss: 0.0981507301\n",
            "Iteration: 110 \tmse_loss: 0.0977660492\n",
            "Iteration: 111 \tmse_loss: 0.0973882154\n",
            "Iteration: 112 \tmse_loss: 0.0970166028\n",
            "Iteration: 113 \tmse_loss: 0.0966513753\n",
            "Iteration: 114 \tmse_loss: 0.0962915868\n",
            "Iteration: 115 \tmse_loss: 0.0959382132\n",
            "Iteration: 116 \tmse_loss: 0.0955913141\n",
            "Iteration: 117 \tmse_loss: 0.0952500328\n",
            "Iteration: 118 \tmse_loss: 0.0949141160\n",
            "Iteration: 119 \tmse_loss: 0.0945830122\n",
            "Iteration: 120 \tmse_loss: 0.0945005119\n",
            "Test -- Iteration: 120 \tmse_loss: 0.0942233056\n",
            "Iteration: 121 \tmse_loss: 0.0941952989\n",
            "Iteration: 122 \tmse_loss: 0.0938938111\n",
            "Iteration: 123 \tmse_loss: 0.0935959369\n",
            "Iteration: 124 \tmse_loss: 0.0933016539\n",
            "Iteration: 125 \tmse_loss: 0.0930105299\n",
            "Iteration: 126 \tmse_loss: 0.0927221775\n",
            "Iteration: 127 \tmse_loss: 0.0924369767\n",
            "Iteration: 128 \tmse_loss: 0.0921547860\n",
            "Iteration: 129 \tmse_loss: 0.0918758065\n",
            "Iteration: 130 \tmse_loss: 0.0916001275\n",
            "Iteration: 131 \tmse_loss: 0.0913278610\n",
            "Iteration: 132 \tmse_loss: 0.0910589248\n",
            "Iteration: 133 \tmse_loss: 0.0907936096\n",
            "Iteration: 134 \tmse_loss: 0.0905315652\n",
            "Iteration: 135 \tmse_loss: 0.0902724192\n",
            "Iteration: 136 \tmse_loss: 0.0900164396\n",
            "Iteration: 137 \tmse_loss: 0.0897637010\n",
            "Iteration: 138 \tmse_loss: 0.0895139873\n",
            "Iteration: 139 \tmse_loss: 0.0892670974\n",
            "Iteration: 140 \tmse_loss: 0.0892974585\n",
            "Test -- Iteration: 140 \tmse_loss: 0.0890847221\n",
            "Iteration: 141 \tmse_loss: 0.0890720785\n",
            "Iteration: 142 \tmse_loss: 0.0888476744\n",
            "Iteration: 143 \tmse_loss: 0.0886248127\n",
            "Iteration: 144 \tmse_loss: 0.0884030908\n",
            "Iteration: 145 \tmse_loss: 0.0881825909\n",
            "Iteration: 146 \tmse_loss: 0.0879631788\n",
            "Iteration: 147 \tmse_loss: 0.0877454430\n",
            "Iteration: 148 \tmse_loss: 0.0875294954\n",
            "Iteration: 149 \tmse_loss: 0.0873152092\n",
            "Iteration: 150 \tmse_loss: 0.0871024877\n",
            "Iteration: 151 \tmse_loss: 0.0868915021\n",
            "Iteration: 152 \tmse_loss: 0.0866823420\n",
            "Iteration: 153 \tmse_loss: 0.0864748731\n",
            "Iteration: 154 \tmse_loss: 0.0862692297\n",
            "Iteration: 155 \tmse_loss: 0.0860655382\n",
            "Iteration: 156 \tmse_loss: 0.0858637691\n",
            "Iteration: 157 \tmse_loss: 0.0856637955\n",
            "Iteration: 158 \tmse_loss: 0.0854657143\n",
            "Iteration: 159 \tmse_loss: 0.0852693319\n",
            "Iteration: 160 \tmse_loss: 0.0853788108\n",
            "Test -- Iteration: 160 \tmse_loss: 0.0851640925\n",
            "Iteration: 161 \tmse_loss: 0.0852016509\n",
            "Iteration: 162 \tmse_loss: 0.0850246996\n",
            "Iteration: 163 \tmse_loss: 0.0848476738\n",
            "Iteration: 164 \tmse_loss: 0.0846707448\n",
            "Iteration: 165 \tmse_loss: 0.0844941586\n",
            "Iteration: 166 \tmse_loss: 0.0843181685\n",
            "Iteration: 167 \tmse_loss: 0.0841426253\n",
            "Iteration: 168 \tmse_loss: 0.0839677379\n",
            "Iteration: 169 \tmse_loss: 0.0837936103\n",
            "Iteration: 170 \tmse_loss: 0.0836204514\n",
            "Iteration: 171 \tmse_loss: 0.0834482238\n",
            "Iteration: 172 \tmse_loss: 0.0832769871\n",
            "Iteration: 173 \tmse_loss: 0.0831068009\n",
            "Iteration: 174 \tmse_loss: 0.0829376429\n",
            "Iteration: 175 \tmse_loss: 0.0827696547\n",
            "Iteration: 176 \tmse_loss: 0.0826028958\n",
            "Iteration: 177 \tmse_loss: 0.0824372396\n",
            "Iteration: 178 \tmse_loss: 0.0822728798\n",
            "Iteration: 179 \tmse_loss: 0.0821097493\n",
            "Iteration: 180 \tmse_loss: 0.0821643472\n",
            "Test -- Iteration: 180 \tmse_loss: 0.0820225999\n",
            "Iteration: 181 \tmse_loss: 0.0820197463\n",
            "Iteration: 182 \tmse_loss: 0.0818745345\n",
            "Iteration: 183 \tmse_loss: 0.0817288086\n",
            "Iteration: 184 \tmse_loss: 0.0815828294\n",
            "Iteration: 185 \tmse_loss: 0.0814367011\n",
            "Iteration: 186 \tmse_loss: 0.0812904164\n",
            "Iteration: 187 \tmse_loss: 0.0811442062\n",
            "Iteration: 188 \tmse_loss: 0.0809983909\n",
            "Iteration: 189 \tmse_loss: 0.0808528289\n",
            "Iteration: 190 \tmse_loss: 0.0807078034\n",
            "Iteration: 191 \tmse_loss: 0.0805632621\n",
            "Iteration: 192 \tmse_loss: 0.0804191828\n",
            "Iteration: 193 \tmse_loss: 0.0802757069\n",
            "Iteration: 194 \tmse_loss: 0.0801329985\n",
            "Iteration: 195 \tmse_loss: 0.0799908862\n",
            "Iteration: 196 \tmse_loss: 0.0798496231\n",
            "Iteration: 197 \tmse_loss: 0.0797091275\n",
            "Iteration: 198 \tmse_loss: 0.0795694068\n",
            "Final loss \tmse_loss: 0.0795694068\n",
            "Iteration: 0 \tmse_loss: 0.0800970867\n",
            "Test -- Iteration: 0 \tmse_loss: 0.0769459531\n",
            "Iteration: 1 \tmse_loss: 0.0769326165\n",
            "Iteration: 2 \tmse_loss: 0.0729136318\n",
            "Iteration: 3 \tmse_loss: 0.0698310286\n",
            "Iteration: 4 \tmse_loss: 0.0676930770\n",
            "Iteration: 5 \tmse_loss: 0.0664651915\n",
            "Iteration: 6 \tmse_loss: 0.0654146895\n",
            "Iteration: 7 \tmse_loss: 0.0644489825\n",
            "Iteration: 8 \tmse_loss: 0.0636685118\n",
            "Iteration: 9 \tmse_loss: 0.0631084442\n",
            "Iteration: 10 \tmse_loss: 0.0626822039\n",
            "Iteration: 11 \tmse_loss: 0.0623282529\n",
            "Iteration: 12 \tmse_loss: 0.0620356649\n",
            "Iteration: 13 \tmse_loss: 0.0617918223\n",
            "Iteration: 14 \tmse_loss: 0.0615500659\n",
            "Iteration: 15 \tmse_loss: 0.0612980314\n",
            "Iteration: 16 \tmse_loss: 0.0610498376\n",
            "Iteration: 17 \tmse_loss: 0.0608102418\n",
            "Iteration: 18 \tmse_loss: 0.0605790913\n",
            "Iteration: 19 \tmse_loss: 0.0603572987\n",
            "Iteration: 20 \tmse_loss: 0.0645684600\n",
            "Test -- Iteration: 20 \tmse_loss: 0.0644015223\n",
            "Iteration: 21 \tmse_loss: 0.0642974824\n",
            "Iteration: 22 \tmse_loss: 0.0638908073\n",
            "Iteration: 23 \tmse_loss: 0.0634238794\n",
            "Iteration: 24 \tmse_loss: 0.0629321188\n",
            "Iteration: 25 \tmse_loss: 0.0624338984\n",
            "Iteration: 26 \tmse_loss: 0.0619445108\n",
            "Iteration: 27 \tmse_loss: 0.0614762120\n",
            "Iteration: 28 \tmse_loss: 0.0610306598\n",
            "Iteration: 29 \tmse_loss: 0.0606125072\n",
            "Iteration: 30 \tmse_loss: 0.0602290891\n",
            "Iteration: 31 \tmse_loss: 0.0598806329\n",
            "Iteration: 32 \tmse_loss: 0.0595571920\n",
            "Iteration: 33 \tmse_loss: 0.0592534281\n",
            "Iteration: 34 \tmse_loss: 0.0589644127\n",
            "Iteration: 35 \tmse_loss: 0.0586907379\n",
            "Iteration: 36 \tmse_loss: 0.0584301017\n",
            "Iteration: 37 \tmse_loss: 0.0581784025\n",
            "Iteration: 38 \tmse_loss: 0.0579380691\n",
            "Iteration: 39 \tmse_loss: 0.0577061549\n",
            "Iteration: 40 \tmse_loss: 0.0626042485\n",
            "Test -- Iteration: 40 \tmse_loss: 0.0625276268\n",
            "Iteration: 41 \tmse_loss: 0.0624183677\n",
            "Iteration: 42 \tmse_loss: 0.0620831884\n",
            "Iteration: 43 \tmse_loss: 0.0616641864\n",
            "Iteration: 44 \tmse_loss: 0.0611941330\n",
            "Iteration: 45 \tmse_loss: 0.0606989786\n",
            "Iteration: 46 \tmse_loss: 0.0602109954\n",
            "Iteration: 47 \tmse_loss: 0.0597406514\n",
            "Iteration: 48 \tmse_loss: 0.0592965893\n",
            "Iteration: 49 \tmse_loss: 0.0588894784\n",
            "Iteration: 50 \tmse_loss: 0.0585186183\n",
            "Iteration: 51 \tmse_loss: 0.0581807643\n",
            "Iteration: 52 \tmse_loss: 0.0578759536\n",
            "Iteration: 53 \tmse_loss: 0.0575987101\n",
            "Iteration: 54 \tmse_loss: 0.0573477410\n",
            "Iteration: 55 \tmse_loss: 0.0571240447\n",
            "Iteration: 56 \tmse_loss: 0.0569098555\n",
            "Iteration: 57 \tmse_loss: 0.0567166321\n",
            "Iteration: 58 \tmse_loss: 0.0565469116\n",
            "Iteration: 59 \tmse_loss: 0.0563862249\n",
            "Iteration: 60 \tmse_loss: 0.0614004917\n",
            "Test -- Iteration: 60 \tmse_loss: 0.0613579266\n",
            "Iteration: 61 \tmse_loss: 0.0612633340\n",
            "Iteration: 62 \tmse_loss: 0.0610026568\n",
            "Iteration: 63 \tmse_loss: 0.0606632903\n",
            "Iteration: 64 \tmse_loss: 0.0602746308\n",
            "Iteration: 65 \tmse_loss: 0.0598663166\n",
            "Iteration: 66 \tmse_loss: 0.0594583899\n",
            "Iteration: 67 \tmse_loss: 0.0590650812\n",
            "Iteration: 68 \tmse_loss: 0.0586935580\n",
            "Iteration: 69 \tmse_loss: 0.0583468862\n",
            "Iteration: 70 \tmse_loss: 0.0580260791\n",
            "Iteration: 71 \tmse_loss: 0.0577331856\n",
            "Iteration: 72 \tmse_loss: 0.0574625172\n",
            "Iteration: 73 \tmse_loss: 0.0572145507\n",
            "Iteration: 74 \tmse_loss: 0.0569942258\n",
            "Iteration: 75 \tmse_loss: 0.0567901656\n",
            "Iteration: 76 \tmse_loss: 0.0566000417\n",
            "Iteration: 77 \tmse_loss: 0.0564295053\n",
            "Iteration: 78 \tmse_loss: 0.0562759712\n",
            "Iteration: 79 \tmse_loss: 0.0561326109\n",
            "Iteration: 80 \tmse_loss: 0.0607664622\n",
            "Test -- Iteration: 80 \tmse_loss: 0.0607178360\n",
            "Iteration: 81 \tmse_loss: 0.0606666803\n",
            "Iteration: 82 \tmse_loss: 0.0604556054\n",
            "Iteration: 83 \tmse_loss: 0.0601757430\n",
            "Iteration: 84 \tmse_loss: 0.0598491803\n",
            "Iteration: 85 \tmse_loss: 0.0594983846\n",
            "Iteration: 86 \tmse_loss: 0.0591456071\n",
            "Iteration: 87 \tmse_loss: 0.0588013232\n",
            "Iteration: 88 \tmse_loss: 0.0584696457\n",
            "Iteration: 89 \tmse_loss: 0.0581518374\n",
            "Iteration: 90 \tmse_loss: 0.0578558594\n",
            "Iteration: 91 \tmse_loss: 0.0575770363\n",
            "Iteration: 92 \tmse_loss: 0.0573186353\n",
            "Iteration: 93 \tmse_loss: 0.0570845865\n",
            "Iteration: 94 \tmse_loss: 0.0568703376\n",
            "Iteration: 95 \tmse_loss: 0.0566713549\n",
            "Iteration: 96 \tmse_loss: 0.0564898476\n",
            "Iteration: 97 \tmse_loss: 0.0563213862\n",
            "Iteration: 98 \tmse_loss: 0.0561660565\n",
            "Iteration: 99 \tmse_loss: 0.0560269766\n",
            "Iteration: 100 \tmse_loss: 0.0602697320\n",
            "Test -- Iteration: 100 \tmse_loss: 0.0602486059\n",
            "Iteration: 101 \tmse_loss: 0.0601702407\n",
            "Iteration: 102 \tmse_loss: 0.0599870682\n",
            "Iteration: 103 \tmse_loss: 0.0597417131\n",
            "Iteration: 104 \tmse_loss: 0.0594593324\n",
            "Iteration: 105 \tmse_loss: 0.0591545738\n",
            "Iteration: 106 \tmse_loss: 0.0588438623\n",
            "Iteration: 107 \tmse_loss: 0.0585324727\n",
            "Iteration: 108 \tmse_loss: 0.0582231209\n",
            "Iteration: 109 \tmse_loss: 0.0579288565\n",
            "Iteration: 110 \tmse_loss: 0.0576464683\n",
            "Iteration: 111 \tmse_loss: 0.0573785529\n",
            "Iteration: 112 \tmse_loss: 0.0571313351\n",
            "Iteration: 113 \tmse_loss: 0.0569010489\n",
            "Iteration: 114 \tmse_loss: 0.0566928834\n",
            "Iteration: 115 \tmse_loss: 0.0564991534\n",
            "Iteration: 116 \tmse_loss: 0.0563204698\n",
            "Iteration: 117 \tmse_loss: 0.0561540760\n",
            "Iteration: 118 \tmse_loss: 0.0560050569\n",
            "Iteration: 119 \tmse_loss: 0.0558686405\n",
            "Iteration: 120 \tmse_loss: 0.0598731674\n",
            "Test -- Iteration: 120 \tmse_loss: 0.0598843507\n",
            "Iteration: 121 \tmse_loss: 0.0597857907\n",
            "Iteration: 122 \tmse_loss: 0.0596283600\n",
            "Iteration: 123 \tmse_loss: 0.0594130196\n",
            "Iteration: 124 \tmse_loss: 0.0591630712\n",
            "Iteration: 125 \tmse_loss: 0.0588903837\n",
            "Iteration: 126 \tmse_loss: 0.0586108081\n",
            "Iteration: 127 \tmse_loss: 0.0583230369\n",
            "Iteration: 128 \tmse_loss: 0.0580302253\n",
            "Iteration: 129 \tmse_loss: 0.0577460863\n",
            "Iteration: 130 \tmse_loss: 0.0574781559\n",
            "Iteration: 131 \tmse_loss: 0.0572269522\n",
            "Iteration: 132 \tmse_loss: 0.0569867417\n",
            "Iteration: 133 \tmse_loss: 0.0567640439\n",
            "Iteration: 134 \tmse_loss: 0.0565621965\n",
            "Iteration: 135 \tmse_loss: 0.0563734174\n",
            "Iteration: 136 \tmse_loss: 0.0561951585\n",
            "Iteration: 137 \tmse_loss: 0.0560336336\n",
            "Iteration: 138 \tmse_loss: 0.0558826923\n",
            "Iteration: 139 \tmse_loss: 0.0557441004\n",
            "Iteration: 140 \tmse_loss: 0.0595998392\n",
            "Test -- Iteration: 140 \tmse_loss: 0.0595888793\n",
            "Iteration: 141 \tmse_loss: 0.0595248044\n",
            "Iteration: 142 \tmse_loss: 0.0593868680\n",
            "Iteration: 143 \tmse_loss: 0.0592010282\n",
            "Iteration: 144 \tmse_loss: 0.0589817055\n",
            "Iteration: 145 \tmse_loss: 0.0587367341\n",
            "Iteration: 146 \tmse_loss: 0.0584805384\n",
            "Iteration: 147 \tmse_loss: 0.0582113191\n",
            "Iteration: 148 \tmse_loss: 0.0579417422\n",
            "Iteration: 149 \tmse_loss: 0.0576737560\n",
            "Iteration: 150 \tmse_loss: 0.0574131384\n",
            "Iteration: 151 \tmse_loss: 0.0571693853\n",
            "Iteration: 152 \tmse_loss: 0.0569432676\n",
            "Iteration: 153 \tmse_loss: 0.0567290597\n",
            "Iteration: 154 \tmse_loss: 0.0565286130\n",
            "Iteration: 155 \tmse_loss: 0.0563439243\n",
            "Iteration: 156 \tmse_loss: 0.0561691858\n",
            "Iteration: 157 \tmse_loss: 0.0560087934\n",
            "Iteration: 158 \tmse_loss: 0.0558617711\n",
            "Iteration: 159 \tmse_loss: 0.0557277612\n",
            "Iteration: 160 \tmse_loss: 0.0594082624\n",
            "Test -- Iteration: 160 \tmse_loss: 0.0593886338\n",
            "Iteration: 161 \tmse_loss: 0.0593368746\n",
            "Iteration: 162 \tmse_loss: 0.0592128523\n",
            "Iteration: 163 \tmse_loss: 0.0590434782\n",
            "Iteration: 164 \tmse_loss: 0.0588362589\n",
            "Iteration: 165 \tmse_loss: 0.0586102568\n",
            "Iteration: 166 \tmse_loss: 0.0583735555\n",
            "Iteration: 167 \tmse_loss: 0.0581206828\n",
            "Iteration: 168 \tmse_loss: 0.0578634404\n",
            "Iteration: 169 \tmse_loss: 0.0576103926\n",
            "Iteration: 170 \tmse_loss: 0.0573696084\n",
            "Iteration: 171 \tmse_loss: 0.0571372472\n",
            "Iteration: 172 \tmse_loss: 0.0569137335\n",
            "Iteration: 173 \tmse_loss: 0.0567066148\n",
            "Iteration: 174 \tmse_loss: 0.0565142334\n",
            "Iteration: 175 \tmse_loss: 0.0563307628\n",
            "Iteration: 176 \tmse_loss: 0.0561565049\n",
            "Iteration: 177 \tmse_loss: 0.0559970401\n",
            "Iteration: 178 \tmse_loss: 0.0558538698\n",
            "Iteration: 179 \tmse_loss: 0.0557193272\n",
            "Iteration: 180 \tmse_loss: 0.0592571571\n",
            "Test -- Iteration: 180 \tmse_loss: 0.0592320189\n",
            "Iteration: 181 \tmse_loss: 0.0591956526\n",
            "Iteration: 182 \tmse_loss: 0.0590827391\n",
            "Iteration: 183 \tmse_loss: 0.0589315407\n",
            "Iteration: 184 \tmse_loss: 0.0587473884\n",
            "Iteration: 185 \tmse_loss: 0.0585407205\n",
            "Iteration: 186 \tmse_loss: 0.0583155602\n",
            "Iteration: 187 \tmse_loss: 0.0580752529\n",
            "Iteration: 188 \tmse_loss: 0.0578356162\n",
            "Iteration: 189 \tmse_loss: 0.0575979725\n",
            "Iteration: 190 \tmse_loss: 0.0573654659\n",
            "Iteration: 191 \tmse_loss: 0.0571428016\n",
            "Iteration: 192 \tmse_loss: 0.0569267124\n",
            "Iteration: 193 \tmse_loss: 0.0567206740\n",
            "Iteration: 194 \tmse_loss: 0.0565302856\n",
            "Iteration: 195 \tmse_loss: 0.0563468374\n",
            "Iteration: 196 \tmse_loss: 0.0561726876\n",
            "Iteration: 197 \tmse_loss: 0.0560154468\n",
            "Iteration: 198 \tmse_loss: 0.0558729172\n",
            "Final loss \tmse_loss: 0.0558729172\n",
            "Iteration: 0 \tmse_loss: 0.0590469427\n",
            "Test -- Iteration: 0 \tmse_loss: 0.0601335131\n",
            "Iteration: 1 \tmse_loss: 0.0598204769\n",
            "Iteration: 2 \tmse_loss: 0.0589853600\n",
            "Iteration: 3 \tmse_loss: 0.0582879558\n",
            "Iteration: 4 \tmse_loss: 0.0581200905\n",
            "Iteration: 5 \tmse_loss: 0.0576832406\n",
            "Iteration: 6 \tmse_loss: 0.0571935177\n",
            "Iteration: 7 \tmse_loss: 0.0568813123\n",
            "Iteration: 8 \tmse_loss: 0.0567266233\n",
            "Iteration: 9 \tmse_loss: 0.0565831624\n",
            "Iteration: 10 \tmse_loss: 0.0563629456\n",
            "Iteration: 11 \tmse_loss: 0.0561200492\n",
            "Iteration: 12 \tmse_loss: 0.0559277050\n",
            "Iteration: 13 \tmse_loss: 0.0557745211\n",
            "Iteration: 14 \tmse_loss: 0.0556454249\n",
            "Iteration: 15 \tmse_loss: 0.0555265397\n",
            "Iteration: 16 \tmse_loss: 0.0553964749\n",
            "Iteration: 17 \tmse_loss: 0.0552693084\n",
            "Iteration: 18 \tmse_loss: 0.0551543497\n",
            "Iteration: 19 \tmse_loss: 0.0550614223\n",
            "Iteration: 20 \tmse_loss: 0.0594100207\n",
            "Test -- Iteration: 20 \tmse_loss: 0.0593608171\n",
            "Iteration: 21 \tmse_loss: 0.0593108907\n",
            "Iteration: 22 \tmse_loss: 0.0591323301\n",
            "Iteration: 23 \tmse_loss: 0.0589129329\n",
            "Iteration: 24 \tmse_loss: 0.0586800948\n",
            "Iteration: 25 \tmse_loss: 0.0584437773\n",
            "Iteration: 26 \tmse_loss: 0.0582083017\n",
            "Iteration: 27 \tmse_loss: 0.0579772592\n",
            "Iteration: 28 \tmse_loss: 0.0577442870\n",
            "Iteration: 29 \tmse_loss: 0.0575112998\n",
            "Iteration: 30 \tmse_loss: 0.0572799481\n",
            "Iteration: 31 \tmse_loss: 0.0570519753\n",
            "Iteration: 32 \tmse_loss: 0.0568294562\n",
            "Iteration: 33 \tmse_loss: 0.0566151813\n",
            "Iteration: 34 \tmse_loss: 0.0564142428\n",
            "Iteration: 35 \tmse_loss: 0.0562278554\n",
            "Iteration: 36 \tmse_loss: 0.0560589582\n",
            "Iteration: 37 \tmse_loss: 0.0559001341\n",
            "Iteration: 38 \tmse_loss: 0.0557549410\n",
            "Iteration: 39 \tmse_loss: 0.0556249693\n",
            "Iteration: 40 \tmse_loss: 0.0591086857\n",
            "Test -- Iteration: 40 \tmse_loss: 0.0591216125\n",
            "Iteration: 41 \tmse_loss: 0.0590453334\n",
            "Iteration: 42 \tmse_loss: 0.0589166321\n",
            "Iteration: 43 \tmse_loss: 0.0587467514\n",
            "Iteration: 44 \tmse_loss: 0.0585512035\n",
            "Iteration: 45 \tmse_loss: 0.0583418682\n",
            "Iteration: 46 \tmse_loss: 0.0581170656\n",
            "Iteration: 47 \tmse_loss: 0.0578895696\n",
            "Iteration: 48 \tmse_loss: 0.0576670207\n",
            "Iteration: 49 \tmse_loss: 0.0574366972\n",
            "Iteration: 50 \tmse_loss: 0.0572078824\n",
            "Iteration: 51 \tmse_loss: 0.0569886342\n",
            "Iteration: 52 \tmse_loss: 0.0567761399\n",
            "Iteration: 53 \tmse_loss: 0.0565743856\n",
            "Iteration: 54 \tmse_loss: 0.0563910641\n",
            "Iteration: 55 \tmse_loss: 0.0562216341\n",
            "Iteration: 56 \tmse_loss: 0.0560588390\n",
            "Iteration: 57 \tmse_loss: 0.0559024699\n",
            "Iteration: 58 \tmse_loss: 0.0557583310\n",
            "Iteration: 59 \tmse_loss: 0.0556297563\n",
            "Iteration: 60 \tmse_loss: 0.0589620061\n",
            "Test -- Iteration: 60 \tmse_loss: 0.0589651130\n",
            "Iteration: 61 \tmse_loss: 0.0588983782\n",
            "Iteration: 62 \tmse_loss: 0.0587853827\n",
            "Iteration: 63 \tmse_loss: 0.0586395524\n",
            "Iteration: 64 \tmse_loss: 0.0584642701\n",
            "Iteration: 65 \tmse_loss: 0.0582711995\n",
            "Iteration: 66 \tmse_loss: 0.0580716431\n",
            "Iteration: 67 \tmse_loss: 0.0578647219\n",
            "Iteration: 68 \tmse_loss: 0.0576463789\n",
            "Iteration: 69 \tmse_loss: 0.0574266128\n",
            "Iteration: 70 \tmse_loss: 0.0572064146\n",
            "Iteration: 71 \tmse_loss: 0.0569936819\n",
            "Iteration: 72 \tmse_loss: 0.0567904525\n",
            "Iteration: 73 \tmse_loss: 0.0565983504\n",
            "Iteration: 74 \tmse_loss: 0.0564177856\n",
            "Iteration: 75 \tmse_loss: 0.0562464185\n",
            "Iteration: 76 \tmse_loss: 0.0560861900\n",
            "Iteration: 77 \tmse_loss: 0.0559346639\n",
            "Iteration: 78 \tmse_loss: 0.0557904281\n",
            "Iteration: 79 \tmse_loss: 0.0556559227\n",
            "Iteration: 80 \tmse_loss: 0.0588674694\n",
            "Test -- Iteration: 80 \tmse_loss: 0.0588644408\n",
            "Iteration: 81 \tmse_loss: 0.0588116199\n",
            "Iteration: 82 \tmse_loss: 0.0587079115\n",
            "Iteration: 83 \tmse_loss: 0.0585718863\n",
            "Iteration: 84 \tmse_loss: 0.0584139600\n",
            "Iteration: 85 \tmse_loss: 0.0582363978\n",
            "Iteration: 86 \tmse_loss: 0.0580454841\n",
            "Iteration: 87 \tmse_loss: 0.0578464977\n",
            "Iteration: 88 \tmse_loss: 0.0576384142\n",
            "Iteration: 89 \tmse_loss: 0.0574216805\n",
            "Iteration: 90 \tmse_loss: 0.0572098568\n",
            "Iteration: 91 \tmse_loss: 0.0570107251\n",
            "Iteration: 92 \tmse_loss: 0.0568150133\n",
            "Iteration: 93 \tmse_loss: 0.0566265173\n",
            "Iteration: 94 \tmse_loss: 0.0564458519\n",
            "Iteration: 95 \tmse_loss: 0.0562757663\n",
            "Iteration: 96 \tmse_loss: 0.0561172403\n",
            "Iteration: 97 \tmse_loss: 0.0559666082\n",
            "Iteration: 98 \tmse_loss: 0.0558208264\n",
            "Iteration: 99 \tmse_loss: 0.0556868725\n",
            "Iteration: 100 \tmse_loss: 0.0587430671\n",
            "Test -- Iteration: 100 \tmse_loss: 0.0587704107\n",
            "Iteration: 101 \tmse_loss: 0.0586875193\n",
            "Iteration: 102 \tmse_loss: 0.0585954934\n",
            "Iteration: 103 \tmse_loss: 0.0584712029\n",
            "Iteration: 104 \tmse_loss: 0.0583223291\n",
            "Iteration: 105 \tmse_loss: 0.0581560098\n",
            "Iteration: 106 \tmse_loss: 0.0579797067\n",
            "Iteration: 107 \tmse_loss: 0.0577849224\n",
            "Iteration: 108 \tmse_loss: 0.0575827509\n",
            "Iteration: 109 \tmse_loss: 0.0573844463\n",
            "Iteration: 110 \tmse_loss: 0.0571867600\n",
            "Iteration: 111 \tmse_loss: 0.0569959134\n",
            "Iteration: 112 \tmse_loss: 0.0568072572\n",
            "Iteration: 113 \tmse_loss: 0.0566219278\n",
            "Iteration: 114 \tmse_loss: 0.0564440899\n",
            "Iteration: 115 \tmse_loss: 0.0562788360\n",
            "Iteration: 116 \tmse_loss: 0.0561197847\n",
            "Iteration: 117 \tmse_loss: 0.0559667461\n",
            "Iteration: 118 \tmse_loss: 0.0558223240\n",
            "Iteration: 119 \tmse_loss: 0.0556974262\n",
            "Iteration: 120 \tmse_loss: 0.0586286001\n",
            "Test -- Iteration: 120 \tmse_loss: 0.0586838536\n",
            "Iteration: 121 \tmse_loss: 0.0585794635\n",
            "Iteration: 122 \tmse_loss: 0.0584922545\n",
            "Iteration: 123 \tmse_loss: 0.0583789088\n",
            "Iteration: 124 \tmse_loss: 0.0582421534\n",
            "Iteration: 125 \tmse_loss: 0.0580868460\n",
            "Iteration: 126 \tmse_loss: 0.0579133816\n",
            "Iteration: 127 \tmse_loss: 0.0577249974\n",
            "Iteration: 128 \tmse_loss: 0.0575351007\n",
            "Iteration: 129 \tmse_loss: 0.0573454127\n",
            "Iteration: 130 \tmse_loss: 0.0571590699\n",
            "Iteration: 131 \tmse_loss: 0.0569734722\n",
            "Iteration: 132 \tmse_loss: 0.0567909256\n",
            "Iteration: 133 \tmse_loss: 0.0566100329\n",
            "Iteration: 134 \tmse_loss: 0.0564387776\n",
            "Iteration: 135 \tmse_loss: 0.0562736876\n",
            "Iteration: 136 \tmse_loss: 0.0561136156\n",
            "Iteration: 137 \tmse_loss: 0.0559649579\n",
            "Iteration: 138 \tmse_loss: 0.0558255985\n",
            "Iteration: 139 \tmse_loss: 0.0557012074\n",
            "Iteration: 140 \tmse_loss: 0.0585827455\n",
            "Test -- Iteration: 140 \tmse_loss: 0.0585986152\n",
            "Iteration: 141 \tmse_loss: 0.0585344620\n",
            "Iteration: 142 \tmse_loss: 0.0584547594\n",
            "Iteration: 143 \tmse_loss: 0.0583489835\n",
            "Iteration: 144 \tmse_loss: 0.0582188368\n",
            "Iteration: 145 \tmse_loss: 0.0580733307\n",
            "Iteration: 146 \tmse_loss: 0.0579122044\n",
            "Iteration: 147 \tmse_loss: 0.0577360876\n",
            "Iteration: 148 \tmse_loss: 0.0575520806\n",
            "Iteration: 149 \tmse_loss: 0.0573670082\n",
            "Iteration: 150 \tmse_loss: 0.0571885444\n",
            "Iteration: 151 \tmse_loss: 0.0570102222\n",
            "Iteration: 152 \tmse_loss: 0.0568311252\n",
            "Iteration: 153 \tmse_loss: 0.0566568375\n",
            "Iteration: 154 \tmse_loss: 0.0564888865\n",
            "Iteration: 155 \tmse_loss: 0.0563254021\n",
            "Iteration: 156 \tmse_loss: 0.0561689660\n",
            "Iteration: 157 \tmse_loss: 0.0560244061\n",
            "Iteration: 158 \tmse_loss: 0.0558870286\n",
            "Iteration: 159 \tmse_loss: 0.0557624698\n",
            "Iteration: 160 \tmse_loss: 0.0585306883\n",
            "Test -- Iteration: 160 \tmse_loss: 0.0585273877\n",
            "Iteration: 161 \tmse_loss: 0.0584825315\n",
            "Iteration: 162 \tmse_loss: 0.0584119968\n",
            "Iteration: 163 \tmse_loss: 0.0583103225\n",
            "Iteration: 164 \tmse_loss: 0.0581789762\n",
            "Iteration: 165 \tmse_loss: 0.0580460690\n",
            "Iteration: 166 \tmse_loss: 0.0578929186\n",
            "Iteration: 167 \tmse_loss: 0.0577209927\n",
            "Iteration: 168 \tmse_loss: 0.0575428307\n",
            "Iteration: 169 \tmse_loss: 0.0573690049\n",
            "Iteration: 170 \tmse_loss: 0.0571952909\n",
            "Iteration: 171 \tmse_loss: 0.0570226051\n",
            "Iteration: 172 \tmse_loss: 0.0568496659\n",
            "Iteration: 173 \tmse_loss: 0.0566772595\n",
            "Iteration: 174 \tmse_loss: 0.0565120429\n",
            "Iteration: 175 \tmse_loss: 0.0563545637\n",
            "Iteration: 176 \tmse_loss: 0.0562024340\n",
            "Iteration: 177 \tmse_loss: 0.0560590699\n",
            "Iteration: 178 \tmse_loss: 0.0559250452\n",
            "Iteration: 179 \tmse_loss: 0.0558013879\n",
            "Iteration: 180 \tmse_loss: 0.0584876016\n",
            "Test -- Iteration: 180 \tmse_loss: 0.0584592856\n",
            "Iteration: 181 \tmse_loss: 0.0584366731\n",
            "Iteration: 182 \tmse_loss: 0.0583693311\n",
            "Iteration: 183 \tmse_loss: 0.0582790934\n",
            "Iteration: 184 \tmse_loss: 0.0581588186\n",
            "Iteration: 185 \tmse_loss: 0.0580294803\n",
            "Iteration: 186 \tmse_loss: 0.0578803010\n",
            "Iteration: 187 \tmse_loss: 0.0577136427\n",
            "Iteration: 188 \tmse_loss: 0.0575469844\n",
            "Iteration: 189 \tmse_loss: 0.0573782958\n",
            "Iteration: 190 \tmse_loss: 0.0572068878\n",
            "Iteration: 191 \tmse_loss: 0.0570369028\n",
            "Iteration: 192 \tmse_loss: 0.0568708181\n",
            "Iteration: 193 \tmse_loss: 0.0567038953\n",
            "Iteration: 194 \tmse_loss: 0.0565412827\n",
            "Iteration: 195 \tmse_loss: 0.0563821830\n",
            "Iteration: 196 \tmse_loss: 0.0562299117\n",
            "Iteration: 197 \tmse_loss: 0.0560911000\n",
            "Iteration: 198 \tmse_loss: 0.0559597500\n",
            "Final loss \tmse_loss: 0.0559597500\n",
            "Iteration: 0 \tmse_loss: 0.0583061725\n",
            "Test -- Iteration: 0 \tmse_loss: 0.0605429411\n",
            "Iteration: 1 \tmse_loss: 0.0602595918\n",
            "Iteration: 2 \tmse_loss: 0.0592900887\n",
            "Iteration: 3 \tmse_loss: 0.0583530515\n",
            "Iteration: 4 \tmse_loss: 0.0583382882\n",
            "Iteration: 5 \tmse_loss: 0.0580238029\n",
            "Iteration: 6 \tmse_loss: 0.0573798902\n",
            "Iteration: 7 \tmse_loss: 0.0570738912\n",
            "Iteration: 8 \tmse_loss: 0.0569605939\n",
            "Iteration: 9 \tmse_loss: 0.0569011346\n",
            "Iteration: 10 \tmse_loss: 0.0567580797\n",
            "Iteration: 11 \tmse_loss: 0.0564824566\n",
            "Iteration: 12 \tmse_loss: 0.0562184826\n",
            "Iteration: 13 \tmse_loss: 0.0560569540\n",
            "Iteration: 14 \tmse_loss: 0.0559432171\n",
            "Iteration: 15 \tmse_loss: 0.0558428876\n",
            "Iteration: 16 \tmse_loss: 0.0557236634\n",
            "Iteration: 17 \tmse_loss: 0.0555807091\n",
            "Iteration: 18 \tmse_loss: 0.0554537848\n",
            "Iteration: 19 \tmse_loss: 0.0553496592\n",
            "Iteration: 20 \tmse_loss: 0.0585554056\n",
            "Test -- Iteration: 20 \tmse_loss: 0.0585749112\n",
            "Iteration: 21 \tmse_loss: 0.0585043095\n",
            "Iteration: 22 \tmse_loss: 0.0584089011\n",
            "Iteration: 23 \tmse_loss: 0.0582841299\n",
            "Iteration: 24 \tmse_loss: 0.0581471063\n",
            "Iteration: 25 \tmse_loss: 0.0580008626\n",
            "Iteration: 26 \tmse_loss: 0.0578476824\n",
            "Iteration: 27 \tmse_loss: 0.0576959364\n",
            "Iteration: 28 \tmse_loss: 0.0575386323\n",
            "Iteration: 29 \tmse_loss: 0.0573713630\n",
            "Iteration: 30 \tmse_loss: 0.0571935698\n",
            "Iteration: 31 \tmse_loss: 0.0570206828\n",
            "Iteration: 32 \tmse_loss: 0.0568464845\n",
            "Iteration: 33 \tmse_loss: 0.0566702597\n",
            "Iteration: 34 \tmse_loss: 0.0565012656\n",
            "Iteration: 35 \tmse_loss: 0.0563450940\n",
            "Iteration: 36 \tmse_loss: 0.0562031567\n",
            "Iteration: 37 \tmse_loss: 0.0560696609\n",
            "Iteration: 38 \tmse_loss: 0.0559372082\n",
            "Iteration: 39 \tmse_loss: 0.0558101982\n",
            "Iteration: 40 \tmse_loss: 0.0583943613\n",
            "Test -- Iteration: 40 \tmse_loss: 0.0584283881\n",
            "Iteration: 41 \tmse_loss: 0.0583439022\n",
            "Iteration: 42 \tmse_loss: 0.0582512505\n",
            "Iteration: 43 \tmse_loss: 0.0581393689\n",
            "Iteration: 44 \tmse_loss: 0.0580116548\n",
            "Iteration: 45 \tmse_loss: 0.0578736402\n",
            "Iteration: 46 \tmse_loss: 0.0577312745\n",
            "Iteration: 47 \tmse_loss: 0.0575834289\n",
            "Iteration: 48 \tmse_loss: 0.0574323982\n",
            "Iteration: 49 \tmse_loss: 0.0572756417\n",
            "Iteration: 50 \tmse_loss: 0.0571137033\n",
            "Iteration: 51 \tmse_loss: 0.0569479764\n",
            "Iteration: 52 \tmse_loss: 0.0567831621\n",
            "Iteration: 53 \tmse_loss: 0.0566155165\n",
            "Iteration: 54 \tmse_loss: 0.0564569719\n",
            "Iteration: 55 \tmse_loss: 0.0563057885\n",
            "Iteration: 56 \tmse_loss: 0.0561678521\n",
            "Iteration: 57 \tmse_loss: 0.0560369566\n",
            "Iteration: 58 \tmse_loss: 0.0559107400\n",
            "Iteration: 59 \tmse_loss: 0.0557892360\n",
            "Iteration: 60 \tmse_loss: 0.0583169945\n",
            "Test -- Iteration: 60 \tmse_loss: 0.0583517626\n",
            "Iteration: 61 \tmse_loss: 0.0582743175\n",
            "Iteration: 62 \tmse_loss: 0.0581961758\n",
            "Iteration: 63 \tmse_loss: 0.0580955893\n",
            "Iteration: 64 \tmse_loss: 0.0579750128\n",
            "Iteration: 65 \tmse_loss: 0.0578472614\n",
            "Iteration: 66 \tmse_loss: 0.0577087887\n",
            "Iteration: 67 \tmse_loss: 0.0575666390\n",
            "Iteration: 68 \tmse_loss: 0.0574178472\n",
            "Iteration: 69 \tmse_loss: 0.0572597980\n",
            "Iteration: 70 \tmse_loss: 0.0571002960\n",
            "Iteration: 71 \tmse_loss: 0.0569386259\n",
            "Iteration: 72 \tmse_loss: 0.0567726977\n",
            "Iteration: 73 \tmse_loss: 0.0566112511\n",
            "Iteration: 74 \tmse_loss: 0.0564572290\n",
            "Iteration: 75 \tmse_loss: 0.0563119426\n",
            "Iteration: 76 \tmse_loss: 0.0561722927\n",
            "Iteration: 77 \tmse_loss: 0.0560375005\n",
            "Iteration: 78 \tmse_loss: 0.0559163392\n",
            "Iteration: 79 \tmse_loss: 0.0557994321\n",
            "Iteration: 80 \tmse_loss: 0.0582841150\n",
            "Test -- Iteration: 80 \tmse_loss: 0.0582941845\n",
            "Iteration: 81 \tmse_loss: 0.0582339875\n",
            "Iteration: 82 \tmse_loss: 0.0581612438\n",
            "Iteration: 83 \tmse_loss: 0.0580663681\n",
            "Iteration: 84 \tmse_loss: 0.0579588749\n",
            "Iteration: 85 \tmse_loss: 0.0578363203\n",
            "Iteration: 86 \tmse_loss: 0.0577001423\n",
            "Iteration: 87 \tmse_loss: 0.0575634614\n",
            "Iteration: 88 \tmse_loss: 0.0574181266\n",
            "Iteration: 89 \tmse_loss: 0.0572617091\n",
            "Iteration: 90 \tmse_loss: 0.0571032241\n",
            "Iteration: 91 \tmse_loss: 0.0569432750\n",
            "Iteration: 92 \tmse_loss: 0.0567835309\n",
            "Iteration: 93 \tmse_loss: 0.0566285998\n",
            "Iteration: 94 \tmse_loss: 0.0564769991\n",
            "Iteration: 95 \tmse_loss: 0.0563320071\n",
            "Iteration: 96 \tmse_loss: 0.0561944321\n",
            "Iteration: 97 \tmse_loss: 0.0560621172\n",
            "Iteration: 98 \tmse_loss: 0.0559349544\n",
            "Iteration: 99 \tmse_loss: 0.0558165982\n",
            "Iteration: 100 \tmse_loss: 0.0581996404\n",
            "Test -- Iteration: 100 \tmse_loss: 0.0582479611\n",
            "Iteration: 101 \tmse_loss: 0.0581557229\n",
            "Iteration: 102 \tmse_loss: 0.0580880269\n",
            "Iteration: 103 \tmse_loss: 0.0579984672\n",
            "Iteration: 104 \tmse_loss: 0.0578964800\n",
            "Iteration: 105 \tmse_loss: 0.0577843301\n",
            "Iteration: 106 \tmse_loss: 0.0576593503\n",
            "Iteration: 107 \tmse_loss: 0.0575222708\n",
            "Iteration: 108 \tmse_loss: 0.0573784932\n",
            "Iteration: 109 \tmse_loss: 0.0572260097\n",
            "Iteration: 110 \tmse_loss: 0.0570730343\n",
            "Iteration: 111 \tmse_loss: 0.0569178164\n",
            "Iteration: 112 \tmse_loss: 0.0567589551\n",
            "Iteration: 113 \tmse_loss: 0.0566077493\n",
            "Iteration: 114 \tmse_loss: 0.0564634763\n",
            "Iteration: 115 \tmse_loss: 0.0563207045\n",
            "Iteration: 116 \tmse_loss: 0.0561855845\n",
            "Iteration: 117 \tmse_loss: 0.0560556725\n",
            "Iteration: 118 \tmse_loss: 0.0559312962\n",
            "Iteration: 119 \tmse_loss: 0.0558128133\n",
            "Iteration: 120 \tmse_loss: 0.0581321120\n",
            "Test -- Iteration: 120 \tmse_loss: 0.0582058392\n",
            "Iteration: 121 \tmse_loss: 0.0580869243\n",
            "Iteration: 122 \tmse_loss: 0.0580211468\n",
            "Iteration: 123 \tmse_loss: 0.0579380393\n",
            "Iteration: 124 \tmse_loss: 0.0578461848\n",
            "Iteration: 125 \tmse_loss: 0.0577338859\n",
            "Iteration: 126 \tmse_loss: 0.0576118045\n",
            "Iteration: 127 \tmse_loss: 0.0574794225\n",
            "Iteration: 128 \tmse_loss: 0.0573377274\n",
            "Iteration: 129 \tmse_loss: 0.0571889021\n",
            "Iteration: 130 \tmse_loss: 0.0570408218\n",
            "Iteration: 131 \tmse_loss: 0.0568889827\n",
            "Iteration: 132 \tmse_loss: 0.0567350797\n",
            "Iteration: 133 \tmse_loss: 0.0565881953\n",
            "Iteration: 134 \tmse_loss: 0.0564462766\n",
            "Iteration: 135 \tmse_loss: 0.0563060828\n",
            "Iteration: 136 \tmse_loss: 0.0561712012\n",
            "Iteration: 137 \tmse_loss: 0.0560406856\n",
            "Iteration: 138 \tmse_loss: 0.0559156649\n",
            "Iteration: 139 \tmse_loss: 0.0558049418\n",
            "Iteration: 140 \tmse_loss: 0.0581344627\n",
            "Test -- Iteration: 140 \tmse_loss: 0.0581581704\n",
            "Iteration: 141 \tmse_loss: 0.0580853112\n",
            "Iteration: 142 \tmse_loss: 0.0580233037\n",
            "Iteration: 143 \tmse_loss: 0.0579478778\n",
            "Iteration: 144 \tmse_loss: 0.0578598678\n",
            "Iteration: 145 \tmse_loss: 0.0577526838\n",
            "Iteration: 146 \tmse_loss: 0.0576357506\n",
            "Iteration: 147 \tmse_loss: 0.0575061366\n",
            "Iteration: 148 \tmse_loss: 0.0573644266\n",
            "Iteration: 149 \tmse_loss: 0.0572224744\n",
            "Iteration: 150 \tmse_loss: 0.0570803545\n",
            "Iteration: 151 \tmse_loss: 0.0569286868\n",
            "Iteration: 152 \tmse_loss: 0.0567787178\n",
            "Iteration: 153 \tmse_loss: 0.0566374697\n",
            "Iteration: 154 \tmse_loss: 0.0564982258\n",
            "Iteration: 155 \tmse_loss: 0.0563596375\n",
            "Iteration: 156 \tmse_loss: 0.0562258959\n",
            "Iteration: 157 \tmse_loss: 0.0560970716\n",
            "Iteration: 158 \tmse_loss: 0.0559790805\n",
            "Iteration: 159 \tmse_loss: 0.0558649264\n",
            "Iteration: 160 \tmse_loss: 0.0581173189\n",
            "Test -- Iteration: 160 \tmse_loss: 0.0581230223\n",
            "Iteration: 161 \tmse_loss: 0.0580724105\n",
            "Iteration: 162 \tmse_loss: 0.0580146126\n",
            "Iteration: 163 \tmse_loss: 0.0579424873\n",
            "Iteration: 164 \tmse_loss: 0.0578570962\n",
            "Iteration: 165 \tmse_loss: 0.0577530228\n",
            "Iteration: 166 \tmse_loss: 0.0576370843\n",
            "Iteration: 167 \tmse_loss: 0.0575106367\n",
            "Iteration: 168 \tmse_loss: 0.0573752932\n",
            "Iteration: 169 \tmse_loss: 0.0572366789\n",
            "Iteration: 170 \tmse_loss: 0.0570916831\n",
            "Iteration: 171 \tmse_loss: 0.0569422543\n",
            "Iteration: 172 \tmse_loss: 0.0568010770\n",
            "Iteration: 173 \tmse_loss: 0.0566603281\n",
            "Iteration: 174 \tmse_loss: 0.0565235615\n",
            "Iteration: 175 \tmse_loss: 0.0563848838\n",
            "Iteration: 176 \tmse_loss: 0.0562501587\n",
            "Iteration: 177 \tmse_loss: 0.0561249256\n",
            "Iteration: 178 \tmse_loss: 0.0560067669\n",
            "Iteration: 179 \tmse_loss: 0.0558925234\n",
            "Iteration: 180 \tmse_loss: 0.0581024848\n",
            "Test -- Iteration: 180 \tmse_loss: 0.0580835044\n",
            "Iteration: 181 \tmse_loss: 0.0580568388\n",
            "Iteration: 182 \tmse_loss: 0.0580026545\n",
            "Iteration: 183 \tmse_loss: 0.0579346605\n",
            "Iteration: 184 \tmse_loss: 0.0578500815\n",
            "Iteration: 185 \tmse_loss: 0.0577526912\n",
            "Iteration: 186 \tmse_loss: 0.0576385222\n",
            "Iteration: 187 \tmse_loss: 0.0575131103\n",
            "Iteration: 188 \tmse_loss: 0.0573811904\n",
            "Iteration: 189 \tmse_loss: 0.0572478697\n",
            "Iteration: 190 \tmse_loss: 0.0571051314\n",
            "Iteration: 191 \tmse_loss: 0.0569586344\n",
            "Iteration: 192 \tmse_loss: 0.0568230636\n",
            "Iteration: 193 \tmse_loss: 0.0566875488\n",
            "Iteration: 194 \tmse_loss: 0.0565483198\n",
            "Iteration: 195 \tmse_loss: 0.0564088672\n",
            "Iteration: 196 \tmse_loss: 0.0562808290\n",
            "Iteration: 197 \tmse_loss: 0.0561585948\n",
            "Iteration: 198 \tmse_loss: 0.0560422428\n",
            "Final loss \tmse_loss: 0.0560422428\n",
            "Iteration: 0 \tmse_loss: 0.0579726994\n",
            "Test -- Iteration: 0 \tmse_loss: 0.0607729964\n",
            "Iteration: 1 \tmse_loss: 0.0605085194\n",
            "Iteration: 2 \tmse_loss: 0.0595094264\n",
            "Iteration: 3 \tmse_loss: 0.0584024042\n",
            "Iteration: 4 \tmse_loss: 0.0584531128\n",
            "Iteration: 5 \tmse_loss: 0.0581835620\n",
            "Iteration: 6 \tmse_loss: 0.0574512519\n",
            "Iteration: 7 \tmse_loss: 0.0571612939\n",
            "Iteration: 8 \tmse_loss: 0.0571040958\n",
            "Iteration: 9 \tmse_loss: 0.0570859760\n",
            "Iteration: 10 \tmse_loss: 0.0569467507\n",
            "Iteration: 11 \tmse_loss: 0.0566568673\n",
            "Iteration: 12 \tmse_loss: 0.0563805588\n",
            "Iteration: 13 \tmse_loss: 0.0562160686\n",
            "Iteration: 14 \tmse_loss: 0.0561127327\n",
            "Iteration: 15 \tmse_loss: 0.0560246743\n",
            "Iteration: 16 \tmse_loss: 0.0559159629\n",
            "Iteration: 17 \tmse_loss: 0.0557801276\n",
            "Iteration: 18 \tmse_loss: 0.0556425266\n",
            "Iteration: 19 \tmse_loss: 0.0555318519\n",
            "Iteration: 20 \tmse_loss: 0.0581929237\n",
            "Test -- Iteration: 20 \tmse_loss: 0.0582446493\n",
            "Iteration: 21 \tmse_loss: 0.0581612214\n",
            "Iteration: 22 \tmse_loss: 0.0580887273\n",
            "Iteration: 23 \tmse_loss: 0.0579927489\n",
            "Iteration: 24 \tmse_loss: 0.0578910522\n",
            "Iteration: 25 \tmse_loss: 0.0577817261\n",
            "Iteration: 26 \tmse_loss: 0.0576603264\n",
            "Iteration: 27 \tmse_loss: 0.0575309619\n",
            "Iteration: 28 \tmse_loss: 0.0573977605\n",
            "Iteration: 29 \tmse_loss: 0.0572625473\n",
            "Iteration: 30 \tmse_loss: 0.0571233742\n",
            "Iteration: 31 \tmse_loss: 0.0569765978\n",
            "Iteration: 32 \tmse_loss: 0.0568263531\n",
            "Iteration: 33 \tmse_loss: 0.0566809960\n",
            "Iteration: 34 \tmse_loss: 0.0565429777\n",
            "Iteration: 35 \tmse_loss: 0.0564082563\n",
            "Iteration: 36 \tmse_loss: 0.0562831834\n",
            "Iteration: 37 \tmse_loss: 0.0561644509\n",
            "Iteration: 38 \tmse_loss: 0.0560462959\n",
            "Iteration: 39 \tmse_loss: 0.0559274070\n",
            "Iteration: 40 \tmse_loss: 0.0580561049\n",
            "Test -- Iteration: 40 \tmse_loss: 0.0581077002\n",
            "Iteration: 41 \tmse_loss: 0.0580169223\n",
            "Iteration: 42 \tmse_loss: 0.0579435676\n",
            "Iteration: 43 \tmse_loss: 0.0578561276\n",
            "Iteration: 44 \tmse_loss: 0.0577606224\n",
            "Iteration: 45 \tmse_loss: 0.0576628894\n",
            "Iteration: 46 \tmse_loss: 0.0575536229\n",
            "Iteration: 47 \tmse_loss: 0.0574319512\n",
            "Iteration: 48 \tmse_loss: 0.0573105179\n",
            "Iteration: 49 \tmse_loss: 0.0571825244\n",
            "Iteration: 50 \tmse_loss: 0.0570448004\n",
            "Iteration: 51 \tmse_loss: 0.0569054745\n",
            "Iteration: 52 \tmse_loss: 0.0567645319\n",
            "Iteration: 53 \tmse_loss: 0.0566235408\n",
            "Iteration: 54 \tmse_loss: 0.0564944632\n",
            "Iteration: 55 \tmse_loss: 0.0563654751\n",
            "Iteration: 56 \tmse_loss: 0.0562416725\n",
            "Iteration: 57 \tmse_loss: 0.0561248437\n",
            "Iteration: 58 \tmse_loss: 0.0560080260\n",
            "Iteration: 59 \tmse_loss: 0.0558955781\n",
            "Iteration: 60 \tmse_loss: 0.0579958297\n",
            "Test -- Iteration: 60 \tmse_loss: 0.0580435544\n",
            "Iteration: 61 \tmse_loss: 0.0579591952\n",
            "Iteration: 62 \tmse_loss: 0.0578948446\n",
            "Iteration: 63 \tmse_loss: 0.0578186512\n",
            "Iteration: 64 \tmse_loss: 0.0577304587\n",
            "Iteration: 65 \tmse_loss: 0.0576335639\n",
            "Iteration: 66 \tmse_loss: 0.0575275831\n",
            "Iteration: 67 \tmse_loss: 0.0574149042\n",
            "Iteration: 68 \tmse_loss: 0.0572960898\n",
            "Iteration: 69 \tmse_loss: 0.0571659170\n",
            "Iteration: 70 \tmse_loss: 0.0570273995\n",
            "Iteration: 71 \tmse_loss: 0.0568866655\n",
            "Iteration: 72 \tmse_loss: 0.0567522869\n",
            "Iteration: 73 \tmse_loss: 0.0566177964\n",
            "Iteration: 74 \tmse_loss: 0.0564837493\n",
            "Iteration: 75 \tmse_loss: 0.0563581772\n",
            "Iteration: 76 \tmse_loss: 0.0562387928\n",
            "Iteration: 77 \tmse_loss: 0.0561195724\n",
            "Iteration: 78 \tmse_loss: 0.0560038127\n",
            "Iteration: 79 \tmse_loss: 0.0558938459\n",
            "Iteration: 80 \tmse_loss: 0.0579881072\n",
            "Test -- Iteration: 80 \tmse_loss: 0.0580187514\n",
            "Iteration: 81 \tmse_loss: 0.0579510257\n",
            "Iteration: 82 \tmse_loss: 0.0578865558\n",
            "Iteration: 83 \tmse_loss: 0.0578117743\n",
            "Iteration: 84 \tmse_loss: 0.0577292554\n",
            "Iteration: 85 \tmse_loss: 0.0576400422\n",
            "Iteration: 86 \tmse_loss: 0.0575369634\n",
            "Iteration: 87 \tmse_loss: 0.0574226342\n",
            "Iteration: 88 \tmse_loss: 0.0573007427\n",
            "Iteration: 89 \tmse_loss: 0.0571730807\n",
            "Iteration: 90 \tmse_loss: 0.0570392683\n",
            "Iteration: 91 \tmse_loss: 0.0569014698\n",
            "Iteration: 92 \tmse_loss: 0.0567664169\n",
            "Iteration: 93 \tmse_loss: 0.0566306561\n",
            "Iteration: 94 \tmse_loss: 0.0565002412\n",
            "Iteration: 95 \tmse_loss: 0.0563766919\n",
            "Iteration: 96 \tmse_loss: 0.0562559962\n",
            "Iteration: 97 \tmse_loss: 0.0561366715\n",
            "Iteration: 98 \tmse_loss: 0.0560223348\n",
            "Iteration: 99 \tmse_loss: 0.0559157617\n",
            "Iteration: 100 \tmse_loss: 0.0579302050\n",
            "Test -- Iteration: 100 \tmse_loss: 0.0579912625\n",
            "Iteration: 101 \tmse_loss: 0.0578904934\n",
            "Iteration: 102 \tmse_loss: 0.0578342490\n",
            "Iteration: 103 \tmse_loss: 0.0577626824\n",
            "Iteration: 104 \tmse_loss: 0.0576833114\n",
            "Iteration: 105 \tmse_loss: 0.0575956404\n",
            "Iteration: 106 \tmse_loss: 0.0574963875\n",
            "Iteration: 107 \tmse_loss: 0.0573873110\n",
            "Iteration: 108 \tmse_loss: 0.0572673120\n",
            "Iteration: 109 \tmse_loss: 0.0571413077\n",
            "Iteration: 110 \tmse_loss: 0.0570072234\n",
            "Iteration: 111 \tmse_loss: 0.0568718314\n",
            "Iteration: 112 \tmse_loss: 0.0567381307\n",
            "Iteration: 113 \tmse_loss: 0.0566083416\n",
            "Iteration: 114 \tmse_loss: 0.0564807877\n",
            "Iteration: 115 \tmse_loss: 0.0563536920\n",
            "Iteration: 116 \tmse_loss: 0.0562360547\n",
            "Iteration: 117 \tmse_loss: 0.0561211705\n",
            "Iteration: 118 \tmse_loss: 0.0560087040\n",
            "Iteration: 119 \tmse_loss: 0.0559011400\n",
            "Iteration: 120 \tmse_loss: 0.0578787476\n",
            "Test -- Iteration: 120 \tmse_loss: 0.0579653829\n",
            "Iteration: 121 \tmse_loss: 0.0578372888\n",
            "Iteration: 122 \tmse_loss: 0.0577839278\n",
            "Iteration: 123 \tmse_loss: 0.0577187575\n",
            "Iteration: 124 \tmse_loss: 0.0576425977\n",
            "Iteration: 125 \tmse_loss: 0.0575564057\n",
            "Iteration: 126 \tmse_loss: 0.0574597120\n",
            "Iteration: 127 \tmse_loss: 0.0573513545\n",
            "Iteration: 128 \tmse_loss: 0.0572342724\n",
            "Iteration: 129 \tmse_loss: 0.0571114868\n",
            "Iteration: 130 \tmse_loss: 0.0569836348\n",
            "Iteration: 131 \tmse_loss: 0.0568512343\n",
            "Iteration: 132 \tmse_loss: 0.0567158014\n",
            "Iteration: 133 \tmse_loss: 0.0565893948\n",
            "Iteration: 134 \tmse_loss: 0.0564683415\n",
            "Iteration: 135 \tmse_loss: 0.0563433580\n",
            "Iteration: 136 \tmse_loss: 0.0562178455\n",
            "Iteration: 137 \tmse_loss: 0.0561050139\n",
            "Iteration: 138 \tmse_loss: 0.0560001954\n",
            "Iteration: 139 \tmse_loss: 0.0558948070\n",
            "Iteration: 140 \tmse_loss: 0.0579055436\n",
            "Test -- Iteration: 140 \tmse_loss: 0.0579405017\n",
            "Iteration: 141 \tmse_loss: 0.0578595810\n",
            "Iteration: 142 \tmse_loss: 0.0578089058\n",
            "Iteration: 143 \tmse_loss: 0.0577527247\n",
            "Iteration: 144 \tmse_loss: 0.0576744415\n",
            "Iteration: 145 \tmse_loss: 0.0575910099\n",
            "Iteration: 146 \tmse_loss: 0.0574969724\n",
            "Iteration: 147 \tmse_loss: 0.0573860407\n",
            "Iteration: 148 \tmse_loss: 0.0572709925\n",
            "Iteration: 149 \tmse_loss: 0.0571501963\n",
            "Iteration: 150 \tmse_loss: 0.0570208207\n",
            "Iteration: 151 \tmse_loss: 0.0568922088\n",
            "Iteration: 152 \tmse_loss: 0.0567652360\n",
            "Iteration: 153 \tmse_loss: 0.0566396937\n",
            "Iteration: 154 \tmse_loss: 0.0565143824\n",
            "Iteration: 155 \tmse_loss: 0.0563916042\n",
            "Iteration: 156 \tmse_loss: 0.0562703572\n",
            "Iteration: 157 \tmse_loss: 0.0561609045\n",
            "Iteration: 158 \tmse_loss: 0.0560545251\n",
            "Iteration: 159 \tmse_loss: 0.0559450835\n",
            "Iteration: 160 \tmse_loss: 0.0578978136\n",
            "Test -- Iteration: 160 \tmse_loss: 0.0579165183\n",
            "Iteration: 161 \tmse_loss: 0.0578589961\n",
            "Iteration: 162 \tmse_loss: 0.0578105263\n",
            "Iteration: 163 \tmse_loss: 0.0577510968\n",
            "Iteration: 164 \tmse_loss: 0.0576829873\n",
            "Iteration: 165 \tmse_loss: 0.0575987995\n",
            "Iteration: 166 \tmse_loss: 0.0575045794\n",
            "Iteration: 167 \tmse_loss: 0.0574026443\n",
            "Iteration: 168 \tmse_loss: 0.0572852045\n",
            "Iteration: 169 \tmse_loss: 0.0571620576\n",
            "Iteration: 170 \tmse_loss: 0.0570423603\n",
            "Iteration: 171 \tmse_loss: 0.0569131561\n",
            "Iteration: 172 \tmse_loss: 0.0567871295\n",
            "Iteration: 173 \tmse_loss: 0.0566637814\n",
            "Iteration: 174 \tmse_loss: 0.0565388985\n",
            "Iteration: 175 \tmse_loss: 0.0564191751\n",
            "Iteration: 176 \tmse_loss: 0.0563013479\n",
            "Iteration: 177 \tmse_loss: 0.0561860874\n",
            "Iteration: 178 \tmse_loss: 0.0560788661\n",
            "Iteration: 179 \tmse_loss: 0.0559768118\n",
            "Iteration: 180 \tmse_loss: 0.0579030104\n",
            "Test -- Iteration: 180 \tmse_loss: 0.0578923598\n",
            "Iteration: 181 \tmse_loss: 0.0578613840\n",
            "Iteration: 182 \tmse_loss: 0.0578226671\n",
            "Iteration: 183 \tmse_loss: 0.0577659793\n",
            "Iteration: 184 \tmse_loss: 0.0576879531\n",
            "Iteration: 185 \tmse_loss: 0.0576104149\n",
            "Iteration: 186 \tmse_loss: 0.0575190485\n",
            "Iteration: 187 \tmse_loss: 0.0574120656\n",
            "Iteration: 188 \tmse_loss: 0.0572986640\n",
            "Iteration: 189 \tmse_loss: 0.0571796708\n",
            "Iteration: 190 \tmse_loss: 0.0570575111\n",
            "Iteration: 191 \tmse_loss: 0.0569356270\n",
            "Iteration: 192 \tmse_loss: 0.0568093546\n",
            "Iteration: 193 \tmse_loss: 0.0566880554\n",
            "Iteration: 194 \tmse_loss: 0.0565662310\n",
            "Iteration: 195 \tmse_loss: 0.0564450696\n",
            "Iteration: 196 \tmse_loss: 0.0563262664\n",
            "Iteration: 197 \tmse_loss: 0.0562166348\n",
            "Iteration: 198 \tmse_loss: 0.0561074056\n",
            "Final loss \tmse_loss: 0.0561074056\n",
            "Iteration: 0 \tmse_loss: 2.1090972424\n",
            "Test -- Iteration: 0 \tmse_loss: 1.9541960955\n",
            "Iteration: 1 \tmse_loss: 1.9541757107\n",
            "Iteration: 2 \tmse_loss: 1.8084821701\n",
            "Iteration: 3 \tmse_loss: 1.6722882986\n",
            "Iteration: 4 \tmse_loss: 1.5457386971\n",
            "Iteration: 5 \tmse_loss: 1.4289562702\n",
            "Iteration: 6 \tmse_loss: 1.3205074072\n",
            "Iteration: 7 \tmse_loss: 1.2205760479\n",
            "Iteration: 8 \tmse_loss: 1.1289311647\n",
            "Iteration: 9 \tmse_loss: 1.0452424288\n",
            "Iteration: 10 \tmse_loss: 0.9685304761\n",
            "Iteration: 11 \tmse_loss: 0.8981584311\n",
            "Iteration: 12 \tmse_loss: 0.8340074420\n",
            "Iteration: 13 \tmse_loss: 0.7757352591\n",
            "Iteration: 14 \tmse_loss: 0.7226569653\n",
            "Iteration: 15 \tmse_loss: 0.6743716598\n",
            "Iteration: 16 \tmse_loss: 0.6304776073\n",
            "Iteration: 17 \tmse_loss: 0.5907388330\n",
            "Iteration: 18 \tmse_loss: 0.5544625521\n",
            "Iteration: 19 \tmse_loss: 0.5213899612\n",
            "Iteration: 20 \tmse_loss: 0.4914616942\n",
            "Test -- Iteration: 20 \tmse_loss: 0.4638578296\n",
            "Iteration: 21 \tmse_loss: 0.4637974203\n",
            "Iteration: 22 \tmse_loss: 0.4384906590\n",
            "Iteration: 23 \tmse_loss: 0.4152836800\n",
            "Iteration: 24 \tmse_loss: 0.3939882517\n",
            "Iteration: 25 \tmse_loss: 0.3744226098\n",
            "Iteration: 26 \tmse_loss: 0.3564807177\n",
            "Iteration: 27 \tmse_loss: 0.3399947584\n",
            "Iteration: 28 \tmse_loss: 0.3248253763\n",
            "Iteration: 29 \tmse_loss: 0.3108530939\n",
            "Iteration: 30 \tmse_loss: 0.2979243100\n",
            "Iteration: 31 \tmse_loss: 0.2859420776\n",
            "Iteration: 32 \tmse_loss: 0.2748641968\n",
            "Iteration: 33 \tmse_loss: 0.2645977437\n",
            "Iteration: 34 \tmse_loss: 0.2550671399\n",
            "Iteration: 35 \tmse_loss: 0.2462079078\n",
            "Iteration: 36 \tmse_loss: 0.2379665077\n",
            "Iteration: 37 \tmse_loss: 0.2302981019\n",
            "Iteration: 38 \tmse_loss: 0.2231504172\n",
            "Iteration: 39 \tmse_loss: 0.2164784968\n",
            "Iteration: 40 \tmse_loss: 0.2114148736\n",
            "Test -- Iteration: 40 \tmse_loss: 0.2056384981\n",
            "Iteration: 41 \tmse_loss: 0.2056281865\n",
            "Iteration: 42 \tmse_loss: 0.2001976073\n",
            "Iteration: 43 \tmse_loss: 0.1950888485\n",
            "Iteration: 44 \tmse_loss: 0.1902898848\n",
            "Iteration: 45 \tmse_loss: 0.1857742816\n",
            "Iteration: 46 \tmse_loss: 0.1815233529\n",
            "Iteration: 47 \tmse_loss: 0.1775262505\n",
            "Iteration: 48 \tmse_loss: 0.1737594604\n",
            "Iteration: 49 \tmse_loss: 0.1701997221\n",
            "Iteration: 50 \tmse_loss: 0.1668314338\n",
            "Iteration: 51 \tmse_loss: 0.1636407226\n",
            "Iteration: 52 \tmse_loss: 0.1606164575\n",
            "Iteration: 53 \tmse_loss: 0.1577488780\n",
            "Iteration: 54 \tmse_loss: 0.1550258398\n",
            "Iteration: 55 \tmse_loss: 0.1524404585\n",
            "Iteration: 56 \tmse_loss: 0.1499857157\n",
            "Iteration: 57 \tmse_loss: 0.1476523876\n",
            "Iteration: 58 \tmse_loss: 0.1454344243\n",
            "Iteration: 59 \tmse_loss: 0.1433261633\n",
            "Iteration: 60 \tmse_loss: 0.1417949349\n",
            "Test -- Iteration: 60 \tmse_loss: 0.1399499178\n",
            "Iteration: 61 \tmse_loss: 0.1399046481\n",
            "Iteration: 62 \tmse_loss: 0.1380953640\n",
            "Iteration: 63 \tmse_loss: 0.1363622546\n",
            "Iteration: 64 \tmse_loss: 0.1347001195\n",
            "Iteration: 65 \tmse_loss: 0.1331060678\n",
            "Iteration: 66 \tmse_loss: 0.1315771937\n",
            "Iteration: 67 \tmse_loss: 0.1301119328\n",
            "Iteration: 68 \tmse_loss: 0.1287054569\n",
            "Iteration: 69 \tmse_loss: 0.1273546666\n",
            "Iteration: 70 \tmse_loss: 0.1260549724\n",
            "Iteration: 71 \tmse_loss: 0.1248039827\n",
            "Iteration: 72 \tmse_loss: 0.1236010045\n",
            "Iteration: 73 \tmse_loss: 0.1224440113\n",
            "Iteration: 74 \tmse_loss: 0.1213308796\n",
            "Iteration: 75 \tmse_loss: 0.1202579439\n",
            "Iteration: 76 \tmse_loss: 0.1192234606\n",
            "Iteration: 77 \tmse_loss: 0.1182263419\n",
            "Iteration: 78 \tmse_loss: 0.1172645390\n",
            "Iteration: 79 \tmse_loss: 0.1163359433\n",
            "Iteration: 80 \tmse_loss: 0.1158695742\n",
            "Test -- Iteration: 80 \tmse_loss: 0.1149854958\n",
            "Iteration: 81 \tmse_loss: 0.1150208712\n",
            "Iteration: 82 \tmse_loss: 0.1141981184\n",
            "Iteration: 83 \tmse_loss: 0.1133998856\n",
            "Iteration: 84 \tmse_loss: 0.1126256064\n",
            "Iteration: 85 \tmse_loss: 0.1118738800\n",
            "Iteration: 86 \tmse_loss: 0.1111445054\n",
            "Iteration: 87 \tmse_loss: 0.1104368642\n",
            "Iteration: 88 \tmse_loss: 0.1097508371\n",
            "Iteration: 89 \tmse_loss: 0.1090851277\n",
            "Iteration: 90 \tmse_loss: 0.1084379330\n",
            "Iteration: 91 \tmse_loss: 0.1078093424\n",
            "Iteration: 92 \tmse_loss: 0.1071991250\n",
            "Iteration: 93 \tmse_loss: 0.1066054776\n",
            "Iteration: 94 \tmse_loss: 0.1060283855\n",
            "Iteration: 95 \tmse_loss: 0.1054656804\n",
            "Iteration: 96 \tmse_loss: 0.1049174964\n",
            "Iteration: 97 \tmse_loss: 0.1043823361\n",
            "Iteration: 98 \tmse_loss: 0.1038599014\n",
            "Iteration: 99 \tmse_loss: 0.1033502668\n",
            "Iteration: 100 \tmse_loss: 0.1031042486\n",
            "Test -- Iteration: 100 \tmse_loss: 0.1026291698\n",
            "Iteration: 101 \tmse_loss: 0.1026332900\n",
            "Iteration: 102 \tmse_loss: 0.1021700874\n",
            "Iteration: 103 \tmse_loss: 0.1017149836\n",
            "Iteration: 104 \tmse_loss: 0.1012685746\n",
            "Iteration: 105 \tmse_loss: 0.1008314490\n",
            "Iteration: 106 \tmse_loss: 0.1004031226\n",
            "Iteration: 107 \tmse_loss: 0.0999821052\n",
            "Iteration: 108 \tmse_loss: 0.0995685235\n",
            "Iteration: 109 \tmse_loss: 0.0991633087\n",
            "Iteration: 110 \tmse_loss: 0.0987652242\n",
            "Iteration: 111 \tmse_loss: 0.0983740538\n",
            "Iteration: 112 \tmse_loss: 0.0979897827\n",
            "Iteration: 113 \tmse_loss: 0.0976119637\n",
            "Iteration: 114 \tmse_loss: 0.0972407833\n",
            "Iteration: 115 \tmse_loss: 0.0968759283\n",
            "Iteration: 116 \tmse_loss: 0.0965176746\n",
            "Iteration: 117 \tmse_loss: 0.0961658582\n",
            "Iteration: 118 \tmse_loss: 0.0958196521\n",
            "Iteration: 119 \tmse_loss: 0.0954788923\n",
            "Iteration: 120 \tmse_loss: 0.0953939110\n",
            "Test -- Iteration: 120 \tmse_loss: 0.0950767249\n",
            "Iteration: 121 \tmse_loss: 0.0950786546\n",
            "Iteration: 122 \tmse_loss: 0.0947663411\n",
            "Iteration: 123 \tmse_loss: 0.0944577903\n",
            "Iteration: 124 \tmse_loss: 0.0941531956\n",
            "Iteration: 125 \tmse_loss: 0.0938521102\n",
            "Iteration: 126 \tmse_loss: 0.0935545936\n",
            "Iteration: 127 \tmse_loss: 0.0932605267\n",
            "Iteration: 128 \tmse_loss: 0.0929697305\n",
            "Iteration: 129 \tmse_loss: 0.0926821828\n",
            "Iteration: 130 \tmse_loss: 0.0923981592\n",
            "Iteration: 131 \tmse_loss: 0.0921178013\n",
            "Iteration: 132 \tmse_loss: 0.0918410495\n",
            "Iteration: 133 \tmse_loss: 0.0915673599\n",
            "Iteration: 134 \tmse_loss: 0.0912971199\n",
            "Iteration: 135 \tmse_loss: 0.0910304636\n",
            "Iteration: 136 \tmse_loss: 0.0907673463\n",
            "Iteration: 137 \tmse_loss: 0.0905074477\n",
            "Iteration: 138 \tmse_loss: 0.0902507156\n",
            "Iteration: 139 \tmse_loss: 0.0899970084\n",
            "Iteration: 140 \tmse_loss: 0.0899545625\n",
            "Test -- Iteration: 140 \tmse_loss: 0.0897582397\n",
            "Iteration: 141 \tmse_loss: 0.0897216946\n",
            "Iteration: 142 \tmse_loss: 0.0894899964\n",
            "Iteration: 143 \tmse_loss: 0.0892597213\n",
            "Iteration: 144 \tmse_loss: 0.0890308917\n",
            "Iteration: 145 \tmse_loss: 0.0888036117\n",
            "Iteration: 146 \tmse_loss: 0.0885779709\n",
            "Iteration: 147 \tmse_loss: 0.0883540213\n",
            "Iteration: 148 \tmse_loss: 0.0881319866\n",
            "Iteration: 149 \tmse_loss: 0.0879116878\n",
            "Iteration: 150 \tmse_loss: 0.0876932591\n",
            "Iteration: 151 \tmse_loss: 0.0874768272\n",
            "Iteration: 152 \tmse_loss: 0.0872623995\n",
            "Iteration: 153 \tmse_loss: 0.0870497376\n",
            "Iteration: 154 \tmse_loss: 0.0868389979\n",
            "Iteration: 155 \tmse_loss: 0.0866303295\n",
            "Iteration: 156 \tmse_loss: 0.0864237025\n",
            "Iteration: 157 \tmse_loss: 0.0862192512\n",
            "Iteration: 158 \tmse_loss: 0.0860167667\n",
            "Iteration: 159 \tmse_loss: 0.0858162716\n",
            "Iteration: 160 \tmse_loss: 0.0859111398\n",
            "Test -- Iteration: 160 \tmse_loss: 0.0857149959\n",
            "Iteration: 161 \tmse_loss: 0.0857292861\n",
            "Iteration: 162 \tmse_loss: 0.0855476856\n",
            "Iteration: 163 \tmse_loss: 0.0853667632\n",
            "Iteration: 164 \tmse_loss: 0.0851862133\n",
            "Iteration: 165 \tmse_loss: 0.0850060359\n",
            "Iteration: 166 \tmse_loss: 0.0848266035\n",
            "Iteration: 167 \tmse_loss: 0.0846479088\n",
            "Iteration: 168 \tmse_loss: 0.0844701156\n",
            "Iteration: 169 \tmse_loss: 0.0842931569\n",
            "Iteration: 170 \tmse_loss: 0.0841173083\n",
            "Iteration: 171 \tmse_loss: 0.0839425325\n",
            "Iteration: 172 \tmse_loss: 0.0837687254\n",
            "Iteration: 173 \tmse_loss: 0.0835960731\n",
            "Iteration: 174 \tmse_loss: 0.0834246576\n",
            "Iteration: 175 \tmse_loss: 0.0832545012\n",
            "Iteration: 176 \tmse_loss: 0.0830855966\n",
            "Iteration: 177 \tmse_loss: 0.0829178765\n",
            "Iteration: 178 \tmse_loss: 0.0827514157\n",
            "Iteration: 179 \tmse_loss: 0.0825863183\n",
            "Iteration: 180 \tmse_loss: 0.0826910660\n",
            "Test -- Iteration: 180 \tmse_loss: 0.0824996829\n",
            "Iteration: 181 \tmse_loss: 0.0825435445\n",
            "Iteration: 182 \tmse_loss: 0.0823956057\n",
            "Iteration: 183 \tmse_loss: 0.0822471827\n",
            "Iteration: 184 \tmse_loss: 0.0820985138\n",
            "Iteration: 185 \tmse_loss: 0.0819497928\n",
            "Iteration: 186 \tmse_loss: 0.0818012133\n",
            "Iteration: 187 \tmse_loss: 0.0816528425\n",
            "Iteration: 188 \tmse_loss: 0.0815049857\n",
            "Iteration: 189 \tmse_loss: 0.0813574716\n",
            "Iteration: 190 \tmse_loss: 0.0812104419\n",
            "Iteration: 191 \tmse_loss: 0.0810639560\n",
            "Iteration: 192 \tmse_loss: 0.0809180215\n",
            "Iteration: 193 \tmse_loss: 0.0807727352\n",
            "Iteration: 194 \tmse_loss: 0.0806282684\n",
            "Iteration: 195 \tmse_loss: 0.0804845467\n",
            "Iteration: 196 \tmse_loss: 0.0803415775\n",
            "Iteration: 197 \tmse_loss: 0.0801994056\n",
            "Iteration: 198 \tmse_loss: 0.0800581425\n",
            "Final loss \tmse_loss: 0.0800581425\n",
            "Iteration: 0 \tmse_loss: 0.0805373415\n",
            "Test -- Iteration: 0 \tmse_loss: 0.0772364289\n",
            "Iteration: 1 \tmse_loss: 0.0772484839\n",
            "Iteration: 2 \tmse_loss: 0.0730849057\n",
            "Iteration: 3 \tmse_loss: 0.0699196532\n",
            "Iteration: 4 \tmse_loss: 0.0677215755\n",
            "Iteration: 5 \tmse_loss: 0.0664900020\n",
            "Iteration: 6 \tmse_loss: 0.0654830262\n",
            "Iteration: 7 \tmse_loss: 0.0645607635\n",
            "Iteration: 8 \tmse_loss: 0.0638164729\n",
            "Iteration: 9 \tmse_loss: 0.0632989183\n",
            "Iteration: 10 \tmse_loss: 0.0629125684\n",
            "Iteration: 11 \tmse_loss: 0.0625795573\n",
            "Iteration: 12 \tmse_loss: 0.0622859895\n",
            "Iteration: 13 \tmse_loss: 0.0620336235\n",
            "Iteration: 14 \tmse_loss: 0.0617930964\n",
            "Iteration: 15 \tmse_loss: 0.0615491420\n",
            "Iteration: 16 \tmse_loss: 0.0613099560\n",
            "Iteration: 17 \tmse_loss: 0.0610799454\n",
            "Iteration: 18 \tmse_loss: 0.0608557537\n",
            "Iteration: 19 \tmse_loss: 0.0606389754\n",
            "Iteration: 20 \tmse_loss: 0.0646712631\n",
            "Test -- Iteration: 20 \tmse_loss: 0.0645248219\n",
            "Iteration: 21 \tmse_loss: 0.0643939078\n",
            "Iteration: 22 \tmse_loss: 0.0639899075\n",
            "Iteration: 23 \tmse_loss: 0.0635325238\n",
            "Iteration: 24 \tmse_loss: 0.0630578548\n",
            "Iteration: 25 \tmse_loss: 0.0625803098\n",
            "Iteration: 26 \tmse_loss: 0.0621167906\n",
            "Iteration: 27 \tmse_loss: 0.0616796389\n",
            "Iteration: 28 \tmse_loss: 0.0612690933\n",
            "Iteration: 29 \tmse_loss: 0.0608851165\n",
            "Iteration: 30 \tmse_loss: 0.0605277792\n",
            "Iteration: 31 \tmse_loss: 0.0601985790\n",
            "Iteration: 32 \tmse_loss: 0.0598964728\n",
            "Iteration: 33 \tmse_loss: 0.0596170202\n",
            "Iteration: 34 \tmse_loss: 0.0593565442\n",
            "Iteration: 35 \tmse_loss: 0.0591021776\n",
            "Iteration: 36 \tmse_loss: 0.0588586740\n",
            "Iteration: 37 \tmse_loss: 0.0586223193\n",
            "Iteration: 38 \tmse_loss: 0.0583874099\n",
            "Iteration: 39 \tmse_loss: 0.0581673421\n",
            "Iteration: 40 \tmse_loss: 0.0628730059\n",
            "Test -- Iteration: 40 \tmse_loss: 0.0627595484\n",
            "Iteration: 41 \tmse_loss: 0.0626896545\n",
            "Iteration: 42 \tmse_loss: 0.0623708442\n",
            "Iteration: 43 \tmse_loss: 0.0619737618\n",
            "Iteration: 44 \tmse_loss: 0.0615285002\n",
            "Iteration: 45 \tmse_loss: 0.0610642731\n",
            "Iteration: 46 \tmse_loss: 0.0605970658\n",
            "Iteration: 47 \tmse_loss: 0.0601400957\n",
            "Iteration: 48 \tmse_loss: 0.0597048141\n",
            "Iteration: 49 \tmse_loss: 0.0593005419\n",
            "Iteration: 50 \tmse_loss: 0.0589263029\n",
            "Iteration: 51 \tmse_loss: 0.0585835502\n",
            "Iteration: 52 \tmse_loss: 0.0582748987\n",
            "Iteration: 53 \tmse_loss: 0.0579931960\n",
            "Iteration: 54 \tmse_loss: 0.0577381067\n",
            "Iteration: 55 \tmse_loss: 0.0575025715\n",
            "Iteration: 56 \tmse_loss: 0.0572810173\n",
            "Iteration: 57 \tmse_loss: 0.0570699573\n",
            "Iteration: 58 \tmse_loss: 0.0568755642\n",
            "Iteration: 59 \tmse_loss: 0.0566953868\n",
            "Iteration: 60 \tmse_loss: 0.0615261197\n",
            "Test -- Iteration: 60 \tmse_loss: 0.0614819825\n",
            "Iteration: 61 \tmse_loss: 0.0613704026\n",
            "Iteration: 62 \tmse_loss: 0.0610974394\n",
            "Iteration: 63 \tmse_loss: 0.0607491173\n",
            "Iteration: 64 \tmse_loss: 0.0603466257\n",
            "Iteration: 65 \tmse_loss: 0.0599316731\n",
            "Iteration: 66 \tmse_loss: 0.0595199913\n",
            "Iteration: 67 \tmse_loss: 0.0591144972\n",
            "Iteration: 68 \tmse_loss: 0.0587267764\n",
            "Iteration: 69 \tmse_loss: 0.0583607703\n",
            "Iteration: 70 \tmse_loss: 0.0580219217\n",
            "Iteration: 71 \tmse_loss: 0.0577127822\n",
            "Iteration: 72 \tmse_loss: 0.0574302860\n",
            "Iteration: 73 \tmse_loss: 0.0571743436\n",
            "Iteration: 74 \tmse_loss: 0.0569439046\n",
            "Iteration: 75 \tmse_loss: 0.0567329712\n",
            "Iteration: 76 \tmse_loss: 0.0565379597\n",
            "Iteration: 77 \tmse_loss: 0.0563561171\n",
            "Iteration: 78 \tmse_loss: 0.0561860390\n",
            "Iteration: 79 \tmse_loss: 0.0560269393\n",
            "Iteration: 80 \tmse_loss: 0.0607006736\n",
            "Test -- Iteration: 80 \tmse_loss: 0.0606117286\n",
            "Iteration: 81 \tmse_loss: 0.0605692565\n",
            "Iteration: 82 \tmse_loss: 0.0603408180\n",
            "Iteration: 83 \tmse_loss: 0.0600506701\n",
            "Iteration: 84 \tmse_loss: 0.0597182475\n",
            "Iteration: 85 \tmse_loss: 0.0593629219\n",
            "Iteration: 86 \tmse_loss: 0.0590080693\n",
            "Iteration: 87 \tmse_loss: 0.0586625189\n",
            "Iteration: 88 \tmse_loss: 0.0583242849\n",
            "Iteration: 89 \tmse_loss: 0.0579996333\n",
            "Iteration: 90 \tmse_loss: 0.0576973446\n",
            "Iteration: 91 \tmse_loss: 0.0574211329\n",
            "Iteration: 92 \tmse_loss: 0.0571692772\n",
            "Iteration: 93 \tmse_loss: 0.0569419675\n",
            "Iteration: 94 \tmse_loss: 0.0567341298\n",
            "Iteration: 95 \tmse_loss: 0.0565416701\n",
            "Iteration: 96 \tmse_loss: 0.0563631020\n",
            "Iteration: 97 \tmse_loss: 0.0561973490\n",
            "Iteration: 98 \tmse_loss: 0.0560402647\n",
            "Iteration: 99 \tmse_loss: 0.0558925606\n",
            "Iteration: 100 \tmse_loss: 0.0601104349\n",
            "Test -- Iteration: 100 \tmse_loss: 0.0600721240\n",
            "Iteration: 101 \tmse_loss: 0.0600055009\n",
            "Iteration: 102 \tmse_loss: 0.0598198771\n",
            "Iteration: 103 \tmse_loss: 0.0595779307\n",
            "Iteration: 104 \tmse_loss: 0.0592995957\n",
            "Iteration: 105 \tmse_loss: 0.0590027347\n",
            "Iteration: 106 \tmse_loss: 0.0586936809\n",
            "Iteration: 107 \tmse_loss: 0.0583859868\n",
            "Iteration: 108 \tmse_loss: 0.0580763631\n",
            "Iteration: 109 \tmse_loss: 0.0577759407\n",
            "Iteration: 110 \tmse_loss: 0.0574959554\n",
            "Iteration: 111 \tmse_loss: 0.0572355501\n",
            "Iteration: 112 \tmse_loss: 0.0569996908\n",
            "Iteration: 113 \tmse_loss: 0.0567849129\n",
            "Iteration: 114 \tmse_loss: 0.0565889180\n",
            "Iteration: 115 \tmse_loss: 0.0564090908\n",
            "Iteration: 116 \tmse_loss: 0.0562390834\n",
            "Iteration: 117 \tmse_loss: 0.0560807362\n",
            "Iteration: 118 \tmse_loss: 0.0559330918\n",
            "Iteration: 119 \tmse_loss: 0.0557924397\n",
            "Iteration: 120 \tmse_loss: 0.0597014427\n",
            "Test -- Iteration: 120 \tmse_loss: 0.0596910305\n",
            "Iteration: 121 \tmse_loss: 0.0596100353\n",
            "Iteration: 122 \tmse_loss: 0.0594508722\n",
            "Iteration: 123 \tmse_loss: 0.0592424758\n",
            "Iteration: 124 \tmse_loss: 0.0590002201\n",
            "Iteration: 125 \tmse_loss: 0.0587362498\n",
            "Iteration: 126 \tmse_loss: 0.0584546961\n",
            "Iteration: 127 \tmse_loss: 0.0581695810\n",
            "Iteration: 128 \tmse_loss: 0.0578810833\n",
            "Iteration: 129 \tmse_loss: 0.0576035976\n",
            "Iteration: 130 \tmse_loss: 0.0573394522\n",
            "Iteration: 131 \tmse_loss: 0.0570920259\n",
            "Iteration: 132 \tmse_loss: 0.0568644442\n",
            "Iteration: 133 \tmse_loss: 0.0566572025\n",
            "Iteration: 134 \tmse_loss: 0.0564636588\n",
            "Iteration: 135 \tmse_loss: 0.0562817045\n",
            "Iteration: 136 \tmse_loss: 0.0561154746\n",
            "Iteration: 137 \tmse_loss: 0.0559615903\n",
            "Iteration: 138 \tmse_loss: 0.0558191650\n",
            "Iteration: 139 \tmse_loss: 0.0556865148\n",
            "Iteration: 140 \tmse_loss: 0.0594031736\n",
            "Test -- Iteration: 140 \tmse_loss: 0.0594233982\n",
            "Iteration: 141 \tmse_loss: 0.0593245924\n",
            "Iteration: 142 \tmse_loss: 0.0591858029\n",
            "Iteration: 143 \tmse_loss: 0.0589984357\n",
            "Iteration: 144 \tmse_loss: 0.0587866008\n",
            "Iteration: 145 \tmse_loss: 0.0585471801\n",
            "Iteration: 146 \tmse_loss: 0.0582953580\n",
            "Iteration: 147 \tmse_loss: 0.0580291338\n",
            "Iteration: 148 \tmse_loss: 0.0577617846\n",
            "Iteration: 149 \tmse_loss: 0.0575042665\n",
            "Iteration: 150 \tmse_loss: 0.0572538078\n",
            "Iteration: 151 \tmse_loss: 0.0570166446\n",
            "Iteration: 152 \tmse_loss: 0.0567996241\n",
            "Iteration: 153 \tmse_loss: 0.0565965101\n",
            "Iteration: 154 \tmse_loss: 0.0564058274\n",
            "Iteration: 155 \tmse_loss: 0.0562305413\n",
            "Iteration: 156 \tmse_loss: 0.0560676642\n",
            "Iteration: 157 \tmse_loss: 0.0559114106\n",
            "Iteration: 158 \tmse_loss: 0.0557738058\n",
            "Iteration: 159 \tmse_loss: 0.0556478240\n",
            "Iteration: 160 \tmse_loss: 0.0592493862\n",
            "Test -- Iteration: 160 \tmse_loss: 0.0592146330\n",
            "Iteration: 161 \tmse_loss: 0.0591836013\n",
            "Iteration: 162 \tmse_loss: 0.0590613373\n",
            "Iteration: 163 \tmse_loss: 0.0588931628\n",
            "Iteration: 164 \tmse_loss: 0.0586935543\n",
            "Iteration: 165 \tmse_loss: 0.0584739707\n",
            "Iteration: 166 \tmse_loss: 0.0582402125\n",
            "Iteration: 167 \tmse_loss: 0.0579934381\n",
            "Iteration: 168 \tmse_loss: 0.0577465594\n",
            "Iteration: 169 \tmse_loss: 0.0574979633\n",
            "Iteration: 170 \tmse_loss: 0.0572604500\n",
            "Iteration: 171 \tmse_loss: 0.0570373572\n",
            "Iteration: 172 \tmse_loss: 0.0568277463\n",
            "Iteration: 173 \tmse_loss: 0.0566273555\n",
            "Iteration: 174 \tmse_loss: 0.0564409345\n",
            "Iteration: 175 \tmse_loss: 0.0562676564\n",
            "Iteration: 176 \tmse_loss: 0.0561083406\n",
            "Iteration: 177 \tmse_loss: 0.0559576042\n",
            "Iteration: 178 \tmse_loss: 0.0558151379\n",
            "Iteration: 179 \tmse_loss: 0.0556908548\n",
            "Iteration: 180 \tmse_loss: 0.0591006540\n",
            "Test -- Iteration: 180 \tmse_loss: 0.0590586327\n",
            "Iteration: 181 \tmse_loss: 0.0590366311\n",
            "Iteration: 182 \tmse_loss: 0.0589237697\n",
            "Iteration: 183 \tmse_loss: 0.0587663613\n",
            "Iteration: 184 \tmse_loss: 0.0585829578\n",
            "Iteration: 185 \tmse_loss: 0.0583809055\n",
            "Iteration: 186 \tmse_loss: 0.0581685752\n",
            "Iteration: 187 \tmse_loss: 0.0579376034\n",
            "Iteration: 188 \tmse_loss: 0.0577011034\n",
            "Iteration: 189 \tmse_loss: 0.0574649982\n",
            "Iteration: 190 \tmse_loss: 0.0572366193\n",
            "Iteration: 191 \tmse_loss: 0.0570221692\n",
            "Iteration: 192 \tmse_loss: 0.0568129458\n",
            "Iteration: 193 \tmse_loss: 0.0566178188\n",
            "Iteration: 194 \tmse_loss: 0.0564362742\n",
            "Iteration: 195 \tmse_loss: 0.0562632419\n",
            "Iteration: 196 \tmse_loss: 0.0561021306\n",
            "Iteration: 197 \tmse_loss: 0.0559561253\n",
            "Iteration: 198 \tmse_loss: 0.0558210164\n",
            "Final loss \tmse_loss: 0.0558210164\n",
            "Iteration: 0 \tmse_loss: 0.0589037240\n",
            "Test -- Iteration: 0 \tmse_loss: 0.0600007549\n",
            "Iteration: 1 \tmse_loss: 0.0597057864\n",
            "Iteration: 2 \tmse_loss: 0.0589638762\n",
            "Iteration: 3 \tmse_loss: 0.0581376590\n",
            "Iteration: 4 \tmse_loss: 0.0580349937\n",
            "Iteration: 5 \tmse_loss: 0.0575963371\n",
            "Iteration: 6 \tmse_loss: 0.0570716634\n",
            "Iteration: 7 \tmse_loss: 0.0567816943\n",
            "Iteration: 8 \tmse_loss: 0.0566334836\n",
            "Iteration: 9 \tmse_loss: 0.0565064549\n",
            "Iteration: 10 \tmse_loss: 0.0563205890\n",
            "Iteration: 11 \tmse_loss: 0.0560790375\n",
            "Iteration: 12 \tmse_loss: 0.0558589138\n",
            "Iteration: 13 \tmse_loss: 0.0557061285\n",
            "Iteration: 14 \tmse_loss: 0.0555904172\n",
            "Iteration: 15 \tmse_loss: 0.0554757901\n",
            "Iteration: 16 \tmse_loss: 0.0553554408\n",
            "Iteration: 17 \tmse_loss: 0.0552347302\n",
            "Iteration: 18 \tmse_loss: 0.0551177040\n",
            "Iteration: 19 \tmse_loss: 0.0550175644\n",
            "Iteration: 20 \tmse_loss: 0.0592027232\n",
            "Test -- Iteration: 20 \tmse_loss: 0.0591889732\n",
            "Iteration: 21 \tmse_loss: 0.0591116026\n",
            "Iteration: 22 \tmse_loss: 0.0589399487\n",
            "Iteration: 23 \tmse_loss: 0.0587240830\n",
            "Iteration: 24 \tmse_loss: 0.0584883615\n",
            "Iteration: 25 \tmse_loss: 0.0582549535\n",
            "Iteration: 26 \tmse_loss: 0.0580214299\n",
            "Iteration: 27 \tmse_loss: 0.0577890426\n",
            "Iteration: 28 \tmse_loss: 0.0575597137\n",
            "Iteration: 29 \tmse_loss: 0.0573340468\n",
            "Iteration: 30 \tmse_loss: 0.0571100749\n",
            "Iteration: 31 \tmse_loss: 0.0568907671\n",
            "Iteration: 32 \tmse_loss: 0.0566763878\n",
            "Iteration: 33 \tmse_loss: 0.0564661026\n",
            "Iteration: 34 \tmse_loss: 0.0562710948\n",
            "Iteration: 35 \tmse_loss: 0.0561009459\n",
            "Iteration: 36 \tmse_loss: 0.0559397601\n",
            "Iteration: 37 \tmse_loss: 0.0557886697\n",
            "Iteration: 38 \tmse_loss: 0.0556471758\n",
            "Iteration: 39 \tmse_loss: 0.0555218980\n",
            "Iteration: 40 \tmse_loss: 0.0590099357\n",
            "Test -- Iteration: 40 \tmse_loss: 0.0589696802\n",
            "Iteration: 41 \tmse_loss: 0.0589464232\n",
            "Iteration: 42 \tmse_loss: 0.0588165522\n",
            "Iteration: 43 \tmse_loss: 0.0586486161\n",
            "Iteration: 44 \tmse_loss: 0.0584533587\n",
            "Iteration: 45 \tmse_loss: 0.0582405478\n",
            "Iteration: 46 \tmse_loss: 0.0580166802\n",
            "Iteration: 47 \tmse_loss: 0.0577883571\n",
            "Iteration: 48 \tmse_loss: 0.0575653352\n",
            "Iteration: 49 \tmse_loss: 0.0573430248\n",
            "Iteration: 50 \tmse_loss: 0.0571222231\n",
            "Iteration: 51 \tmse_loss: 0.0569107905\n",
            "Iteration: 52 \tmse_loss: 0.0567065217\n",
            "Iteration: 53 \tmse_loss: 0.0565142184\n",
            "Iteration: 54 \tmse_loss: 0.0563346446\n",
            "Iteration: 55 \tmse_loss: 0.0561692268\n",
            "Iteration: 56 \tmse_loss: 0.0560147315\n",
            "Iteration: 57 \tmse_loss: 0.0558709614\n",
            "Iteration: 58 \tmse_loss: 0.0557326749\n",
            "Iteration: 59 \tmse_loss: 0.0556041226\n",
            "Iteration: 60 \tmse_loss: 0.0588142313\n",
            "Test -- Iteration: 60 \tmse_loss: 0.0588226281\n",
            "Iteration: 61 \tmse_loss: 0.0587526821\n",
            "Iteration: 62 \tmse_loss: 0.0586367249\n",
            "Iteration: 63 \tmse_loss: 0.0584898666\n",
            "Iteration: 64 \tmse_loss: 0.0583143272\n",
            "Iteration: 65 \tmse_loss: 0.0581235923\n",
            "Iteration: 66 \tmse_loss: 0.0579212569\n",
            "Iteration: 67 \tmse_loss: 0.0577183329\n",
            "Iteration: 68 \tmse_loss: 0.0575060509\n",
            "Iteration: 69 \tmse_loss: 0.0572887398\n",
            "Iteration: 70 \tmse_loss: 0.0570719875\n",
            "Iteration: 71 \tmse_loss: 0.0568639785\n",
            "Iteration: 72 \tmse_loss: 0.0566669293\n",
            "Iteration: 73 \tmse_loss: 0.0564798824\n",
            "Iteration: 74 \tmse_loss: 0.0563025102\n",
            "Iteration: 75 \tmse_loss: 0.0561437272\n",
            "Iteration: 76 \tmse_loss: 0.0559920780\n",
            "Iteration: 77 \tmse_loss: 0.0558455475\n",
            "Iteration: 78 \tmse_loss: 0.0557139367\n",
            "Iteration: 79 \tmse_loss: 0.0555900894\n",
            "Iteration: 80 \tmse_loss: 0.0587449297\n",
            "Test -- Iteration: 80 \tmse_loss: 0.0587137155\n",
            "Iteration: 81 \tmse_loss: 0.0586830080\n",
            "Iteration: 82 \tmse_loss: 0.0585833266\n",
            "Iteration: 83 \tmse_loss: 0.0584506765\n",
            "Iteration: 84 \tmse_loss: 0.0582897961\n",
            "Iteration: 85 \tmse_loss: 0.0581115223\n",
            "Iteration: 86 \tmse_loss: 0.0579238757\n",
            "Iteration: 87 \tmse_loss: 0.0577323809\n",
            "Iteration: 88 \tmse_loss: 0.0575269051\n",
            "Iteration: 89 \tmse_loss: 0.0573176071\n",
            "Iteration: 90 \tmse_loss: 0.0571103953\n",
            "Iteration: 91 \tmse_loss: 0.0569129325\n",
            "Iteration: 92 \tmse_loss: 0.0567182228\n",
            "Iteration: 93 \tmse_loss: 0.0565359257\n",
            "Iteration: 94 \tmse_loss: 0.0563670248\n",
            "Iteration: 95 \tmse_loss: 0.0562035069\n",
            "Iteration: 96 \tmse_loss: 0.0560511611\n",
            "Iteration: 97 \tmse_loss: 0.0559069812\n",
            "Iteration: 98 \tmse_loss: 0.0557679906\n",
            "Iteration: 99 \tmse_loss: 0.0556420535\n",
            "Iteration: 100 \tmse_loss: 0.0586395562\n",
            "Test -- Iteration: 100 \tmse_loss: 0.0586323068\n",
            "Iteration: 101 \tmse_loss: 0.0585829914\n",
            "Iteration: 102 \tmse_loss: 0.0584903099\n",
            "Iteration: 103 \tmse_loss: 0.0583695360\n",
            "Iteration: 104 \tmse_loss: 0.0582241453\n",
            "Iteration: 105 \tmse_loss: 0.0580560453\n",
            "Iteration: 106 \tmse_loss: 0.0578794666\n",
            "Iteration: 107 \tmse_loss: 0.0576935410\n",
            "Iteration: 108 \tmse_loss: 0.0574978143\n",
            "Iteration: 109 \tmse_loss: 0.0572979487\n",
            "Iteration: 110 \tmse_loss: 0.0570974909\n",
            "Iteration: 111 \tmse_loss: 0.0569121465\n",
            "Iteration: 112 \tmse_loss: 0.0567318536\n",
            "Iteration: 113 \tmse_loss: 0.0565520339\n",
            "Iteration: 114 \tmse_loss: 0.0563792773\n",
            "Iteration: 115 \tmse_loss: 0.0562189184\n",
            "Iteration: 116 \tmse_loss: 0.0560658053\n",
            "Iteration: 117 \tmse_loss: 0.0559238791\n",
            "Iteration: 118 \tmse_loss: 0.0557885617\n",
            "Iteration: 119 \tmse_loss: 0.0556636564\n",
            "Iteration: 120 \tmse_loss: 0.0585295446\n",
            "Test -- Iteration: 120 \tmse_loss: 0.0585519150\n",
            "Iteration: 121 \tmse_loss: 0.0584779643\n",
            "Iteration: 122 \tmse_loss: 0.0583908483\n",
            "Iteration: 123 \tmse_loss: 0.0582767799\n",
            "Iteration: 124 \tmse_loss: 0.0581416413\n",
            "Iteration: 125 \tmse_loss: 0.0579872765\n",
            "Iteration: 126 \tmse_loss: 0.0578200705\n",
            "Iteration: 127 \tmse_loss: 0.0576377846\n",
            "Iteration: 128 \tmse_loss: 0.0574475005\n",
            "Iteration: 129 \tmse_loss: 0.0572558008\n",
            "Iteration: 130 \tmse_loss: 0.0570688173\n",
            "Iteration: 131 \tmse_loss: 0.0568844303\n",
            "Iteration: 132 \tmse_loss: 0.0567044541\n",
            "Iteration: 133 \tmse_loss: 0.0565285496\n",
            "Iteration: 134 \tmse_loss: 0.0563625991\n",
            "Iteration: 135 \tmse_loss: 0.0562054105\n",
            "Iteration: 136 \tmse_loss: 0.0560560115\n",
            "Iteration: 137 \tmse_loss: 0.0559136420\n",
            "Iteration: 138 \tmse_loss: 0.0557783395\n",
            "Iteration: 139 \tmse_loss: 0.0556544326\n",
            "Iteration: 140 \tmse_loss: 0.0584376603\n",
            "Test -- Iteration: 140 \tmse_loss: 0.0584806688\n",
            "Iteration: 141 \tmse_loss: 0.0583883785\n",
            "Iteration: 142 \tmse_loss: 0.0583085455\n",
            "Iteration: 143 \tmse_loss: 0.0582019351\n",
            "Iteration: 144 \tmse_loss: 0.0580718257\n",
            "Iteration: 145 \tmse_loss: 0.0579324439\n",
            "Iteration: 146 \tmse_loss: 0.0577771030\n",
            "Iteration: 147 \tmse_loss: 0.0576022416\n",
            "Iteration: 148 \tmse_loss: 0.0574203096\n",
            "Iteration: 149 \tmse_loss: 0.0572373942\n",
            "Iteration: 150 \tmse_loss: 0.0570581257\n",
            "Iteration: 151 \tmse_loss: 0.0568830445\n",
            "Iteration: 152 \tmse_loss: 0.0567083955\n",
            "Iteration: 153 \tmse_loss: 0.0565391928\n",
            "Iteration: 154 \tmse_loss: 0.0563778505\n",
            "Iteration: 155 \tmse_loss: 0.0562190637\n",
            "Iteration: 156 \tmse_loss: 0.0560709275\n",
            "Iteration: 157 \tmse_loss: 0.0559316017\n",
            "Iteration: 158 \tmse_loss: 0.0558015443\n",
            "Iteration: 159 \tmse_loss: 0.0556800999\n",
            "Iteration: 160 \tmse_loss: 0.0584403649\n",
            "Test -- Iteration: 160 \tmse_loss: 0.0584117807\n",
            "Iteration: 161 \tmse_loss: 0.0583905876\n",
            "Iteration: 162 \tmse_loss: 0.0583162084\n",
            "Iteration: 163 \tmse_loss: 0.0582197458\n",
            "Iteration: 164 \tmse_loss: 0.0580973364\n",
            "Iteration: 165 \tmse_loss: 0.0579633713\n",
            "Iteration: 166 \tmse_loss: 0.0578104481\n",
            "Iteration: 167 \tmse_loss: 0.0576450527\n",
            "Iteration: 168 \tmse_loss: 0.0574731901\n",
            "Iteration: 169 \tmse_loss: 0.0572987571\n",
            "Iteration: 170 \tmse_loss: 0.0571238995\n",
            "Iteration: 171 \tmse_loss: 0.0569505692\n",
            "Iteration: 172 \tmse_loss: 0.0567784794\n",
            "Iteration: 173 \tmse_loss: 0.0566155724\n",
            "Iteration: 174 \tmse_loss: 0.0564570501\n",
            "Iteration: 175 \tmse_loss: 0.0563012511\n",
            "Iteration: 176 \tmse_loss: 0.0561521128\n",
            "Iteration: 177 \tmse_loss: 0.0560174882\n",
            "Iteration: 178 \tmse_loss: 0.0558908544\n",
            "Iteration: 179 \tmse_loss: 0.0557684079\n",
            "Iteration: 180 \tmse_loss: 0.0584059395\n",
            "Test -- Iteration: 180 \tmse_loss: 0.0583509505\n",
            "Iteration: 181 \tmse_loss: 0.0583535023\n",
            "Iteration: 182 \tmse_loss: 0.0582849383\n",
            "Iteration: 183 \tmse_loss: 0.0581937581\n",
            "Iteration: 184 \tmse_loss: 0.0580719151\n",
            "Iteration: 185 \tmse_loss: 0.0579436608\n",
            "Iteration: 186 \tmse_loss: 0.0578004755\n",
            "Iteration: 187 \tmse_loss: 0.0576368086\n",
            "Iteration: 188 \tmse_loss: 0.0574699976\n",
            "Iteration: 189 \tmse_loss: 0.0573055260\n",
            "Iteration: 190 \tmse_loss: 0.0571347699\n",
            "Iteration: 191 \tmse_loss: 0.0569701605\n",
            "Iteration: 192 \tmse_loss: 0.0568071753\n",
            "Iteration: 193 \tmse_loss: 0.0566429272\n",
            "Iteration: 194 \tmse_loss: 0.0564825237\n",
            "Iteration: 195 \tmse_loss: 0.0563282147\n",
            "Iteration: 196 \tmse_loss: 0.0561842322\n",
            "Iteration: 197 \tmse_loss: 0.0560489818\n",
            "Iteration: 198 \tmse_loss: 0.0559200421\n",
            "Final loss \tmse_loss: 0.0559200421\n",
            "Iteration: 0 \tmse_loss: 0.0582361035\n",
            "Test -- Iteration: 0 \tmse_loss: 0.0602098182\n",
            "Iteration: 1 \tmse_loss: 0.0599523336\n",
            "Iteration: 2 \tmse_loss: 0.0590840951\n",
            "Iteration: 3 \tmse_loss: 0.0581841320\n",
            "Iteration: 4 \tmse_loss: 0.0581921190\n",
            "Iteration: 5 \tmse_loss: 0.0577971525\n",
            "Iteration: 6 \tmse_loss: 0.0572246425\n",
            "Iteration: 7 \tmse_loss: 0.0569616221\n",
            "Iteration: 8 \tmse_loss: 0.0568929426\n",
            "Iteration: 9 \tmse_loss: 0.0568107553\n",
            "Iteration: 10 \tmse_loss: 0.0566080138\n",
            "Iteration: 11 \tmse_loss: 0.0563460812\n",
            "Iteration: 12 \tmse_loss: 0.0561337247\n",
            "Iteration: 13 \tmse_loss: 0.0559882596\n",
            "Iteration: 14 \tmse_loss: 0.0558698699\n",
            "Iteration: 15 \tmse_loss: 0.0557590201\n",
            "Iteration: 16 \tmse_loss: 0.0556434803\n",
            "Iteration: 17 \tmse_loss: 0.0555138700\n",
            "Iteration: 18 \tmse_loss: 0.0553973392\n",
            "Iteration: 19 \tmse_loss: 0.0553010143\n",
            "Iteration: 20 \tmse_loss: 0.0584566928\n",
            "Test -- Iteration: 20 \tmse_loss: 0.0584920123\n",
            "Iteration: 21 \tmse_loss: 0.0584060736\n",
            "Iteration: 22 \tmse_loss: 0.0583088696\n",
            "Iteration: 23 \tmse_loss: 0.0581854917\n",
            "Iteration: 24 \tmse_loss: 0.0580460466\n",
            "Iteration: 25 \tmse_loss: 0.0579011738\n",
            "Iteration: 26 \tmse_loss: 0.0577488393\n",
            "Iteration: 27 \tmse_loss: 0.0575984046\n",
            "Iteration: 28 \tmse_loss: 0.0574434623\n",
            "Iteration: 29 \tmse_loss: 0.0572777651\n",
            "Iteration: 30 \tmse_loss: 0.0571037233\n",
            "Iteration: 31 \tmse_loss: 0.0569284037\n",
            "Iteration: 32 \tmse_loss: 0.0567540899\n",
            "Iteration: 33 \tmse_loss: 0.0565859713\n",
            "Iteration: 34 \tmse_loss: 0.0564235747\n",
            "Iteration: 35 \tmse_loss: 0.0562731102\n",
            "Iteration: 36 \tmse_loss: 0.0561360791\n",
            "Iteration: 37 \tmse_loss: 0.0560064614\n",
            "Iteration: 38 \tmse_loss: 0.0558803156\n",
            "Iteration: 39 \tmse_loss: 0.0557596684\n",
            "Iteration: 40 \tmse_loss: 0.0583851114\n",
            "Test -- Iteration: 40 \tmse_loss: 0.0583559647\n",
            "Iteration: 41 \tmse_loss: 0.0583280511\n",
            "Iteration: 42 \tmse_loss: 0.0582377836\n",
            "Iteration: 43 \tmse_loss: 0.0581282899\n",
            "Iteration: 44 \tmse_loss: 0.0580033325\n",
            "Iteration: 45 \tmse_loss: 0.0578669421\n",
            "Iteration: 46 \tmse_loss: 0.0577274300\n",
            "Iteration: 47 \tmse_loss: 0.0575825125\n",
            "Iteration: 48 \tmse_loss: 0.0574325323\n",
            "Iteration: 49 \tmse_loss: 0.0572723225\n",
            "Iteration: 50 \tmse_loss: 0.0571082830\n",
            "Iteration: 51 \tmse_loss: 0.0569450818\n",
            "Iteration: 52 \tmse_loss: 0.0567769222\n",
            "Iteration: 53 \tmse_loss: 0.0566124506\n",
            "Iteration: 54 \tmse_loss: 0.0564618707\n",
            "Iteration: 55 \tmse_loss: 0.0563163087\n",
            "Iteration: 56 \tmse_loss: 0.0561746061\n",
            "Iteration: 57 \tmse_loss: 0.0560450442\n",
            "Iteration: 58 \tmse_loss: 0.0559293814\n",
            "Iteration: 59 \tmse_loss: 0.0558140129\n",
            "Iteration: 60 \tmse_loss: 0.0582602955\n",
            "Test -- Iteration: 60 \tmse_loss: 0.0582773946\n",
            "Iteration: 61 \tmse_loss: 0.0582059361\n",
            "Iteration: 62 \tmse_loss: 0.0581270196\n",
            "Iteration: 63 \tmse_loss: 0.0580269992\n",
            "Iteration: 64 \tmse_loss: 0.0579079278\n",
            "Iteration: 65 \tmse_loss: 0.0577824898\n",
            "Iteration: 66 \tmse_loss: 0.0576485172\n",
            "Iteration: 67 \tmse_loss: 0.0575087219\n",
            "Iteration: 68 \tmse_loss: 0.0573627539\n",
            "Iteration: 69 \tmse_loss: 0.0572066344\n",
            "Iteration: 70 \tmse_loss: 0.0570449121\n",
            "Iteration: 71 \tmse_loss: 0.0568821728\n",
            "Iteration: 72 \tmse_loss: 0.0567192882\n",
            "Iteration: 73 \tmse_loss: 0.0565606393\n",
            "Iteration: 74 \tmse_loss: 0.0564140864\n",
            "Iteration: 75 \tmse_loss: 0.0562716573\n",
            "Iteration: 76 \tmse_loss: 0.0561345667\n",
            "Iteration: 77 \tmse_loss: 0.0560084954\n",
            "Iteration: 78 \tmse_loss: 0.0558895320\n",
            "Iteration: 79 \tmse_loss: 0.0557728074\n",
            "Iteration: 80 \tmse_loss: 0.0582432970\n",
            "Test -- Iteration: 80 \tmse_loss: 0.0582328476\n",
            "Iteration: 81 \tmse_loss: 0.0581941046\n",
            "Iteration: 82 \tmse_loss: 0.0581189357\n",
            "Iteration: 83 \tmse_loss: 0.0580264963\n",
            "Iteration: 84 \tmse_loss: 0.0579173379\n",
            "Iteration: 85 \tmse_loss: 0.0577938631\n",
            "Iteration: 86 \tmse_loss: 0.0576661751\n",
            "Iteration: 87 \tmse_loss: 0.0575323403\n",
            "Iteration: 88 \tmse_loss: 0.0573836006\n",
            "Iteration: 89 \tmse_loss: 0.0572308600\n",
            "Iteration: 90 \tmse_loss: 0.0570756011\n",
            "Iteration: 91 \tmse_loss: 0.0569126494\n",
            "Iteration: 92 \tmse_loss: 0.0567542389\n",
            "Iteration: 93 \tmse_loss: 0.0566006787\n",
            "Iteration: 94 \tmse_loss: 0.0564564839\n",
            "Iteration: 95 \tmse_loss: 0.0563168302\n",
            "Iteration: 96 \tmse_loss: 0.0561812706\n",
            "Iteration: 97 \tmse_loss: 0.0560522117\n",
            "Iteration: 98 \tmse_loss: 0.0559304543\n",
            "Iteration: 99 \tmse_loss: 0.0558149964\n",
            "Iteration: 100 \tmse_loss: 0.0581807643\n",
            "Test -- Iteration: 100 \tmse_loss: 0.0581898503\n",
            "Iteration: 101 \tmse_loss: 0.0581332371\n",
            "Iteration: 102 \tmse_loss: 0.0580689460\n",
            "Iteration: 103 \tmse_loss: 0.0579792932\n",
            "Iteration: 104 \tmse_loss: 0.0578737333\n",
            "Iteration: 105 \tmse_loss: 0.0577603318\n",
            "Iteration: 106 \tmse_loss: 0.0576374792\n",
            "Iteration: 107 \tmse_loss: 0.0575073622\n",
            "Iteration: 108 \tmse_loss: 0.0573620498\n",
            "Iteration: 109 \tmse_loss: 0.0572099984\n",
            "Iteration: 110 \tmse_loss: 0.0570597649\n",
            "Iteration: 111 \tmse_loss: 0.0569091961\n",
            "Iteration: 112 \tmse_loss: 0.0567506067\n",
            "Iteration: 113 \tmse_loss: 0.0565961599\n",
            "Iteration: 114 \tmse_loss: 0.0564550273\n",
            "Iteration: 115 \tmse_loss: 0.0563177504\n",
            "Iteration: 116 \tmse_loss: 0.0561854504\n",
            "Iteration: 117 \tmse_loss: 0.0560556687\n",
            "Iteration: 118 \tmse_loss: 0.0559372865\n",
            "Iteration: 119 \tmse_loss: 0.0558290742\n",
            "Iteration: 120 \tmse_loss: 0.0581150800\n",
            "Test -- Iteration: 120 \tmse_loss: 0.0581447892\n",
            "Iteration: 121 \tmse_loss: 0.0580612198\n",
            "Iteration: 122 \tmse_loss: 0.0579989925\n",
            "Iteration: 123 \tmse_loss: 0.0579194166\n",
            "Iteration: 124 \tmse_loss: 0.0578211881\n",
            "Iteration: 125 \tmse_loss: 0.0577081963\n",
            "Iteration: 126 \tmse_loss: 0.0575930066\n",
            "Iteration: 127 \tmse_loss: 0.0574611947\n",
            "Iteration: 128 \tmse_loss: 0.0573208220\n",
            "Iteration: 129 \tmse_loss: 0.0571758673\n",
            "Iteration: 130 \tmse_loss: 0.0570268631\n",
            "Iteration: 131 \tmse_loss: 0.0568746813\n",
            "Iteration: 132 \tmse_loss: 0.0567236207\n",
            "Iteration: 133 \tmse_loss: 0.0565740839\n",
            "Iteration: 134 \tmse_loss: 0.0564361475\n",
            "Iteration: 135 \tmse_loss: 0.0563013367\n",
            "Iteration: 136 \tmse_loss: 0.0561653301\n",
            "Iteration: 137 \tmse_loss: 0.0560397059\n",
            "Iteration: 138 \tmse_loss: 0.0559233651\n",
            "Iteration: 139 \tmse_loss: 0.0558106154\n",
            "Iteration: 140 \tmse_loss: 0.0580526479\n",
            "Test -- Iteration: 140 \tmse_loss: 0.0581062697\n",
            "Iteration: 141 \tmse_loss: 0.0580049865\n",
            "Iteration: 142 \tmse_loss: 0.0579449907\n",
            "Iteration: 143 \tmse_loss: 0.0578698963\n",
            "Iteration: 144 \tmse_loss: 0.0577808730\n",
            "Iteration: 145 \tmse_loss: 0.0576765463\n",
            "Iteration: 146 \tmse_loss: 0.0575627126\n",
            "Iteration: 147 \tmse_loss: 0.0574362092\n",
            "Iteration: 148 \tmse_loss: 0.0572976694\n",
            "Iteration: 149 \tmse_loss: 0.0571580268\n",
            "Iteration: 150 \tmse_loss: 0.0570144616\n",
            "Iteration: 151 \tmse_loss: 0.0568612553\n",
            "Iteration: 152 \tmse_loss: 0.0567173511\n",
            "Iteration: 153 \tmse_loss: 0.0565766059\n",
            "Iteration: 154 \tmse_loss: 0.0564368591\n",
            "Iteration: 155 \tmse_loss: 0.0563030541\n",
            "Iteration: 156 \tmse_loss: 0.0561751910\n",
            "Iteration: 157 \tmse_loss: 0.0560500696\n",
            "Iteration: 158 \tmse_loss: 0.0559324510\n",
            "Iteration: 159 \tmse_loss: 0.0558227971\n",
            "Iteration: 160 \tmse_loss: 0.0580915809\n",
            "Test -- Iteration: 160 \tmse_loss: 0.0580735505\n",
            "Iteration: 161 \tmse_loss: 0.0580445863\n",
            "Iteration: 162 \tmse_loss: 0.0579885766\n",
            "Iteration: 163 \tmse_loss: 0.0579148494\n",
            "Iteration: 164 \tmse_loss: 0.0578240044\n",
            "Iteration: 165 \tmse_loss: 0.0577278696\n",
            "Iteration: 166 \tmse_loss: 0.0576170273\n",
            "Iteration: 167 \tmse_loss: 0.0574928448\n",
            "Iteration: 168 \tmse_loss: 0.0573580563\n",
            "Iteration: 169 \tmse_loss: 0.0572190136\n",
            "Iteration: 170 \tmse_loss: 0.0570789240\n",
            "Iteration: 171 \tmse_loss: 0.0569351166\n",
            "Iteration: 172 \tmse_loss: 0.0567905195\n",
            "Iteration: 173 \tmse_loss: 0.0566519871\n",
            "Iteration: 174 \tmse_loss: 0.0565164052\n",
            "Iteration: 175 \tmse_loss: 0.0563856140\n",
            "Iteration: 176 \tmse_loss: 0.0562559813\n",
            "Iteration: 177 \tmse_loss: 0.0561342649\n",
            "Iteration: 178 \tmse_loss: 0.0560178049\n",
            "Iteration: 179 \tmse_loss: 0.0559091792\n",
            "Iteration: 180 \tmse_loss: 0.0580881834\n",
            "Test -- Iteration: 180 \tmse_loss: 0.0580368415\n",
            "Iteration: 181 \tmse_loss: 0.0580377951\n",
            "Iteration: 182 \tmse_loss: 0.0579837561\n",
            "Iteration: 183 \tmse_loss: 0.0579172485\n",
            "Iteration: 184 \tmse_loss: 0.0578270070\n",
            "Iteration: 185 \tmse_loss: 0.0577350259\n",
            "Iteration: 186 \tmse_loss: 0.0576302335\n",
            "Iteration: 187 \tmse_loss: 0.0575019158\n",
            "Iteration: 188 \tmse_loss: 0.0573697053\n",
            "Iteration: 189 \tmse_loss: 0.0572360829\n",
            "Iteration: 190 \tmse_loss: 0.0570956953\n",
            "Iteration: 191 \tmse_loss: 0.0569535084\n",
            "Iteration: 192 \tmse_loss: 0.0568116121\n",
            "Iteration: 193 \tmse_loss: 0.0566731282\n",
            "Iteration: 194 \tmse_loss: 0.0565426312\n",
            "Iteration: 195 \tmse_loss: 0.0564132519\n",
            "Iteration: 196 \tmse_loss: 0.0562803410\n",
            "Iteration: 197 \tmse_loss: 0.0561639853\n",
            "Iteration: 198 \tmse_loss: 0.0560517907\n",
            "Final loss \tmse_loss: 0.0560517907\n",
            "Iteration: 0 \tmse_loss: 0.0579564050\n",
            "Test -- Iteration: 0 \tmse_loss: 0.0607836805\n",
            "Iteration: 1 \tmse_loss: 0.0605376624\n",
            "Iteration: 2 \tmse_loss: 0.0594131127\n",
            "Iteration: 3 \tmse_loss: 0.0583422557\n",
            "Iteration: 4 \tmse_loss: 0.0583953783\n",
            "Iteration: 5 \tmse_loss: 0.0581225306\n",
            "Iteration: 6 \tmse_loss: 0.0574395508\n",
            "Iteration: 7 \tmse_loss: 0.0571961626\n",
            "Iteration: 8 \tmse_loss: 0.0571631230\n",
            "Iteration: 9 \tmse_loss: 0.0571102612\n",
            "Iteration: 10 \tmse_loss: 0.0569391251\n",
            "Iteration: 11 \tmse_loss: 0.0566626228\n",
            "Iteration: 12 \tmse_loss: 0.0563917048\n",
            "Iteration: 13 \tmse_loss: 0.0562154055\n",
            "Iteration: 14 \tmse_loss: 0.0561027825\n",
            "Iteration: 15 \tmse_loss: 0.0560168065\n",
            "Iteration: 16 \tmse_loss: 0.0559174642\n",
            "Iteration: 17 \tmse_loss: 0.0557830334\n",
            "Iteration: 18 \tmse_loss: 0.0556461178\n",
            "Iteration: 19 \tmse_loss: 0.0555545948\n",
            "Iteration: 20 \tmse_loss: 0.0581660047\n",
            "Test -- Iteration: 20 \tmse_loss: 0.0582194105\n",
            "Iteration: 21 \tmse_loss: 0.0581254028\n",
            "Iteration: 22 \tmse_loss: 0.0580404401\n",
            "Iteration: 23 \tmse_loss: 0.0579456203\n",
            "Iteration: 24 \tmse_loss: 0.0578521118\n",
            "Iteration: 25 \tmse_loss: 0.0577426143\n",
            "Iteration: 26 \tmse_loss: 0.0576158166\n",
            "Iteration: 27 \tmse_loss: 0.0574876145\n",
            "Iteration: 28 \tmse_loss: 0.0573577285\n",
            "Iteration: 29 \tmse_loss: 0.0572206415\n",
            "Iteration: 30 \tmse_loss: 0.0570810772\n",
            "Iteration: 31 \tmse_loss: 0.0569337308\n",
            "Iteration: 32 \tmse_loss: 0.0567899346\n",
            "Iteration: 33 \tmse_loss: 0.0566512495\n",
            "Iteration: 34 \tmse_loss: 0.0565145686\n",
            "Iteration: 35 \tmse_loss: 0.0563812368\n",
            "Iteration: 36 \tmse_loss: 0.0562596396\n",
            "Iteration: 37 \tmse_loss: 0.0561374463\n",
            "Iteration: 38 \tmse_loss: 0.0560172200\n",
            "Iteration: 39 \tmse_loss: 0.0559063703\n",
            "Iteration: 40 \tmse_loss: 0.0580825992\n",
            "Test -- Iteration: 40 \tmse_loss: 0.0580771975\n",
            "Iteration: 41 \tmse_loss: 0.0580403246\n",
            "Iteration: 42 \tmse_loss: 0.0579701848\n",
            "Iteration: 43 \tmse_loss: 0.0578868166\n",
            "Iteration: 44 \tmse_loss: 0.0577951372\n",
            "Iteration: 45 \tmse_loss: 0.0576954633\n",
            "Iteration: 46 \tmse_loss: 0.0575831011\n",
            "Iteration: 47 \tmse_loss: 0.0574625134\n",
            "Iteration: 48 \tmse_loss: 0.0573373325\n",
            "Iteration: 49 \tmse_loss: 0.0572037399\n",
            "Iteration: 50 \tmse_loss: 0.0570686609\n",
            "Iteration: 51 \tmse_loss: 0.0569312684\n",
            "Iteration: 52 \tmse_loss: 0.0567887798\n",
            "Iteration: 53 \tmse_loss: 0.0566517189\n",
            "Iteration: 54 \tmse_loss: 0.0565222055\n",
            "Iteration: 55 \tmse_loss: 0.0563947409\n",
            "Iteration: 56 \tmse_loss: 0.0562739633\n",
            "Iteration: 57 \tmse_loss: 0.0561570302\n",
            "Iteration: 58 \tmse_loss: 0.0560404994\n",
            "Iteration: 59 \tmse_loss: 0.0559343658\n",
            "Iteration: 60 \tmse_loss: 0.0579753593\n",
            "Test -- Iteration: 60 \tmse_loss: 0.0580108874\n",
            "Iteration: 61 \tmse_loss: 0.0579305701\n",
            "Iteration: 62 \tmse_loss: 0.0578694977\n",
            "Iteration: 63 \tmse_loss: 0.0577957705\n",
            "Iteration: 64 \tmse_loss: 0.0577076152\n",
            "Iteration: 65 \tmse_loss: 0.0576102845\n",
            "Iteration: 66 \tmse_loss: 0.0575048812\n",
            "Iteration: 67 \tmse_loss: 0.0573916063\n",
            "Iteration: 68 \tmse_loss: 0.0572699383\n",
            "Iteration: 69 \tmse_loss: 0.0571394861\n",
            "Iteration: 70 \tmse_loss: 0.0570039712\n",
            "Iteration: 71 \tmse_loss: 0.0568651743\n",
            "Iteration: 72 \tmse_loss: 0.0567310899\n",
            "Iteration: 73 \tmse_loss: 0.0565962642\n",
            "Iteration: 74 \tmse_loss: 0.0564667918\n",
            "Iteration: 75 \tmse_loss: 0.0563435964\n",
            "Iteration: 76 \tmse_loss: 0.0562228635\n",
            "Iteration: 77 \tmse_loss: 0.0561091304\n",
            "Iteration: 78 \tmse_loss: 0.0559950434\n",
            "Iteration: 79 \tmse_loss: 0.0558853447\n",
            "Iteration: 80 \tmse_loss: 0.0579790547\n",
            "Test -- Iteration: 80 \tmse_loss: 0.0579876378\n",
            "Iteration: 81 \tmse_loss: 0.0579423644\n",
            "Iteration: 82 \tmse_loss: 0.0578825101\n",
            "Iteration: 83 \tmse_loss: 0.0578081608\n",
            "Iteration: 84 \tmse_loss: 0.0577250682\n",
            "Iteration: 85 \tmse_loss: 0.0576345064\n",
            "Iteration: 86 \tmse_loss: 0.0575316250\n",
            "Iteration: 87 \tmse_loss: 0.0574206300\n",
            "Iteration: 88 \tmse_loss: 0.0573017709\n",
            "Iteration: 89 \tmse_loss: 0.0571711771\n",
            "Iteration: 90 \tmse_loss: 0.0570357591\n",
            "Iteration: 91 \tmse_loss: 0.0568996444\n",
            "Iteration: 92 \tmse_loss: 0.0567645542\n",
            "Iteration: 93 \tmse_loss: 0.0566328056\n",
            "Iteration: 94 \tmse_loss: 0.0565066114\n",
            "Iteration: 95 \tmse_loss: 0.0563798398\n",
            "Iteration: 96 \tmse_loss: 0.0562628768\n",
            "Iteration: 97 \tmse_loss: 0.0561476462\n",
            "Iteration: 98 \tmse_loss: 0.0560321175\n",
            "Iteration: 99 \tmse_loss: 0.0559271909\n",
            "Iteration: 100 \tmse_loss: 0.0579405390\n",
            "Test -- Iteration: 100 \tmse_loss: 0.0579608679\n",
            "Iteration: 101 \tmse_loss: 0.0578952432\n",
            "Iteration: 102 \tmse_loss: 0.0578418970\n",
            "Iteration: 103 \tmse_loss: 0.0577759184\n",
            "Iteration: 104 \tmse_loss: 0.0576958545\n",
            "Iteration: 105 \tmse_loss: 0.0576068871\n",
            "Iteration: 106 \tmse_loss: 0.0575079545\n",
            "Iteration: 107 \tmse_loss: 0.0573983416\n",
            "Iteration: 108 \tmse_loss: 0.0572817884\n",
            "Iteration: 109 \tmse_loss: 0.0571556240\n",
            "Iteration: 110 \tmse_loss: 0.0570216365\n",
            "Iteration: 111 \tmse_loss: 0.0568880141\n",
            "Iteration: 112 \tmse_loss: 0.0567579418\n",
            "Iteration: 113 \tmse_loss: 0.0566260479\n",
            "Iteration: 114 \tmse_loss: 0.0565002523\n",
            "Iteration: 115 \tmse_loss: 0.0563786849\n",
            "Iteration: 116 \tmse_loss: 0.0562600605\n",
            "Iteration: 117 \tmse_loss: 0.0561471395\n",
            "Iteration: 118 \tmse_loss: 0.0560372956\n",
            "Iteration: 119 \tmse_loss: 0.0559297502\n",
            "Iteration: 120 \tmse_loss: 0.0578922518\n",
            "Test -- Iteration: 120 \tmse_loss: 0.0579409674\n",
            "Iteration: 121 \tmse_loss: 0.0578467250\n",
            "Iteration: 122 \tmse_loss: 0.0577942207\n",
            "Iteration: 123 \tmse_loss: 0.0577301607\n",
            "Iteration: 124 \tmse_loss: 0.0576534718\n",
            "Iteration: 125 \tmse_loss: 0.0575662665\n",
            "Iteration: 126 \tmse_loss: 0.0574700460\n",
            "Iteration: 127 \tmse_loss: 0.0573634394\n",
            "Iteration: 128 \tmse_loss: 0.0572426692\n",
            "Iteration: 129 \tmse_loss: 0.0571195334\n",
            "Iteration: 130 \tmse_loss: 0.0569918454\n",
            "Iteration: 131 \tmse_loss: 0.0568594746\n",
            "Iteration: 132 \tmse_loss: 0.0567264818\n",
            "Iteration: 133 \tmse_loss: 0.0565985888\n",
            "Iteration: 134 \tmse_loss: 0.0564757027\n",
            "Iteration: 135 \tmse_loss: 0.0563542135\n",
            "Iteration: 136 \tmse_loss: 0.0562371127\n",
            "Iteration: 137 \tmse_loss: 0.0561206155\n",
            "Iteration: 138 \tmse_loss: 0.0560113713\n",
            "Iteration: 139 \tmse_loss: 0.0559086427\n",
            "Iteration: 140 \tmse_loss: 0.0578487776\n",
            "Test -- Iteration: 140 \tmse_loss: 0.0579115339\n",
            "Iteration: 141 \tmse_loss: 0.0578010939\n",
            "Iteration: 142 \tmse_loss: 0.0577553473\n",
            "Iteration: 143 \tmse_loss: 0.0576971732\n",
            "Iteration: 144 \tmse_loss: 0.0576234721\n",
            "Iteration: 145 \tmse_loss: 0.0575393327\n",
            "Iteration: 146 \tmse_loss: 0.0574461930\n",
            "Iteration: 147 \tmse_loss: 0.0573389977\n",
            "Iteration: 148 \tmse_loss: 0.0572235659\n",
            "Iteration: 149 \tmse_loss: 0.0571009517\n",
            "Iteration: 150 \tmse_loss: 0.0569755919\n",
            "Iteration: 151 \tmse_loss: 0.0568459295\n",
            "Iteration: 152 \tmse_loss: 0.0567179993\n",
            "Iteration: 153 \tmse_loss: 0.0565915182\n",
            "Iteration: 154 \tmse_loss: 0.0564711653\n",
            "Iteration: 155 \tmse_loss: 0.0563521981\n",
            "Iteration: 156 \tmse_loss: 0.0562338307\n",
            "Iteration: 157 \tmse_loss: 0.0561266430\n",
            "Iteration: 158 \tmse_loss: 0.0560184643\n",
            "Iteration: 159 \tmse_loss: 0.0559122041\n",
            "Iteration: 160 \tmse_loss: 0.0579024479\n",
            "Test -- Iteration: 160 \tmse_loss: 0.0578969643\n",
            "Iteration: 161 \tmse_loss: 0.0578603037\n",
            "Iteration: 162 \tmse_loss: 0.0578141473\n",
            "Iteration: 163 \tmse_loss: 0.0577536821\n",
            "Iteration: 164 \tmse_loss: 0.0576849245\n",
            "Iteration: 165 \tmse_loss: 0.0576035306\n",
            "Iteration: 166 \tmse_loss: 0.0575152859\n",
            "Iteration: 167 \tmse_loss: 0.0574087426\n",
            "Iteration: 168 \tmse_loss: 0.0572910830\n",
            "Iteration: 169 \tmse_loss: 0.0571676008\n",
            "Iteration: 170 \tmse_loss: 0.0570444576\n",
            "Iteration: 171 \tmse_loss: 0.0569178388\n",
            "Iteration: 172 \tmse_loss: 0.0567922108\n",
            "Iteration: 173 \tmse_loss: 0.0566677339\n",
            "Iteration: 174 \tmse_loss: 0.0565475784\n",
            "Iteration: 175 \tmse_loss: 0.0564271249\n",
            "Iteration: 176 \tmse_loss: 0.0563131981\n",
            "Iteration: 177 \tmse_loss: 0.0562022291\n",
            "Iteration: 178 \tmse_loss: 0.0560956635\n",
            "Iteration: 179 \tmse_loss: 0.0559942015\n",
            "Iteration: 180 \tmse_loss: 0.0579051375\n",
            "Test -- Iteration: 180 \tmse_loss: 0.0578699671\n",
            "Iteration: 181 \tmse_loss: 0.0578669347\n",
            "Iteration: 182 \tmse_loss: 0.0578237474\n",
            "Iteration: 183 \tmse_loss: 0.0577695519\n",
            "Iteration: 184 \tmse_loss: 0.0576960854\n",
            "Iteration: 185 \tmse_loss: 0.0576154627\n",
            "Iteration: 186 \tmse_loss: 0.0575278923\n",
            "Iteration: 187 \tmse_loss: 0.0574225038\n",
            "Iteration: 188 \tmse_loss: 0.0573068373\n",
            "Iteration: 189 \tmse_loss: 0.0571880117\n",
            "Iteration: 190 \tmse_loss: 0.0570631996\n",
            "Iteration: 191 \tmse_loss: 0.0569388159\n",
            "Iteration: 192 \tmse_loss: 0.0568186939\n",
            "Iteration: 193 \tmse_loss: 0.0566933379\n",
            "Iteration: 194 \tmse_loss: 0.0565710738\n",
            "Iteration: 195 \tmse_loss: 0.0564550832\n",
            "Iteration: 196 \tmse_loss: 0.0563396290\n",
            "Iteration: 197 \tmse_loss: 0.0562262647\n",
            "Iteration: 198 \tmse_loss: 0.0561256371\n",
            "Final loss \tmse_loss: 0.0561256371\n",
            "Iteration: 0 \tmse_loss: 2.0337400436\n",
            "Test -- Iteration: 0 \tmse_loss: 1.8814700842\n",
            "Iteration: 1 \tmse_loss: 1.8817335367\n",
            "Iteration: 2 \tmse_loss: 1.7391190529\n",
            "Iteration: 3 \tmse_loss: 1.6063300371\n",
            "Iteration: 4 \tmse_loss: 1.4833016396\n",
            "Iteration: 5 \tmse_loss: 1.3696103096\n",
            "Iteration: 6 \tmse_loss: 1.2646989822\n",
            "Iteration: 7 \tmse_loss: 1.1681373119\n",
            "Iteration: 8 \tmse_loss: 1.0801963806\n",
            "Iteration: 9 \tmse_loss: 1.0001422167\n",
            "Iteration: 10 \tmse_loss: 0.9269164205\n",
            "Iteration: 11 \tmse_loss: 0.8602330685\n",
            "Iteration: 12 \tmse_loss: 0.7996673584\n",
            "Iteration: 13 \tmse_loss: 0.7445040941\n",
            "Iteration: 14 \tmse_loss: 0.6941905022\n",
            "Iteration: 15 \tmse_loss: 0.6484244466\n",
            "Iteration: 16 \tmse_loss: 0.6067320108\n",
            "Iteration: 17 \tmse_loss: 0.5688749552\n",
            "Iteration: 18 \tmse_loss: 0.5343558192\n",
            "Iteration: 19 \tmse_loss: 0.5027736425\n",
            "Iteration: 20 \tmse_loss: 0.4741269648\n",
            "Test -- Iteration: 20 \tmse_loss: 0.4477572143\n",
            "Iteration: 21 \tmse_loss: 0.4476975501\n",
            "Iteration: 22 \tmse_loss: 0.4235374928\n",
            "Iteration: 23 \tmse_loss: 0.4013422132\n",
            "Iteration: 24 \tmse_loss: 0.3809282780\n",
            "Iteration: 25 \tmse_loss: 0.3621725440\n",
            "Iteration: 26 \tmse_loss: 0.3449165523\n",
            "Iteration: 27 \tmse_loss: 0.3290090561\n",
            "Iteration: 28 \tmse_loss: 0.3143734336\n",
            "Iteration: 29 \tmse_loss: 0.3008731008\n",
            "Iteration: 30 \tmse_loss: 0.2884006798\n",
            "Iteration: 31 \tmse_loss: 0.2768736482\n",
            "Iteration: 32 \tmse_loss: 0.2661926150\n",
            "Iteration: 33 \tmse_loss: 0.2563032806\n",
            "Iteration: 34 \tmse_loss: 0.2471375167\n",
            "Iteration: 35 \tmse_loss: 0.2386170328\n",
            "Iteration: 36 \tmse_loss: 0.2306872159\n",
            "Iteration: 37 \tmse_loss: 0.2233143598\n",
            "Iteration: 38 \tmse_loss: 0.2164496630\n",
            "Iteration: 39 \tmse_loss: 0.2100324929\n",
            "Iteration: 40 \tmse_loss: 0.2051592022\n",
            "Test -- Iteration: 40 \tmse_loss: 0.1996352375\n",
            "Iteration: 41 \tmse_loss: 0.1995712817\n",
            "Iteration: 42 \tmse_loss: 0.1943325698\n",
            "Iteration: 43 \tmse_loss: 0.1894101501\n",
            "Iteration: 44 \tmse_loss: 0.1847818941\n",
            "Iteration: 45 \tmse_loss: 0.1804320365\n",
            "Iteration: 46 \tmse_loss: 0.1763416976\n",
            "Iteration: 47 \tmse_loss: 0.1724900603\n",
            "Iteration: 48 \tmse_loss: 0.1688528657\n",
            "Iteration: 49 \tmse_loss: 0.1654174626\n",
            "Iteration: 50 \tmse_loss: 0.1621711999\n",
            "Iteration: 51 \tmse_loss: 0.1591001302\n",
            "Iteration: 52 \tmse_loss: 0.1561939716\n",
            "Iteration: 53 \tmse_loss: 0.1534428596\n",
            "Iteration: 54 \tmse_loss: 0.1508405507\n",
            "Iteration: 55 \tmse_loss: 0.1483699977\n",
            "Iteration: 56 \tmse_loss: 0.1460225284\n",
            "Iteration: 57 \tmse_loss: 0.1437929571\n",
            "Iteration: 58 \tmse_loss: 0.1416703463\n",
            "Iteration: 59 \tmse_loss: 0.1396491975\n",
            "Iteration: 60 \tmse_loss: 0.1383231580\n",
            "Test -- Iteration: 60 \tmse_loss: 0.1365016103\n",
            "Iteration: 61 \tmse_loss: 0.1365137696\n",
            "Iteration: 62 \tmse_loss: 0.1347853839\n",
            "Iteration: 63 \tmse_loss: 0.1331309378\n",
            "Iteration: 64 \tmse_loss: 0.1315447837\n",
            "Iteration: 65 \tmse_loss: 0.1300243139\n",
            "Iteration: 66 \tmse_loss: 0.1285673529\n",
            "Iteration: 67 \tmse_loss: 0.1271708608\n",
            "Iteration: 68 \tmse_loss: 0.1258300543\n",
            "Iteration: 69 \tmse_loss: 0.1245431602\n",
            "Iteration: 70 \tmse_loss: 0.1233071163\n",
            "Iteration: 71 \tmse_loss: 0.1221182272\n",
            "Iteration: 72 \tmse_loss: 0.1209756061\n",
            "Iteration: 73 \tmse_loss: 0.1198754534\n",
            "Iteration: 74 \tmse_loss: 0.1188160032\n",
            "Iteration: 75 \tmse_loss: 0.1177945882\n",
            "Iteration: 76 \tmse_loss: 0.1168106198\n",
            "Iteration: 77 \tmse_loss: 0.1158613563\n",
            "Iteration: 78 \tmse_loss: 0.1149452403\n",
            "Iteration: 79 \tmse_loss: 0.1140610129\n",
            "Iteration: 80 \tmse_loss: 0.1135040298\n",
            "Test -- Iteration: 80 \tmse_loss: 0.1127496958\n",
            "Iteration: 81 \tmse_loss: 0.1126968637\n",
            "Iteration: 82 \tmse_loss: 0.1119136065\n",
            "Iteration: 83 \tmse_loss: 0.1111534834\n",
            "Iteration: 84 \tmse_loss: 0.1104155108\n",
            "Iteration: 85 \tmse_loss: 0.1097008437\n",
            "Iteration: 86 \tmse_loss: 0.1090077907\n",
            "Iteration: 87 \tmse_loss: 0.1083362773\n",
            "Iteration: 88 \tmse_loss: 0.1076838449\n",
            "Iteration: 89 \tmse_loss: 0.1070492342\n",
            "Iteration: 90 \tmse_loss: 0.1064314246\n",
            "Iteration: 91 \tmse_loss: 0.1058315411\n",
            "Iteration: 92 \tmse_loss: 0.1052480713\n",
            "Iteration: 93 \tmse_loss: 0.1046805009\n",
            "Iteration: 94 \tmse_loss: 0.1041285172\n",
            "Iteration: 95 \tmse_loss: 0.1035905182\n",
            "Iteration: 96 \tmse_loss: 0.1030662581\n",
            "Iteration: 97 \tmse_loss: 0.1025553271\n",
            "Iteration: 98 \tmse_loss: 0.1020576134\n",
            "Iteration: 99 \tmse_loss: 0.1015721112\n",
            "Iteration: 100 \tmse_loss: 0.1014229730\n",
            "Test -- Iteration: 100 \tmse_loss: 0.1009968668\n",
            "Iteration: 101 \tmse_loss: 0.1009748280\n",
            "Iteration: 102 \tmse_loss: 0.1005343348\n",
            "Iteration: 103 \tmse_loss: 0.1001007706\n",
            "Iteration: 104 \tmse_loss: 0.0996751189\n",
            "Iteration: 105 \tmse_loss: 0.0992575809\n",
            "Iteration: 106 \tmse_loss: 0.0988482907\n",
            "Iteration: 107 \tmse_loss: 0.0984466001\n",
            "Iteration: 108 \tmse_loss: 0.0980522484\n",
            "Iteration: 109 \tmse_loss: 0.0976644158\n",
            "Iteration: 110 \tmse_loss: 0.0972830281\n",
            "Iteration: 111 \tmse_loss: 0.0969082341\n",
            "Iteration: 112 \tmse_loss: 0.0965401232\n",
            "Iteration: 113 \tmse_loss: 0.0961784050\n",
            "Iteration: 114 \tmse_loss: 0.0958228186\n",
            "Iteration: 115 \tmse_loss: 0.0954731032\n",
            "Iteration: 116 \tmse_loss: 0.0951294154\n",
            "Iteration: 117 \tmse_loss: 0.0947916359\n",
            "Iteration: 118 \tmse_loss: 0.0944592282\n",
            "Iteration: 119 \tmse_loss: 0.0941320807\n",
            "Iteration: 120 \tmse_loss: 0.0940724611\n",
            "Test -- Iteration: 120 \tmse_loss: 0.0937970504\n",
            "Iteration: 121 \tmse_loss: 0.0937714279\n",
            "Iteration: 122 \tmse_loss: 0.0934732705\n",
            "Iteration: 123 \tmse_loss: 0.0931782052\n",
            "Iteration: 124 \tmse_loss: 0.0928861573\n",
            "Iteration: 125 \tmse_loss: 0.0925972238\n",
            "Iteration: 126 \tmse_loss: 0.0923118517\n",
            "Iteration: 127 \tmse_loss: 0.0920295194\n",
            "Iteration: 128 \tmse_loss: 0.0917501673\n",
            "Iteration: 129 \tmse_loss: 0.0914735869\n",
            "Iteration: 130 \tmse_loss: 0.0912006199\n",
            "Iteration: 131 \tmse_loss: 0.0909309462\n",
            "Iteration: 132 \tmse_loss: 0.0906645954\n",
            "Iteration: 133 \tmse_loss: 0.0904012844\n",
            "Iteration: 134 \tmse_loss: 0.0901409313\n",
            "Iteration: 135 \tmse_loss: 0.0898839906\n",
            "Iteration: 136 \tmse_loss: 0.0896303430\n",
            "Iteration: 137 \tmse_loss: 0.0893800035\n",
            "Iteration: 138 \tmse_loss: 0.0891325995\n",
            "Iteration: 139 \tmse_loss: 0.0888880789\n",
            "Iteration: 140 \tmse_loss: 0.0889766887\n",
            "Test -- Iteration: 140 \tmse_loss: 0.0887038410\n",
            "Iteration: 141 \tmse_loss: 0.0887532011\n",
            "Iteration: 142 \tmse_loss: 0.0885305926\n",
            "Iteration: 143 \tmse_loss: 0.0883092880\n",
            "Iteration: 144 \tmse_loss: 0.0880891681\n",
            "Iteration: 145 \tmse_loss: 0.0878700316\n",
            "Iteration: 146 \tmse_loss: 0.0876524523\n",
            "Iteration: 147 \tmse_loss: 0.0874364004\n",
            "Iteration: 148 \tmse_loss: 0.0872217789\n",
            "Iteration: 149 \tmse_loss: 0.0870088190\n",
            "Iteration: 150 \tmse_loss: 0.0867977142\n",
            "Iteration: 151 \tmse_loss: 0.0865884423\n",
            "Iteration: 152 \tmse_loss: 0.0863808841\n",
            "Iteration: 153 \tmse_loss: 0.0861749128\n",
            "Iteration: 154 \tmse_loss: 0.0859706849\n",
            "Iteration: 155 \tmse_loss: 0.0857683569\n",
            "Iteration: 156 \tmse_loss: 0.0855679065\n",
            "Iteration: 157 \tmse_loss: 0.0853693038\n",
            "Iteration: 158 \tmse_loss: 0.0851724222\n",
            "Iteration: 159 \tmse_loss: 0.0849774703\n",
            "Iteration: 160 \tmse_loss: 0.0849832669\n",
            "Test -- Iteration: 160 \tmse_loss: 0.0848089233\n",
            "Iteration: 161 \tmse_loss: 0.0848074108\n",
            "Iteration: 162 \tmse_loss: 0.0846315771\n",
            "Iteration: 163 \tmse_loss: 0.0844559073\n",
            "Iteration: 164 \tmse_loss: 0.0842803046\n",
            "Iteration: 165 \tmse_loss: 0.0841049701\n",
            "Iteration: 166 \tmse_loss: 0.0839300603\n",
            "Iteration: 167 \tmse_loss: 0.0837558359\n",
            "Iteration: 168 \tmse_loss: 0.0835822672\n",
            "Iteration: 169 \tmse_loss: 0.0834093764\n",
            "Iteration: 170 \tmse_loss: 0.0832377002\n",
            "Iteration: 171 \tmse_loss: 0.0830669776\n",
            "Iteration: 172 \tmse_loss: 0.0828970969\n",
            "Iteration: 173 \tmse_loss: 0.0827280805\n",
            "Iteration: 174 \tmse_loss: 0.0825603083\n",
            "Iteration: 175 \tmse_loss: 0.0823937058\n",
            "Iteration: 176 \tmse_loss: 0.0822283179\n",
            "Iteration: 177 \tmse_loss: 0.0820641294\n",
            "Iteration: 178 \tmse_loss: 0.0819010511\n",
            "Iteration: 179 \tmse_loss: 0.0817392543\n",
            "Iteration: 180 \tmse_loss: 0.0818353370\n",
            "Test -- Iteration: 180 \tmse_loss: 0.0816872343\n",
            "Iteration: 181 \tmse_loss: 0.0816916227\n",
            "Iteration: 182 \tmse_loss: 0.0815473050\n",
            "Iteration: 183 \tmse_loss: 0.0814024955\n",
            "Iteration: 184 \tmse_loss: 0.0812572539\n",
            "Iteration: 185 \tmse_loss: 0.0811119080\n",
            "Iteration: 186 \tmse_loss: 0.0809665769\n",
            "Iteration: 187 \tmse_loss: 0.0808212906\n",
            "Iteration: 188 \tmse_loss: 0.0806763023\n",
            "Iteration: 189 \tmse_loss: 0.0805316046\n",
            "Iteration: 190 \tmse_loss: 0.0803873837\n",
            "Iteration: 191 \tmse_loss: 0.0802436471\n",
            "Iteration: 192 \tmse_loss: 0.0801004469\n",
            "Iteration: 193 \tmse_loss: 0.0799577758\n",
            "Iteration: 194 \tmse_loss: 0.0798158571\n",
            "Iteration: 195 \tmse_loss: 0.0796746612\n",
            "Iteration: 196 \tmse_loss: 0.0795342252\n",
            "Iteration: 197 \tmse_loss: 0.0793946236\n",
            "Iteration: 198 \tmse_loss: 0.0792558715\n",
            "Final loss \tmse_loss: 0.0792558715\n",
            "Iteration: 0 \tmse_loss: 0.0797567889\n",
            "Test -- Iteration: 0 \tmse_loss: 0.0766583756\n",
            "Iteration: 1 \tmse_loss: 0.0766448453\n",
            "Iteration: 2 \tmse_loss: 0.0726927146\n",
            "Iteration: 3 \tmse_loss: 0.0696472675\n",
            "Iteration: 4 \tmse_loss: 0.0675579831\n",
            "Iteration: 5 \tmse_loss: 0.0663551241\n",
            "Iteration: 6 \tmse_loss: 0.0653290674\n",
            "Iteration: 7 \tmse_loss: 0.0644038394\n",
            "Iteration: 8 \tmse_loss: 0.0636714101\n",
            "Iteration: 9 \tmse_loss: 0.0631570294\n",
            "Iteration: 10 \tmse_loss: 0.0627687424\n",
            "Iteration: 11 \tmse_loss: 0.0624421127\n",
            "Iteration: 12 \tmse_loss: 0.0621641763\n",
            "Iteration: 13 \tmse_loss: 0.0619225278\n",
            "Iteration: 14 \tmse_loss: 0.0616817139\n",
            "Iteration: 15 \tmse_loss: 0.0614372827\n",
            "Iteration: 16 \tmse_loss: 0.0611992441\n",
            "Iteration: 17 \tmse_loss: 0.0609666929\n",
            "Iteration: 18 \tmse_loss: 0.0607377961\n",
            "Iteration: 19 \tmse_loss: 0.0605181754\n",
            "Iteration: 20 \tmse_loss: 0.0644497126\n",
            "Test -- Iteration: 20 \tmse_loss: 0.0643029213\n",
            "Iteration: 21 \tmse_loss: 0.0641693920\n",
            "Iteration: 22 \tmse_loss: 0.0637746453\n",
            "Iteration: 23 \tmse_loss: 0.0633387342\n",
            "Iteration: 24 \tmse_loss: 0.0628751516\n",
            "Iteration: 25 \tmse_loss: 0.0623954386\n",
            "Iteration: 26 \tmse_loss: 0.0619231910\n",
            "Iteration: 27 \tmse_loss: 0.0614685044\n",
            "Iteration: 28 \tmse_loss: 0.0610303618\n",
            "Iteration: 29 \tmse_loss: 0.0606126152\n",
            "Iteration: 30 \tmse_loss: 0.0602226630\n",
            "Iteration: 31 \tmse_loss: 0.0598554537\n",
            "Iteration: 32 \tmse_loss: 0.0595123582\n",
            "Iteration: 33 \tmse_loss: 0.0591971017\n",
            "Iteration: 34 \tmse_loss: 0.0588931926\n",
            "Iteration: 35 \tmse_loss: 0.0585995018\n",
            "Iteration: 36 \tmse_loss: 0.0583191216\n",
            "Iteration: 37 \tmse_loss: 0.0580594502\n",
            "Iteration: 38 \tmse_loss: 0.0578244254\n",
            "Iteration: 39 \tmse_loss: 0.0576048978\n",
            "Iteration: 40 \tmse_loss: 0.0623032115\n",
            "Test -- Iteration: 40 \tmse_loss: 0.0622116625\n",
            "Iteration: 41 \tmse_loss: 0.0621178895\n",
            "Iteration: 42 \tmse_loss: 0.0617988184\n",
            "Iteration: 43 \tmse_loss: 0.0614091381\n",
            "Iteration: 44 \tmse_loss: 0.0609631166\n",
            "Iteration: 45 \tmse_loss: 0.0604907349\n",
            "Iteration: 46 \tmse_loss: 0.0600229762\n",
            "Iteration: 47 \tmse_loss: 0.0595739819\n",
            "Iteration: 48 \tmse_loss: 0.0591502860\n",
            "Iteration: 49 \tmse_loss: 0.0587639548\n",
            "Iteration: 50 \tmse_loss: 0.0584135987\n",
            "Iteration: 51 \tmse_loss: 0.0580945499\n",
            "Iteration: 52 \tmse_loss: 0.0578016341\n",
            "Iteration: 53 \tmse_loss: 0.0575305410\n",
            "Iteration: 54 \tmse_loss: 0.0572822653\n",
            "Iteration: 55 \tmse_loss: 0.0570547953\n",
            "Iteration: 56 \tmse_loss: 0.0568448976\n",
            "Iteration: 57 \tmse_loss: 0.0566493683\n",
            "Iteration: 58 \tmse_loss: 0.0564677753\n",
            "Iteration: 59 \tmse_loss: 0.0562972985\n",
            "Iteration: 60 \tmse_loss: 0.0611335300\n",
            "Test -- Iteration: 60 \tmse_loss: 0.0610973984\n",
            "Iteration: 61 \tmse_loss: 0.0610150471\n",
            "Iteration: 62 \tmse_loss: 0.0607707985\n",
            "Iteration: 63 \tmse_loss: 0.0604473948\n",
            "Iteration: 64 \tmse_loss: 0.0600686558\n",
            "Iteration: 65 \tmse_loss: 0.0596672781\n",
            "Iteration: 66 \tmse_loss: 0.0592641458\n",
            "Iteration: 67 \tmse_loss: 0.0588746406\n",
            "Iteration: 68 \tmse_loss: 0.0585095584\n",
            "Iteration: 69 \tmse_loss: 0.0581704080\n",
            "Iteration: 70 \tmse_loss: 0.0578554384\n",
            "Iteration: 71 \tmse_loss: 0.0575629100\n",
            "Iteration: 72 \tmse_loss: 0.0572918653\n",
            "Iteration: 73 \tmse_loss: 0.0570477694\n",
            "Iteration: 74 \tmse_loss: 0.0568246916\n",
            "Iteration: 75 \tmse_loss: 0.0566189252\n",
            "Iteration: 76 \tmse_loss: 0.0564298704\n",
            "Iteration: 77 \tmse_loss: 0.0562541820\n",
            "Iteration: 78 \tmse_loss: 0.0560885631\n",
            "Iteration: 79 \tmse_loss: 0.0559330061\n",
            "Iteration: 80 \tmse_loss: 0.0604266860\n",
            "Test -- Iteration: 80 \tmse_loss: 0.0604302883\n",
            "Iteration: 81 \tmse_loss: 0.0603273958\n",
            "Iteration: 82 \tmse_loss: 0.0601274818\n",
            "Iteration: 83 \tmse_loss: 0.0598605275\n",
            "Iteration: 84 \tmse_loss: 0.0595475882\n",
            "Iteration: 85 \tmse_loss: 0.0592101142\n",
            "Iteration: 86 \tmse_loss: 0.0588628128\n",
            "Iteration: 87 \tmse_loss: 0.0585268140\n",
            "Iteration: 88 \tmse_loss: 0.0582014807\n",
            "Iteration: 89 \tmse_loss: 0.0578878708\n",
            "Iteration: 90 \tmse_loss: 0.0575961284\n",
            "Iteration: 91 \tmse_loss: 0.0573289506\n",
            "Iteration: 92 \tmse_loss: 0.0570835769\n",
            "Iteration: 93 \tmse_loss: 0.0568644069\n",
            "Iteration: 94 \tmse_loss: 0.0566641279\n",
            "Iteration: 95 \tmse_loss: 0.0564766861\n",
            "Iteration: 96 \tmse_loss: 0.0563002490\n",
            "Iteration: 97 \tmse_loss: 0.0561363064\n",
            "Iteration: 98 \tmse_loss: 0.0559820607\n",
            "Iteration: 99 \tmse_loss: 0.0558420122\n",
            "Iteration: 100 \tmse_loss: 0.0600223094\n",
            "Test -- Iteration: 100 \tmse_loss: 0.0600170642\n",
            "Iteration: 101 \tmse_loss: 0.0599399246\n",
            "Iteration: 102 \tmse_loss: 0.0597766750\n",
            "Iteration: 103 \tmse_loss: 0.0595471635\n",
            "Iteration: 104 \tmse_loss: 0.0592746548\n",
            "Iteration: 105 \tmse_loss: 0.0589843728\n",
            "Iteration: 106 \tmse_loss: 0.0586847439\n",
            "Iteration: 107 \tmse_loss: 0.0583847314\n",
            "Iteration: 108 \tmse_loss: 0.0580850616\n",
            "Iteration: 109 \tmse_loss: 0.0577883832\n",
            "Iteration: 110 \tmse_loss: 0.0575126633\n",
            "Iteration: 111 \tmse_loss: 0.0572595075\n",
            "Iteration: 112 \tmse_loss: 0.0570267253\n",
            "Iteration: 113 \tmse_loss: 0.0568164252\n",
            "Iteration: 114 \tmse_loss: 0.0566224605\n",
            "Iteration: 115 \tmse_loss: 0.0564432852\n",
            "Iteration: 116 \tmse_loss: 0.0562769957\n",
            "Iteration: 117 \tmse_loss: 0.0561219677\n",
            "Iteration: 118 \tmse_loss: 0.0559767783\n",
            "Iteration: 119 \tmse_loss: 0.0558453761\n",
            "Iteration: 120 \tmse_loss: 0.0597524494\n",
            "Test -- Iteration: 120 \tmse_loss: 0.0597505830\n",
            "Iteration: 121 \tmse_loss: 0.0596695691\n",
            "Iteration: 122 \tmse_loss: 0.0595309474\n",
            "Iteration: 123 \tmse_loss: 0.0593333505\n",
            "Iteration: 124 \tmse_loss: 0.0590985939\n",
            "Iteration: 125 \tmse_loss: 0.0588426478\n",
            "Iteration: 126 \tmse_loss: 0.0585766062\n",
            "Iteration: 127 \tmse_loss: 0.0583050549\n",
            "Iteration: 128 \tmse_loss: 0.0580250360\n",
            "Iteration: 129 \tmse_loss: 0.0577473007\n",
            "Iteration: 130 \tmse_loss: 0.0574830100\n",
            "Iteration: 131 \tmse_loss: 0.0572417304\n",
            "Iteration: 132 \tmse_loss: 0.0570164435\n",
            "Iteration: 133 \tmse_loss: 0.0568102896\n",
            "Iteration: 134 \tmse_loss: 0.0566233434\n",
            "Iteration: 135 \tmse_loss: 0.0564450584\n",
            "Iteration: 136 \tmse_loss: 0.0562816784\n",
            "Iteration: 137 \tmse_loss: 0.0561286397\n",
            "Iteration: 138 \tmse_loss: 0.0559855178\n",
            "Iteration: 139 \tmse_loss: 0.0558559299\n",
            "Iteration: 140 \tmse_loss: 0.0595994517\n",
            "Test -- Iteration: 140 \tmse_loss: 0.0595441945\n",
            "Iteration: 141 \tmse_loss: 0.0595306568\n",
            "Iteration: 142 \tmse_loss: 0.0594062470\n",
            "Iteration: 143 \tmse_loss: 0.0592325814\n",
            "Iteration: 144 \tmse_loss: 0.0590212420\n",
            "Iteration: 145 \tmse_loss: 0.0587876476\n",
            "Iteration: 146 \tmse_loss: 0.0585475005\n",
            "Iteration: 147 \tmse_loss: 0.0582922995\n",
            "Iteration: 148 \tmse_loss: 0.0580295771\n",
            "Iteration: 149 \tmse_loss: 0.0577694997\n",
            "Iteration: 150 \tmse_loss: 0.0575222299\n",
            "Iteration: 151 \tmse_loss: 0.0572891794\n",
            "Iteration: 152 \tmse_loss: 0.0570758134\n",
            "Iteration: 153 \tmse_loss: 0.0568744019\n",
            "Iteration: 154 \tmse_loss: 0.0566875339\n",
            "Iteration: 155 \tmse_loss: 0.0565135814\n",
            "Iteration: 156 \tmse_loss: 0.0563476533\n",
            "Iteration: 157 \tmse_loss: 0.0562004037\n",
            "Iteration: 158 \tmse_loss: 0.0560640022\n",
            "Iteration: 159 \tmse_loss: 0.0559309162\n",
            "Iteration: 160 \tmse_loss: 0.0593885072\n",
            "Test -- Iteration: 160 \tmse_loss: 0.0593836904\n",
            "Iteration: 161 \tmse_loss: 0.0593316518\n",
            "Iteration: 162 \tmse_loss: 0.0592170767\n",
            "Iteration: 163 \tmse_loss: 0.0590509735\n",
            "Iteration: 164 \tmse_loss: 0.0588603579\n",
            "Iteration: 165 \tmse_loss: 0.0586462356\n",
            "Iteration: 166 \tmse_loss: 0.0584252998\n",
            "Iteration: 167 \tmse_loss: 0.0581859276\n",
            "Iteration: 168 \tmse_loss: 0.0579379164\n",
            "Iteration: 169 \tmse_loss: 0.0576944090\n",
            "Iteration: 170 \tmse_loss: 0.0574603900\n",
            "Iteration: 171 \tmse_loss: 0.0572335348\n",
            "Iteration: 172 \tmse_loss: 0.0570258684\n",
            "Iteration: 173 \tmse_loss: 0.0568304136\n",
            "Iteration: 174 \tmse_loss: 0.0566450208\n",
            "Iteration: 175 \tmse_loss: 0.0564702749\n",
            "Iteration: 176 \tmse_loss: 0.0563068949\n",
            "Iteration: 177 \tmse_loss: 0.0561555885\n",
            "Iteration: 178 \tmse_loss: 0.0560177378\n",
            "Iteration: 179 \tmse_loss: 0.0558922328\n",
            "Iteration: 180 \tmse_loss: 0.0592641272\n",
            "Test -- Iteration: 180 \tmse_loss: 0.0592355542\n",
            "Iteration: 181 \tmse_loss: 0.0592046790\n",
            "Iteration: 182 \tmse_loss: 0.0591004826\n",
            "Iteration: 183 \tmse_loss: 0.0589546897\n",
            "Iteration: 184 \tmse_loss: 0.0587796010\n",
            "Iteration: 185 \tmse_loss: 0.0585856363\n",
            "Iteration: 186 \tmse_loss: 0.0583761036\n",
            "Iteration: 187 \tmse_loss: 0.0581484325\n",
            "Iteration: 188 \tmse_loss: 0.0579142869\n",
            "Iteration: 189 \tmse_loss: 0.0576810129\n",
            "Iteration: 190 \tmse_loss: 0.0574565865\n",
            "Iteration: 191 \tmse_loss: 0.0572426058\n",
            "Iteration: 192 \tmse_loss: 0.0570352226\n",
            "Iteration: 193 \tmse_loss: 0.0568416566\n",
            "Iteration: 194 \tmse_loss: 0.0566594973\n",
            "Iteration: 195 \tmse_loss: 0.0564851016\n",
            "Iteration: 196 \tmse_loss: 0.0563220344\n",
            "Iteration: 197 \tmse_loss: 0.0561671257\n",
            "Iteration: 198 \tmse_loss: 0.0560310371\n",
            "Final loss \tmse_loss: 0.0560310371\n",
            "Iteration: 0 \tmse_loss: 0.0590397231\n",
            "Test -- Iteration: 0 \tmse_loss: 0.0600938387\n",
            "Iteration: 1 \tmse_loss: 0.0597673282\n",
            "Iteration: 2 \tmse_loss: 0.0590821505\n",
            "Iteration: 3 \tmse_loss: 0.0583234578\n",
            "Iteration: 4 \tmse_loss: 0.0581830591\n",
            "Iteration: 5 \tmse_loss: 0.0577520505\n",
            "Iteration: 6 \tmse_loss: 0.0572564267\n",
            "Iteration: 7 \tmse_loss: 0.0569756962\n",
            "Iteration: 8 \tmse_loss: 0.0568233617\n",
            "Iteration: 9 \tmse_loss: 0.0566953756\n",
            "Iteration: 10 \tmse_loss: 0.0564906485\n",
            "Iteration: 11 \tmse_loss: 0.0562484749\n",
            "Iteration: 12 \tmse_loss: 0.0560576357\n",
            "Iteration: 13 \tmse_loss: 0.0559183434\n",
            "Iteration: 14 \tmse_loss: 0.0557995401\n",
            "Iteration: 15 \tmse_loss: 0.0556807257\n",
            "Iteration: 16 \tmse_loss: 0.0555574447\n",
            "Iteration: 17 \tmse_loss: 0.0554360561\n",
            "Iteration: 18 \tmse_loss: 0.0553302616\n",
            "Iteration: 19 \tmse_loss: 0.0552410856\n",
            "Iteration: 20 \tmse_loss: 0.0593994781\n",
            "Test -- Iteration: 20 \tmse_loss: 0.0594044179\n",
            "Iteration: 21 \tmse_loss: 0.0593088120\n",
            "Iteration: 22 \tmse_loss: 0.0591383763\n",
            "Iteration: 23 \tmse_loss: 0.0589252114\n",
            "Iteration: 24 \tmse_loss: 0.0586943962\n",
            "Iteration: 25 \tmse_loss: 0.0584630296\n",
            "Iteration: 26 \tmse_loss: 0.0582315624\n",
            "Iteration: 27 \tmse_loss: 0.0580004044\n",
            "Iteration: 28 \tmse_loss: 0.0577740446\n",
            "Iteration: 29 \tmse_loss: 0.0575547665\n",
            "Iteration: 30 \tmse_loss: 0.0573354885\n",
            "Iteration: 31 \tmse_loss: 0.0571122468\n",
            "Iteration: 32 \tmse_loss: 0.0568959080\n",
            "Iteration: 33 \tmse_loss: 0.0566863008\n",
            "Iteration: 34 \tmse_loss: 0.0564939864\n",
            "Iteration: 35 \tmse_loss: 0.0563191064\n",
            "Iteration: 36 \tmse_loss: 0.0561540835\n",
            "Iteration: 37 \tmse_loss: 0.0560053326\n",
            "Iteration: 38 \tmse_loss: 0.0558695421\n",
            "Iteration: 39 \tmse_loss: 0.0557394512\n",
            "Iteration: 40 \tmse_loss: 0.0591729209\n",
            "Test -- Iteration: 40 \tmse_loss: 0.0591664836\n",
            "Iteration: 41 \tmse_loss: 0.0591089129\n",
            "Iteration: 42 \tmse_loss: 0.0589773394\n",
            "Iteration: 43 \tmse_loss: 0.0588035695\n",
            "Iteration: 44 \tmse_loss: 0.0586085543\n",
            "Iteration: 45 \tmse_loss: 0.0584012158\n",
            "Iteration: 46 \tmse_loss: 0.0581852533\n",
            "Iteration: 47 \tmse_loss: 0.0579716302\n",
            "Iteration: 48 \tmse_loss: 0.0577552803\n",
            "Iteration: 49 \tmse_loss: 0.0575349703\n",
            "Iteration: 50 \tmse_loss: 0.0573164932\n",
            "Iteration: 51 \tmse_loss: 0.0571006685\n",
            "Iteration: 52 \tmse_loss: 0.0568891652\n",
            "Iteration: 53 \tmse_loss: 0.0566999279\n",
            "Iteration: 54 \tmse_loss: 0.0565192513\n",
            "Iteration: 55 \tmse_loss: 0.0563493595\n",
            "Iteration: 56 \tmse_loss: 0.0561946183\n",
            "Iteration: 57 \tmse_loss: 0.0560507253\n",
            "Iteration: 58 \tmse_loss: 0.0559162721\n",
            "Iteration: 59 \tmse_loss: 0.0557873547\n",
            "Iteration: 60 \tmse_loss: 0.0590161234\n",
            "Test -- Iteration: 60 \tmse_loss: 0.0590214729\n",
            "Iteration: 61 \tmse_loss: 0.0589543507\n",
            "Iteration: 62 \tmse_loss: 0.0588434152\n",
            "Iteration: 63 \tmse_loss: 0.0586959608\n",
            "Iteration: 64 \tmse_loss: 0.0585201755\n",
            "Iteration: 65 \tmse_loss: 0.0583317429\n",
            "Iteration: 66 \tmse_loss: 0.0581353083\n",
            "Iteration: 67 \tmse_loss: 0.0579310358\n",
            "Iteration: 68 \tmse_loss: 0.0577218346\n",
            "Iteration: 69 \tmse_loss: 0.0575047471\n",
            "Iteration: 70 \tmse_loss: 0.0572895892\n",
            "Iteration: 71 \tmse_loss: 0.0570802838\n",
            "Iteration: 72 \tmse_loss: 0.0568787828\n",
            "Iteration: 73 \tmse_loss: 0.0566868968\n",
            "Iteration: 74 \tmse_loss: 0.0565106533\n",
            "Iteration: 75 \tmse_loss: 0.0563449264\n",
            "Iteration: 76 \tmse_loss: 0.0561859570\n",
            "Iteration: 77 \tmse_loss: 0.0560397729\n",
            "Iteration: 78 \tmse_loss: 0.0559002832\n",
            "Iteration: 79 \tmse_loss: 0.0557709336\n",
            "Iteration: 80 \tmse_loss: 0.0588689074\n",
            "Test -- Iteration: 80 \tmse_loss: 0.0589194074\n",
            "Iteration: 81 \tmse_loss: 0.0588129424\n",
            "Iteration: 82 \tmse_loss: 0.0587097928\n",
            "Iteration: 83 \tmse_loss: 0.0585718676\n",
            "Iteration: 84 \tmse_loss: 0.0584201813\n",
            "Iteration: 85 \tmse_loss: 0.0582468249\n",
            "Iteration: 86 \tmse_loss: 0.0580638833\n",
            "Iteration: 87 \tmse_loss: 0.0578708276\n",
            "Iteration: 88 \tmse_loss: 0.0576664917\n",
            "Iteration: 89 \tmse_loss: 0.0574580431\n",
            "Iteration: 90 \tmse_loss: 0.0572526902\n",
            "Iteration: 91 \tmse_loss: 0.0570525639\n",
            "Iteration: 92 \tmse_loss: 0.0568615235\n",
            "Iteration: 93 \tmse_loss: 0.0566770844\n",
            "Iteration: 94 \tmse_loss: 0.0565008149\n",
            "Iteration: 95 \tmse_loss: 0.0563396849\n",
            "Iteration: 96 \tmse_loss: 0.0561831929\n",
            "Iteration: 97 \tmse_loss: 0.0560303330\n",
            "Iteration: 98 \tmse_loss: 0.0558930375\n",
            "Iteration: 99 \tmse_loss: 0.0557658374\n",
            "Iteration: 100 \tmse_loss: 0.0587926246\n",
            "Test -- Iteration: 100 \tmse_loss: 0.0588311553\n",
            "Iteration: 101 \tmse_loss: 0.0587382168\n",
            "Iteration: 102 \tmse_loss: 0.0586484484\n",
            "Iteration: 103 \tmse_loss: 0.0585239679\n",
            "Iteration: 104 \tmse_loss: 0.0583798140\n",
            "Iteration: 105 \tmse_loss: 0.0582126901\n",
            "Iteration: 106 \tmse_loss: 0.0580357760\n",
            "Iteration: 107 \tmse_loss: 0.0578501634\n",
            "Iteration: 108 \tmse_loss: 0.0576551408\n",
            "Iteration: 109 \tmse_loss: 0.0574484132\n",
            "Iteration: 110 \tmse_loss: 0.0572507046\n",
            "Iteration: 111 \tmse_loss: 0.0570598505\n",
            "Iteration: 112 \tmse_loss: 0.0568709075\n",
            "Iteration: 113 \tmse_loss: 0.0566899031\n",
            "Iteration: 114 \tmse_loss: 0.0565183125\n",
            "Iteration: 115 \tmse_loss: 0.0563515313\n",
            "Iteration: 116 \tmse_loss: 0.0561914966\n",
            "Iteration: 117 \tmse_loss: 0.0560437329\n",
            "Iteration: 118 \tmse_loss: 0.0559071638\n",
            "Iteration: 119 \tmse_loss: 0.0557788946\n",
            "Iteration: 120 \tmse_loss: 0.0587034896\n",
            "Test -- Iteration: 120 \tmse_loss: 0.0587499104\n",
            "Iteration: 121 \tmse_loss: 0.0586522818\n",
            "Iteration: 122 \tmse_loss: 0.0585708208\n",
            "Iteration: 123 \tmse_loss: 0.0584570803\n",
            "Iteration: 124 \tmse_loss: 0.0583163276\n",
            "Iteration: 125 \tmse_loss: 0.0581645072\n",
            "Iteration: 126 \tmse_loss: 0.0580014028\n",
            "Iteration: 127 \tmse_loss: 0.0578199551\n",
            "Iteration: 128 \tmse_loss: 0.0576271564\n",
            "Iteration: 129 \tmse_loss: 0.0574350953\n",
            "Iteration: 130 \tmse_loss: 0.0572495870\n",
            "Iteration: 131 \tmse_loss: 0.0570656173\n",
            "Iteration: 132 \tmse_loss: 0.0568818375\n",
            "Iteration: 133 \tmse_loss: 0.0567021072\n",
            "Iteration: 134 \tmse_loss: 0.0565321408\n",
            "Iteration: 135 \tmse_loss: 0.0563687496\n",
            "Iteration: 136 \tmse_loss: 0.0562092066\n",
            "Iteration: 137 \tmse_loss: 0.0560617074\n",
            "Iteration: 138 \tmse_loss: 0.0559293739\n",
            "Iteration: 139 \tmse_loss: 0.0558025986\n",
            "Iteration: 140 \tmse_loss: 0.0587006249\n",
            "Test -- Iteration: 140 \tmse_loss: 0.0586746596\n",
            "Iteration: 141 \tmse_loss: 0.0586557426\n",
            "Iteration: 142 \tmse_loss: 0.0585785173\n",
            "Iteration: 143 \tmse_loss: 0.0584674515\n",
            "Iteration: 144 \tmse_loss: 0.0583330505\n",
            "Iteration: 145 \tmse_loss: 0.0581886210\n",
            "Iteration: 146 \tmse_loss: 0.0580319501\n",
            "Iteration: 147 \tmse_loss: 0.0578581616\n",
            "Iteration: 148 \tmse_loss: 0.0576762706\n",
            "Iteration: 149 \tmse_loss: 0.0574999899\n",
            "Iteration: 150 \tmse_loss: 0.0573223643\n",
            "Iteration: 151 \tmse_loss: 0.0571399666\n",
            "Iteration: 152 \tmse_loss: 0.0569607280\n",
            "Iteration: 153 \tmse_loss: 0.0567882657\n",
            "Iteration: 154 \tmse_loss: 0.0566229820\n",
            "Iteration: 155 \tmse_loss: 0.0564605743\n",
            "Iteration: 156 \tmse_loss: 0.0563000217\n",
            "Iteration: 157 \tmse_loss: 0.0561564565\n",
            "Iteration: 158 \tmse_loss: 0.0560307689\n",
            "Iteration: 159 \tmse_loss: 0.0559038632\n",
            "Iteration: 160 \tmse_loss: 0.0585987531\n",
            "Test -- Iteration: 160 \tmse_loss: 0.0586020499\n",
            "Iteration: 161 \tmse_loss: 0.0585508421\n",
            "Iteration: 162 \tmse_loss: 0.0584778935\n",
            "Iteration: 163 \tmse_loss: 0.0583770648\n",
            "Iteration: 164 \tmse_loss: 0.0582459606\n",
            "Iteration: 165 \tmse_loss: 0.0581085049\n",
            "Iteration: 166 \tmse_loss: 0.0579552166\n",
            "Iteration: 167 \tmse_loss: 0.0577911288\n",
            "Iteration: 168 \tmse_loss: 0.0576180033\n",
            "Iteration: 169 \tmse_loss: 0.0574464053\n",
            "Iteration: 170 \tmse_loss: 0.0572742969\n",
            "Iteration: 171 \tmse_loss: 0.0570994616\n",
            "Iteration: 172 \tmse_loss: 0.0569267459\n",
            "Iteration: 173 \tmse_loss: 0.0567573123\n",
            "Iteration: 174 \tmse_loss: 0.0565930158\n",
            "Iteration: 175 \tmse_loss: 0.0564338975\n",
            "Iteration: 176 \tmse_loss: 0.0562824719\n",
            "Iteration: 177 \tmse_loss: 0.0561399236\n",
            "Iteration: 178 \tmse_loss: 0.0560087971\n",
            "Iteration: 179 \tmse_loss: 0.0558876097\n",
            "Iteration: 180 \tmse_loss: 0.0585643388\n",
            "Test -- Iteration: 180 \tmse_loss: 0.0585357361\n",
            "Iteration: 181 \tmse_loss: 0.0585161671\n",
            "Iteration: 182 \tmse_loss: 0.0584459230\n",
            "Iteration: 183 \tmse_loss: 0.0583487861\n",
            "Iteration: 184 \tmse_loss: 0.0582267419\n",
            "Iteration: 185 \tmse_loss: 0.0581009239\n",
            "Iteration: 186 \tmse_loss: 0.0579581037\n",
            "Iteration: 187 \tmse_loss: 0.0577931367\n",
            "Iteration: 188 \tmse_loss: 0.0576271713\n",
            "Iteration: 189 \tmse_loss: 0.0574596003\n",
            "Iteration: 190 \tmse_loss: 0.0572965220\n",
            "Iteration: 191 \tmse_loss: 0.0571318157\n",
            "Iteration: 192 \tmse_loss: 0.0569594912\n",
            "Iteration: 193 \tmse_loss: 0.0567915551\n",
            "Iteration: 194 \tmse_loss: 0.0566332377\n",
            "Iteration: 195 \tmse_loss: 0.0564760715\n",
            "Iteration: 196 \tmse_loss: 0.0563259199\n",
            "Iteration: 197 \tmse_loss: 0.0561856069\n",
            "Iteration: 198 \tmse_loss: 0.0560533516\n",
            "Final loss \tmse_loss: 0.0560533516\n",
            "Iteration: 0 \tmse_loss: 0.0583632514\n",
            "Test -- Iteration: 0 \tmse_loss: 0.0603596494\n",
            "Iteration: 1 \tmse_loss: 0.0600551255\n",
            "Iteration: 2 \tmse_loss: 0.0593701750\n",
            "Iteration: 3 \tmse_loss: 0.0583277531\n",
            "Iteration: 4 \tmse_loss: 0.0583792888\n",
            "Iteration: 5 \tmse_loss: 0.0580372736\n",
            "Iteration: 6 \tmse_loss: 0.0573750958\n",
            "Iteration: 7 \tmse_loss: 0.0570885614\n",
            "Iteration: 8 \tmse_loss: 0.0570001714\n",
            "Iteration: 9 \tmse_loss: 0.0569471493\n",
            "Iteration: 10 \tmse_loss: 0.0567976572\n",
            "Iteration: 11 \tmse_loss: 0.0565225929\n",
            "Iteration: 12 \tmse_loss: 0.0562745556\n",
            "Iteration: 13 \tmse_loss: 0.0561219230\n",
            "Iteration: 14 \tmse_loss: 0.0560097471\n",
            "Iteration: 15 \tmse_loss: 0.0558965243\n",
            "Iteration: 16 \tmse_loss: 0.0557684377\n",
            "Iteration: 17 \tmse_loss: 0.0556366444\n",
            "Iteration: 18 \tmse_loss: 0.0555225611\n",
            "Iteration: 19 \tmse_loss: 0.0554185137\n",
            "Iteration: 20 \tmse_loss: 0.0585973002\n",
            "Test -- Iteration: 20 \tmse_loss: 0.0586606599\n",
            "Iteration: 21 \tmse_loss: 0.0585470870\n",
            "Iteration: 22 \tmse_loss: 0.0584536605\n",
            "Iteration: 23 \tmse_loss: 0.0583342016\n",
            "Iteration: 24 \tmse_loss: 0.0581993200\n",
            "Iteration: 25 \tmse_loss: 0.0580525249\n",
            "Iteration: 26 \tmse_loss: 0.0578965768\n",
            "Iteration: 27 \tmse_loss: 0.0577455610\n",
            "Iteration: 28 \tmse_loss: 0.0575935096\n",
            "Iteration: 29 \tmse_loss: 0.0574279092\n",
            "Iteration: 30 \tmse_loss: 0.0572549142\n",
            "Iteration: 31 \tmse_loss: 0.0570761003\n",
            "Iteration: 32 \tmse_loss: 0.0569008105\n",
            "Iteration: 33 \tmse_loss: 0.0567320399\n",
            "Iteration: 34 \tmse_loss: 0.0565668084\n",
            "Iteration: 35 \tmse_loss: 0.0564111769\n",
            "Iteration: 36 \tmse_loss: 0.0562701933\n",
            "Iteration: 37 \tmse_loss: 0.0561331026\n",
            "Iteration: 38 \tmse_loss: 0.0560022816\n",
            "Iteration: 39 \tmse_loss: 0.0558819808\n",
            "Iteration: 40 \tmse_loss: 0.0585005172\n",
            "Test -- Iteration: 40 \tmse_loss: 0.0585179292\n",
            "Iteration: 41 \tmse_loss: 0.0584426410\n",
            "Iteration: 42 \tmse_loss: 0.0583448932\n",
            "Iteration: 43 \tmse_loss: 0.0582322143\n",
            "Iteration: 44 \tmse_loss: 0.0581048690\n",
            "Iteration: 45 \tmse_loss: 0.0579702146\n",
            "Iteration: 46 \tmse_loss: 0.0578246936\n",
            "Iteration: 47 \tmse_loss: 0.0576725565\n",
            "Iteration: 48 \tmse_loss: 0.0575246625\n",
            "Iteration: 49 \tmse_loss: 0.0573720969\n",
            "Iteration: 50 \tmse_loss: 0.0572080500\n",
            "Iteration: 51 \tmse_loss: 0.0570408180\n",
            "Iteration: 52 \tmse_loss: 0.0568724126\n",
            "Iteration: 53 \tmse_loss: 0.0567050576\n",
            "Iteration: 54 \tmse_loss: 0.0565515496\n",
            "Iteration: 55 \tmse_loss: 0.0564009175\n",
            "Iteration: 56 \tmse_loss: 0.0562577546\n",
            "Iteration: 57 \tmse_loss: 0.0561258681\n",
            "Iteration: 58 \tmse_loss: 0.0559982397\n",
            "Iteration: 59 \tmse_loss: 0.0558791049\n",
            "Iteration: 60 \tmse_loss: 0.0583988838\n",
            "Test -- Iteration: 60 \tmse_loss: 0.0584394075\n",
            "Iteration: 61 \tmse_loss: 0.0583553128\n",
            "Iteration: 62 \tmse_loss: 0.0582711622\n",
            "Iteration: 63 \tmse_loss: 0.0581689551\n",
            "Iteration: 64 \tmse_loss: 0.0580511577\n",
            "Iteration: 65 \tmse_loss: 0.0579185486\n",
            "Iteration: 66 \tmse_loss: 0.0577772856\n",
            "Iteration: 67 \tmse_loss: 0.0576361902\n",
            "Iteration: 68 \tmse_loss: 0.0574887358\n",
            "Iteration: 69 \tmse_loss: 0.0573324412\n",
            "Iteration: 70 \tmse_loss: 0.0571661368\n",
            "Iteration: 71 \tmse_loss: 0.0569979362\n",
            "Iteration: 72 \tmse_loss: 0.0568395182\n",
            "Iteration: 73 \tmse_loss: 0.0566812083\n",
            "Iteration: 74 \tmse_loss: 0.0565239713\n",
            "Iteration: 75 \tmse_loss: 0.0563772731\n",
            "Iteration: 76 \tmse_loss: 0.0562362932\n",
            "Iteration: 77 \tmse_loss: 0.0561036952\n",
            "Iteration: 78 \tmse_loss: 0.0559801087\n",
            "Iteration: 79 \tmse_loss: 0.0558576994\n",
            "Iteration: 80 \tmse_loss: 0.0583008341\n",
            "Test -- Iteration: 80 \tmse_loss: 0.0583822429\n",
            "Iteration: 81 \tmse_loss: 0.0582619123\n",
            "Iteration: 82 \tmse_loss: 0.0581855960\n",
            "Iteration: 83 \tmse_loss: 0.0580869019\n",
            "Iteration: 84 \tmse_loss: 0.0579705387\n",
            "Iteration: 85 \tmse_loss: 0.0578539260\n",
            "Iteration: 86 \tmse_loss: 0.0577250645\n",
            "Iteration: 87 \tmse_loss: 0.0575873181\n",
            "Iteration: 88 \tmse_loss: 0.0574376509\n",
            "Iteration: 89 \tmse_loss: 0.0572817065\n",
            "Iteration: 90 \tmse_loss: 0.0571225360\n",
            "Iteration: 91 \tmse_loss: 0.0569643043\n",
            "Iteration: 92 \tmse_loss: 0.0568063110\n",
            "Iteration: 93 \tmse_loss: 0.0566502027\n",
            "Iteration: 94 \tmse_loss: 0.0564989708\n",
            "Iteration: 95 \tmse_loss: 0.0563550331\n",
            "Iteration: 96 \tmse_loss: 0.0562174916\n",
            "Iteration: 97 \tmse_loss: 0.0560853928\n",
            "Iteration: 98 \tmse_loss: 0.0559594184\n",
            "Iteration: 99 \tmse_loss: 0.0558438823\n",
            "Iteration: 100 \tmse_loss: 0.0582681037\n",
            "Test -- Iteration: 100 \tmse_loss: 0.0583351739\n",
            "Iteration: 101 \tmse_loss: 0.0582236387\n",
            "Iteration: 102 \tmse_loss: 0.0581500977\n",
            "Iteration: 103 \tmse_loss: 0.0580635518\n",
            "Iteration: 104 \tmse_loss: 0.0579619855\n",
            "Iteration: 105 \tmse_loss: 0.0578412972\n",
            "Iteration: 106 \tmse_loss: 0.0577107891\n",
            "Iteration: 107 \tmse_loss: 0.0575784333\n",
            "Iteration: 108 \tmse_loss: 0.0574337579\n",
            "Iteration: 109 \tmse_loss: 0.0572790392\n",
            "Iteration: 110 \tmse_loss: 0.0571221747\n",
            "Iteration: 111 \tmse_loss: 0.0569660850\n",
            "Iteration: 112 \tmse_loss: 0.0568055846\n",
            "Iteration: 113 \tmse_loss: 0.0566520058\n",
            "Iteration: 114 \tmse_loss: 0.0565054826\n",
            "Iteration: 115 \tmse_loss: 0.0563623980\n",
            "Iteration: 116 \tmse_loss: 0.0562233441\n",
            "Iteration: 117 \tmse_loss: 0.0560923554\n",
            "Iteration: 118 \tmse_loss: 0.0559682362\n",
            "Iteration: 119 \tmse_loss: 0.0558539778\n",
            "Iteration: 120 \tmse_loss: 0.0582248904\n",
            "Test -- Iteration: 120 \tmse_loss: 0.0582883246\n",
            "Iteration: 121 \tmse_loss: 0.0581743345\n",
            "Iteration: 122 \tmse_loss: 0.0581071675\n",
            "Iteration: 123 \tmse_loss: 0.0580269955\n",
            "Iteration: 124 \tmse_loss: 0.0579292290\n",
            "Iteration: 125 \tmse_loss: 0.0578170344\n",
            "Iteration: 126 \tmse_loss: 0.0576967895\n",
            "Iteration: 127 \tmse_loss: 0.0575620830\n",
            "Iteration: 128 \tmse_loss: 0.0574182086\n",
            "Iteration: 129 \tmse_loss: 0.0572705269\n",
            "Iteration: 130 \tmse_loss: 0.0571183003\n",
            "Iteration: 131 \tmse_loss: 0.0569655448\n",
            "Iteration: 132 \tmse_loss: 0.0568121858\n",
            "Iteration: 133 \tmse_loss: 0.0566632114\n",
            "Iteration: 134 \tmse_loss: 0.0565174930\n",
            "Iteration: 135 \tmse_loss: 0.0563769713\n",
            "Iteration: 136 \tmse_loss: 0.0562402941\n",
            "Iteration: 137 \tmse_loss: 0.0561066642\n",
            "Iteration: 138 \tmse_loss: 0.0559859909\n",
            "Iteration: 139 \tmse_loss: 0.0558720827\n",
            "Iteration: 140 \tmse_loss: 0.0582550615\n",
            "Test -- Iteration: 140 \tmse_loss: 0.0582400374\n",
            "Iteration: 141 \tmse_loss: 0.0582062043\n",
            "Iteration: 142 \tmse_loss: 0.0581440814\n",
            "Iteration: 143 \tmse_loss: 0.0580689013\n",
            "Iteration: 144 \tmse_loss: 0.0579733960\n",
            "Iteration: 145 \tmse_loss: 0.0578630231\n",
            "Iteration: 146 \tmse_loss: 0.0577462576\n",
            "Iteration: 147 \tmse_loss: 0.0576183386\n",
            "Iteration: 148 \tmse_loss: 0.0574813299\n",
            "Iteration: 149 \tmse_loss: 0.0573357977\n",
            "Iteration: 150 \tmse_loss: 0.0571862012\n",
            "Iteration: 151 \tmse_loss: 0.0570366606\n",
            "Iteration: 152 \tmse_loss: 0.0568876229\n",
            "Iteration: 153 \tmse_loss: 0.0567405522\n",
            "Iteration: 154 \tmse_loss: 0.0565968715\n",
            "Iteration: 155 \tmse_loss: 0.0564587042\n",
            "Iteration: 156 \tmse_loss: 0.0563263856\n",
            "Iteration: 157 \tmse_loss: 0.0561975688\n",
            "Iteration: 158 \tmse_loss: 0.0560763068\n",
            "Iteration: 159 \tmse_loss: 0.0559618808\n",
            "Iteration: 160 \tmse_loss: 0.0581783615\n",
            "Test -- Iteration: 160 \tmse_loss: 0.0581905097\n",
            "Iteration: 161 \tmse_loss: 0.0581263043\n",
            "Iteration: 162 \tmse_loss: 0.0580719523\n",
            "Iteration: 163 \tmse_loss: 0.0579994917\n",
            "Iteration: 164 \tmse_loss: 0.0579061098\n",
            "Iteration: 165 \tmse_loss: 0.0578036793\n",
            "Iteration: 166 \tmse_loss: 0.0576909147\n",
            "Iteration: 167 \tmse_loss: 0.0575633831\n",
            "Iteration: 168 \tmse_loss: 0.0574271008\n",
            "Iteration: 169 \tmse_loss: 0.0572895445\n",
            "Iteration: 170 \tmse_loss: 0.0571433678\n",
            "Iteration: 171 \tmse_loss: 0.0569966063\n",
            "Iteration: 172 \tmse_loss: 0.0568482652\n",
            "Iteration: 173 \tmse_loss: 0.0567046702\n",
            "Iteration: 174 \tmse_loss: 0.0565664805\n",
            "Iteration: 175 \tmse_loss: 0.0564322285\n",
            "Iteration: 176 \tmse_loss: 0.0562998168\n",
            "Iteration: 177 \tmse_loss: 0.0561724082\n",
            "Iteration: 178 \tmse_loss: 0.0560505912\n",
            "Iteration: 179 \tmse_loss: 0.0559392422\n",
            "Iteration: 180 \tmse_loss: 0.0581695028\n",
            "Test -- Iteration: 180 \tmse_loss: 0.0581465550\n",
            "Iteration: 181 \tmse_loss: 0.0581239685\n",
            "Iteration: 182 \tmse_loss: 0.0580703653\n",
            "Iteration: 183 \tmse_loss: 0.0580023937\n",
            "Iteration: 184 \tmse_loss: 0.0579131171\n",
            "Iteration: 185 \tmse_loss: 0.0578152537\n",
            "Iteration: 186 \tmse_loss: 0.0577037446\n",
            "Iteration: 187 \tmse_loss: 0.0575767830\n",
            "Iteration: 188 \tmse_loss: 0.0574451610\n",
            "Iteration: 189 \tmse_loss: 0.0573083945\n",
            "Iteration: 190 \tmse_loss: 0.0571644716\n",
            "Iteration: 191 \tmse_loss: 0.0570235848\n",
            "Iteration: 192 \tmse_loss: 0.0568836145\n",
            "Iteration: 193 \tmse_loss: 0.0567424037\n",
            "Iteration: 194 \tmse_loss: 0.0566056855\n",
            "Iteration: 195 \tmse_loss: 0.0564705916\n",
            "Iteration: 196 \tmse_loss: 0.0563388765\n",
            "Iteration: 197 \tmse_loss: 0.0562140942\n",
            "Iteration: 198 \tmse_loss: 0.0560982749\n",
            "Final loss \tmse_loss: 0.0560982749\n",
            "Iteration: 0 \tmse_loss: 0.0580087043\n",
            "Test -- Iteration: 0 \tmse_loss: 0.0609707311\n",
            "Iteration: 1 \tmse_loss: 0.0606826246\n",
            "Iteration: 2 \tmse_loss: 0.0596871674\n",
            "Iteration: 3 \tmse_loss: 0.0584354773\n",
            "Iteration: 4 \tmse_loss: 0.0585663803\n",
            "Iteration: 5 \tmse_loss: 0.0583942570\n",
            "Iteration: 6 \tmse_loss: 0.0575588159\n",
            "Iteration: 7 \tmse_loss: 0.0572073683\n",
            "Iteration: 8 \tmse_loss: 0.0571657084\n",
            "Iteration: 9 \tmse_loss: 0.0571608134\n",
            "Iteration: 10 \tmse_loss: 0.0570511036\n",
            "Iteration: 11 \tmse_loss: 0.0567745119\n",
            "Iteration: 12 \tmse_loss: 0.0564718880\n",
            "Iteration: 13 \tmse_loss: 0.0562964752\n",
            "Iteration: 14 \tmse_loss: 0.0562004074\n",
            "Iteration: 15 \tmse_loss: 0.0561003536\n",
            "Iteration: 16 \tmse_loss: 0.0559679344\n",
            "Iteration: 17 \tmse_loss: 0.0558167994\n",
            "Iteration: 18 \tmse_loss: 0.0556885526\n",
            "Iteration: 19 \tmse_loss: 0.0555902533\n",
            "Iteration: 20 \tmse_loss: 0.0582443066\n",
            "Test -- Iteration: 20 \tmse_loss: 0.0583156124\n",
            "Iteration: 21 \tmse_loss: 0.0581980646\n",
            "Iteration: 22 \tmse_loss: 0.0581207909\n",
            "Iteration: 23 \tmse_loss: 0.0580295287\n",
            "Iteration: 24 \tmse_loss: 0.0579333752\n",
            "Iteration: 25 \tmse_loss: 0.0578251071\n",
            "Iteration: 26 \tmse_loss: 0.0577054359\n",
            "Iteration: 27 \tmse_loss: 0.0575757064\n",
            "Iteration: 28 \tmse_loss: 0.0574445315\n",
            "Iteration: 29 \tmse_loss: 0.0573111624\n",
            "Iteration: 30 \tmse_loss: 0.0571672507\n",
            "Iteration: 31 \tmse_loss: 0.0570167266\n",
            "Iteration: 32 \tmse_loss: 0.0568660647\n",
            "Iteration: 33 \tmse_loss: 0.0567213409\n",
            "Iteration: 34 \tmse_loss: 0.0565823615\n",
            "Iteration: 35 \tmse_loss: 0.0564434268\n",
            "Iteration: 36 \tmse_loss: 0.0563144051\n",
            "Iteration: 37 \tmse_loss: 0.0561932214\n",
            "Iteration: 38 \tmse_loss: 0.0560763739\n",
            "Iteration: 39 \tmse_loss: 0.0559607409\n",
            "Iteration: 40 \tmse_loss: 0.0581259765\n",
            "Test -- Iteration: 40 \tmse_loss: 0.0581662729\n",
            "Iteration: 41 \tmse_loss: 0.0580832325\n",
            "Iteration: 42 \tmse_loss: 0.0580102764\n",
            "Iteration: 43 \tmse_loss: 0.0579239950\n",
            "Iteration: 44 \tmse_loss: 0.0578258857\n",
            "Iteration: 45 \tmse_loss: 0.0577172190\n",
            "Iteration: 46 \tmse_loss: 0.0576070212\n",
            "Iteration: 47 \tmse_loss: 0.0574898832\n",
            "Iteration: 48 \tmse_loss: 0.0573648661\n",
            "Iteration: 49 \tmse_loss: 0.0572324730\n",
            "Iteration: 50 \tmse_loss: 0.0570978336\n",
            "Iteration: 51 \tmse_loss: 0.0569576733\n",
            "Iteration: 52 \tmse_loss: 0.0568133742\n",
            "Iteration: 53 \tmse_loss: 0.0566720925\n",
            "Iteration: 54 \tmse_loss: 0.0565379076\n",
            "Iteration: 55 \tmse_loss: 0.0564100742\n",
            "Iteration: 56 \tmse_loss: 0.0562831052\n",
            "Iteration: 57 \tmse_loss: 0.0561603121\n",
            "Iteration: 58 \tmse_loss: 0.0560473576\n",
            "Iteration: 59 \tmse_loss: 0.0559373684\n",
            "Iteration: 60 \tmse_loss: 0.0580516569\n",
            "Test -- Iteration: 60 \tmse_loss: 0.0581022613\n",
            "Iteration: 61 \tmse_loss: 0.0580109730\n",
            "Iteration: 62 \tmse_loss: 0.0579496510\n",
            "Iteration: 63 \tmse_loss: 0.0578721128\n",
            "Iteration: 64 \tmse_loss: 0.0577802770\n",
            "Iteration: 65 \tmse_loss: 0.0576802157\n",
            "Iteration: 66 \tmse_loss: 0.0575671718\n",
            "Iteration: 67 \tmse_loss: 0.0574512966\n",
            "Iteration: 68 \tmse_loss: 0.0573305190\n",
            "Iteration: 69 \tmse_loss: 0.0572014339\n",
            "Iteration: 70 \tmse_loss: 0.0570684671\n",
            "Iteration: 71 \tmse_loss: 0.0569284186\n",
            "Iteration: 72 \tmse_loss: 0.0567854159\n",
            "Iteration: 73 \tmse_loss: 0.0566497557\n",
            "Iteration: 74 \tmse_loss: 0.0565192848\n",
            "Iteration: 75 \tmse_loss: 0.0563867055\n",
            "Iteration: 76 \tmse_loss: 0.0562604666\n",
            "Iteration: 77 \tmse_loss: 0.0561419614\n",
            "Iteration: 78 \tmse_loss: 0.0560261309\n",
            "Iteration: 79 \tmse_loss: 0.0559214652\n",
            "Iteration: 80 \tmse_loss: 0.0579967871\n",
            "Test -- Iteration: 80 \tmse_loss: 0.0580751039\n",
            "Iteration: 81 \tmse_loss: 0.0579536259\n",
            "Iteration: 82 \tmse_loss: 0.0578917414\n",
            "Iteration: 83 \tmse_loss: 0.0578155629\n",
            "Iteration: 84 \tmse_loss: 0.0577258468\n",
            "Iteration: 85 \tmse_loss: 0.0576267466\n",
            "Iteration: 86 \tmse_loss: 0.0575213395\n",
            "Iteration: 87 \tmse_loss: 0.0574095100\n",
            "Iteration: 88 \tmse_loss: 0.0572935976\n",
            "Iteration: 89 \tmse_loss: 0.0571644679\n",
            "Iteration: 90 \tmse_loss: 0.0570293479\n",
            "Iteration: 91 \tmse_loss: 0.0568941534\n",
            "Iteration: 92 \tmse_loss: 0.0567530282\n",
            "Iteration: 93 \tmse_loss: 0.0566156730\n",
            "Iteration: 94 \tmse_loss: 0.0564841405\n",
            "Iteration: 95 \tmse_loss: 0.0563545488\n",
            "Iteration: 96 \tmse_loss: 0.0562311411\n",
            "Iteration: 97 \tmse_loss: 0.0561172403\n",
            "Iteration: 98 \tmse_loss: 0.0560029671\n",
            "Iteration: 99 \tmse_loss: 0.0558932871\n",
            "Iteration: 100 \tmse_loss: 0.0579708554\n",
            "Test -- Iteration: 100 \tmse_loss: 0.0580518134\n",
            "Iteration: 101 \tmse_loss: 0.0579332560\n",
            "Iteration: 102 \tmse_loss: 0.0578731000\n",
            "Iteration: 103 \tmse_loss: 0.0577995703\n",
            "Iteration: 104 \tmse_loss: 0.0577156954\n",
            "Iteration: 105 \tmse_loss: 0.0576188155\n",
            "Iteration: 106 \tmse_loss: 0.0575172827\n",
            "Iteration: 107 \tmse_loss: 0.0574074574\n",
            "Iteration: 108 \tmse_loss: 0.0572878979\n",
            "Iteration: 109 \tmse_loss: 0.0571583696\n",
            "Iteration: 110 \tmse_loss: 0.0570275933\n",
            "Iteration: 111 \tmse_loss: 0.0568949506\n",
            "Iteration: 112 \tmse_loss: 0.0567576028\n",
            "Iteration: 113 \tmse_loss: 0.0566182695\n",
            "Iteration: 114 \tmse_loss: 0.0564858988\n",
            "Iteration: 115 \tmse_loss: 0.0563616715\n",
            "Iteration: 116 \tmse_loss: 0.0562375672\n",
            "Iteration: 117 \tmse_loss: 0.0561166443\n",
            "Iteration: 118 \tmse_loss: 0.0560057238\n",
            "Iteration: 119 \tmse_loss: 0.0558979809\n",
            "Iteration: 120 \tmse_loss: 0.0579463355\n",
            "Test -- Iteration: 120 \tmse_loss: 0.0580245666\n",
            "Iteration: 121 \tmse_loss: 0.0579052866\n",
            "Iteration: 122 \tmse_loss: 0.0578486323\n",
            "Iteration: 123 \tmse_loss: 0.0577792041\n",
            "Iteration: 124 \tmse_loss: 0.0576982982\n",
            "Iteration: 125 \tmse_loss: 0.0576099604\n",
            "Iteration: 126 \tmse_loss: 0.0575104915\n",
            "Iteration: 127 \tmse_loss: 0.0574034080\n",
            "Iteration: 128 \tmse_loss: 0.0572823808\n",
            "Iteration: 129 \tmse_loss: 0.0571549870\n",
            "Iteration: 130 \tmse_loss: 0.0570249222\n",
            "Iteration: 131 \tmse_loss: 0.0568928905\n",
            "Iteration: 132 \tmse_loss: 0.0567556508\n",
            "Iteration: 133 \tmse_loss: 0.0566255301\n",
            "Iteration: 134 \tmse_loss: 0.0564990193\n",
            "Iteration: 135 \tmse_loss: 0.0563755445\n",
            "Iteration: 136 \tmse_loss: 0.0562490486\n",
            "Iteration: 137 \tmse_loss: 0.0561314300\n",
            "Iteration: 138 \tmse_loss: 0.0560216717\n",
            "Iteration: 139 \tmse_loss: 0.0559158474\n",
            "Iteration: 140 \tmse_loss: 0.0579941832\n",
            "Test -- Iteration: 140 \tmse_loss: 0.0579947233\n",
            "Iteration: 141 \tmse_loss: 0.0579538122\n",
            "Iteration: 142 \tmse_loss: 0.0579019152\n",
            "Iteration: 143 \tmse_loss: 0.0578411780\n",
            "Iteration: 144 \tmse_loss: 0.0577619374\n",
            "Iteration: 145 \tmse_loss: 0.0576690659\n",
            "Iteration: 146 \tmse_loss: 0.0575748608\n",
            "Iteration: 147 \tmse_loss: 0.0574680753\n",
            "Iteration: 148 \tmse_loss: 0.0573483743\n",
            "Iteration: 149 \tmse_loss: 0.0572262593\n",
            "Iteration: 150 \tmse_loss: 0.0570997745\n",
            "Iteration: 151 \tmse_loss: 0.0569670089\n",
            "Iteration: 152 \tmse_loss: 0.0568355210\n",
            "Iteration: 153 \tmse_loss: 0.0567059815\n",
            "Iteration: 154 \tmse_loss: 0.0565769747\n",
            "Iteration: 155 \tmse_loss: 0.0564574972\n",
            "Iteration: 156 \tmse_loss: 0.0563370958\n",
            "Iteration: 157 \tmse_loss: 0.0562168397\n",
            "Iteration: 158 \tmse_loss: 0.0561073683\n",
            "Iteration: 159 \tmse_loss: 0.0560047962\n",
            "Iteration: 160 \tmse_loss: 0.0579383634\n",
            "Test -- Iteration: 160 \tmse_loss: 0.0579680353\n",
            "Iteration: 161 \tmse_loss: 0.0578971617\n",
            "Iteration: 162 \tmse_loss: 0.0578483269\n",
            "Iteration: 163 \tmse_loss: 0.0577861890\n",
            "Iteration: 164 \tmse_loss: 0.0577090122\n",
            "Iteration: 165 \tmse_loss: 0.0576202609\n",
            "Iteration: 166 \tmse_loss: 0.0575283095\n",
            "Iteration: 167 \tmse_loss: 0.0574252978\n",
            "Iteration: 168 \tmse_loss: 0.0573072024\n",
            "Iteration: 169 \tmse_loss: 0.0571829155\n",
            "Iteration: 170 \tmse_loss: 0.0570622087\n",
            "Iteration: 171 \tmse_loss: 0.0569334961\n",
            "Iteration: 172 \tmse_loss: 0.0567994490\n",
            "Iteration: 173 \tmse_loss: 0.0566748902\n",
            "Iteration: 174 \tmse_loss: 0.0565512478\n",
            "Iteration: 175 \tmse_loss: 0.0564301349\n",
            "Iteration: 176 \tmse_loss: 0.0563090183\n",
            "Iteration: 177 \tmse_loss: 0.0561920479\n",
            "Iteration: 178 \tmse_loss: 0.0560858473\n",
            "Iteration: 179 \tmse_loss: 0.0559834540\n",
            "Iteration: 180 \tmse_loss: 0.0579540767\n",
            "Test -- Iteration: 180 \tmse_loss: 0.0579351746\n",
            "Iteration: 181 \tmse_loss: 0.0579106994\n",
            "Iteration: 182 \tmse_loss: 0.0578673445\n",
            "Iteration: 183 \tmse_loss: 0.0578086041\n",
            "Iteration: 184 \tmse_loss: 0.0577318072\n",
            "Iteration: 185 \tmse_loss: 0.0576471910\n",
            "Iteration: 186 \tmse_loss: 0.0575554483\n",
            "Iteration: 187 \tmse_loss: 0.0574524961\n",
            "Iteration: 188 \tmse_loss: 0.0573385134\n",
            "Iteration: 189 \tmse_loss: 0.0572172962\n",
            "Iteration: 190 \tmse_loss: 0.0570926666\n",
            "Iteration: 191 \tmse_loss: 0.0569681264\n",
            "Iteration: 192 \tmse_loss: 0.0568408407\n",
            "Iteration: 193 \tmse_loss: 0.0567177683\n",
            "Iteration: 194 \tmse_loss: 0.0565971024\n",
            "Iteration: 195 \tmse_loss: 0.0564751588\n",
            "Iteration: 196 \tmse_loss: 0.0563544072\n",
            "Iteration: 197 \tmse_loss: 0.0562409461\n",
            "Iteration: 198 \tmse_loss: 0.0561330505\n",
            "Final loss \tmse_loss: 0.0561330505\n"
          ]
        }
      ],
      "source": [
        "mask_cross_validation = [0]\n",
        "\n",
        "res = []\n",
        "for seed in range(10):\n",
        "    res.append(decompose(seed=seed, data=data, number_components=[2,3,3], iterations=iterations,\n",
        "                decay_rate_mask=decay_rate_mask, decay_rate_lr=decay_rate_lr, decay_iterations=decay_iterations,\n",
        "                decay_type_mask=decay_type_mask, decay_type_lr=decay_type_lr, learning_rate=learning_rate, mask=mask,\n",
        "                mask_cross_validation=mask_cross_validation[0], batch_size=batch_size, sliceTCA=True, positive=positive,\n",
        "                orthogonal_penalty=orthogonal_penalty, metric=metric, cross_validation=False,\n",
        "                precision=torch.float32, orthogonal_constraint=orthogonal_constraint, cut_cv_mask=cut_cv_mask,\n",
        "                initialization=initialization, orthogonal_skip=(), test_freq=-1, verbose_train=verbose_train,\n",
        "                verbose_test=verbose_test, device=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzUeJYl2XGnL"
      },
      "outputs": [],
      "source": [
        "bestmodel = np.argmin([r[2] for r in res])\n",
        "components, metric_value, ls, l_cv, convergence, model = res[bestmodel]\n",
        "pickle.dump(model.cpu(), open('./IBL_sliceTCA-2-3-3.p', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = [r[-1].cpu() for r in res]\n",
        "losses = [r[2] for r in res]"
      ],
      "metadata": {
        "id": "QmW_Onp1h3iU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump([models, losses], open('./IBL_2-3-3_all-models.p', 'wb'))"
      ],
      "metadata": {
        "id": "7YZcmMCDh6CN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YTGvog7mh-ph"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}