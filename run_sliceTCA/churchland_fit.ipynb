{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHiF2GEMNydk",
        "outputId": "8b0998f9-d55c-4fe8-c321-327e6f88f105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqVOdtHDQ8on",
        "outputId": "3c956dc4-4d49-4792-c619-df0d3f2204a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/iterative-tensor-decomposition-colab\n"
          ]
        }
      ],
      "source": [
        "cd drive/MyDrive/iterative-tensor-decomposition-colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "05Y9zjdCOdCA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.ndimage as spnd\n",
        "import torch\n",
        "from run.run_tca import decompose\n",
        "import pickle\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "d1 = np.load('./data/neurons_10_straight_Churchland.npy').transpose([1,0,2]) * 100\n",
        "d2 = np.load('./data/neurons_10_curved_Churchland.npy').transpose([1,0,2]) * 100\n",
        "data = np.concatenate([d1,d2], axis=1)\n",
        "\n",
        "data = spnd.gaussian_filter1d(data, sigma=2)\n",
        "data = np.array([d-np.min(d) for d in data])\n",
        "data = np.array([d/np.max(d) for d in data])\n",
        "data = torch.from_numpy(data.transpose([1,0,2])).float().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Om4r3dlON0v",
        "outputId": "e369aaad-a3ab-4774-db66-8385183fdc00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([511, 182, 150])\n",
            "0.20214619040450743\n"
          ]
        }
      ],
      "source": [
        "print(data.shape)\n",
        "print((1*1*15*188000)/(511*182*150)) # percentage: block mask dims, how many blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "X06E2010O3ON"
      },
      "outputs": [],
      "source": [
        "#The hyperparameters\n",
        "slice_TCA = True\n",
        "positive = True\n",
        "orthogonal_constraint  = False\n",
        "cross_validation = True\n",
        "orthogonal_penalty = False\n",
        "metric = False\n",
        "do_varimax = False\n",
        "cut_cv_mask = 4\n",
        "\n",
        "mask_cross_validation = 0.2\n",
        "\n",
        "learning_rate = 0.02\n",
        "mask = 0.8\n",
        "\n",
        "decay_rate_lr = 1\n",
        "decay_rate_mask = 0.5\n",
        "decay_iterations = 3\n",
        "decay_type_lr='exponential'\n",
        "decay_type_mask='exponential'\n",
        "\n",
        "iterations = decay_iterations*149\n",
        "batch_size = 20\n",
        "test_freq = -1\n",
        "initialization = 'uniform-positive'\n",
        "loss_kernel_sigmas = None\n",
        "\n",
        "seed = 999\n",
        "\n",
        "verbose_train = True\n",
        "verbose_test = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask_cross_validation = [0]\n",
        "\n",
        "res = []\n",
        "for seed in range(10):\n",
        "    res.append(decompose(seed=seed, data=data, number_components=[12,0,1], iterations=iterations,\n",
        "                decay_rate_mask=decay_rate_mask, decay_rate_lr=decay_rate_lr, decay_iterations=decay_iterations,\n",
        "                decay_type_mask=decay_type_mask, decay_type_lr=decay_type_lr, learning_rate=learning_rate, mask=mask,\n",
        "                mask_cross_validation=mask_cross_validation[0], batch_size=batch_size, sliceTCA=slice_TCA, positive=positive,\n",
        "                orthogonal_penalty=orthogonal_penalty, metric=metric, cross_validation=False,\n",
        "                precision=torch.float32, orthogonal_constraint=orthogonal_constraint, cut_cv_mask=cut_cv_mask,\n",
        "                initialization=initialization, orthogonal_skip=(), test_freq=-1, verbose_train=verbose_train,\n",
        "                verbose_test=verbose_test, device=device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        },
        "id": "tkkzMLgOqgSR",
        "outputId": "8c1e7830-823e-41e1-fcd2-c5d112ff5baa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0 \tmse_loss: 3.0465669632\n",
            "Test -- Iteration: 0 \tmse_loss: 2.8168802261\n",
            "Iteration: 1 \tmse_loss: 2.8171935081\n",
            "Iteration: 2 \tmse_loss: 2.6022610664\n",
            "Iteration: 3 \tmse_loss: 2.4020912647\n",
            "Iteration: 4 \tmse_loss: 2.2172360420\n",
            "Iteration: 5 \tmse_loss: 2.0471653938\n",
            "Iteration: 6 \tmse_loss: 1.8899700642\n",
            "Iteration: 7 \tmse_loss: 1.7455542088\n",
            "Iteration: 8 \tmse_loss: 1.6134904623\n",
            "Iteration: 9 \tmse_loss: 1.4928222895\n",
            "Iteration: 10 \tmse_loss: 1.3823325634\n",
            "Iteration: 11 \tmse_loss: 1.2814027071\n",
            "Iteration: 12 \tmse_loss: 1.1898528337\n",
            "Iteration: 13 \tmse_loss: 1.1066349745\n",
            "Iteration: 14 \tmse_loss: 1.0308688879\n",
            "Iteration: 15 \tmse_loss: 0.9621300697\n",
            "Iteration: 16 \tmse_loss: 0.8999217749\n",
            "Iteration: 17 \tmse_loss: 0.8434091210\n",
            "Iteration: 18 \tmse_loss: 0.7918075323\n",
            "Iteration: 19 \tmse_loss: 0.7446738482\n",
            "Iteration: 20 \tmse_loss: 0.7017400861\n",
            "Test -- Iteration: 20 \tmse_loss: 0.6623878479\n",
            "Iteration: 21 \tmse_loss: 0.6623658538\n",
            "Iteration: 22 \tmse_loss: 0.6263423562\n",
            "Iteration: 23 \tmse_loss: 0.5932705402\n",
            "Iteration: 24 \tmse_loss: 0.5629963279\n",
            "Iteration: 25 \tmse_loss: 0.5352507830\n",
            "Iteration: 26 \tmse_loss: 0.5097948909\n",
            "Iteration: 27 \tmse_loss: 0.4863901734\n",
            "Iteration: 28 \tmse_loss: 0.4648213685\n",
            "Iteration: 29 \tmse_loss: 0.4449524879\n",
            "Iteration: 30 \tmse_loss: 0.4265975654\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-b8f994c74c48>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     res.append(decompose(seed=seed, data=data, number_components=[12,0,0], iterations=iterations,\n\u001b[0m\u001b[1;32m      6\u001b[0m                 \u001b[0mdecay_rate_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay_rate_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_rate_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay_rate_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mdecay_type_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay_type_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_type_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay_type_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/iterative-tensor-decomposition-colab/run/run_tca.py\u001b[0m in \u001b[0;36mdecompose\u001b[0;34m(seed, data, number_components, iterations, decay_rate_mask, decay_rate_lr, decay_iterations, decay_type_mask, decay_type_lr, learning_rate, mask, cut_cv_mask, mask_cross_validation, batch_size, sliceTCA, positive, orthogonal_penalty, metric, cross_validation, precision, orthogonal_constraint, loss_kernel_sigmas, positive_function, initialization, orthogonal_skip, test_freq, verbose_train, verbose_test, device, animator)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mconvergence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecay_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         ls, convergence = model.fit(data, max_iter=iterations, learning_rate=learning_rate, mask=mask,\n\u001b[0m\u001b[1;32m     84\u001b[0m                                     \u001b[0mfixed_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                                     verbose_train=verbose_train, verbose_test=verbose_test)\n",
            "\u001b[0;32m/content/drive/MyDrive/iterative-tensor-decomposition-colab/core/classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, tensor, max_iter, learning_rate, noise, mask, fixed_mask, batch_size, test_freq, verbose_train, verbose_test)\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0;31m#         previous = torch.sqrt(l).item()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mthat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnoise\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mthat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthat\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/iterative-tensor-decomposition-colab/core/classes.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bestmodel = np.argmin([r[2] for r in res])\n",
        "components, metric_value, ls, l_cv, convergence, model = res[bestmodel]\n",
        "pickle.dump(model.cpu(), open('./Churchland_sliceTCA-12-0-1.p', 'wb'))"
      ],
      "metadata": {
        "id": "AU3_7D3qqsX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [r[-1].cpu() for r in res]\n",
        "losses = [r[2] for r in res]"
      ],
      "metadata": {
        "id": "_d6r1s8YUEAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnzZm1ghu_t8"
      },
      "outputs": [],
      "source": [
        "pickle.dump([models, losses], open('./Churchland_sliceTCA_12-0-1_all-models.p', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SHrqvwKE5Sy-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}